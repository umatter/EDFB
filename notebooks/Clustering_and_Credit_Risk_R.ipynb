{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practical of Real Financial Data (R version)\n",
        "\n",
        "---\n",
        "This notebook covers an end-to-end unsupervised and supervised learning task on real financial data, focusing on SMEs applying for loans at a P2P lending platform. The workflow mirrors the Python version, but uses idiomatic R and tidyverse approaches for clarity and comparison.\n",
        "\n",
        "## Topics covered\n",
        "\n",
        "* Data description and pre-processing\n",
        "* K-means clustering with different k values\n",
        "* Cluster evaluation and selection of best k\n",
        "* Logistic regression classifier for loan default prediction (full dataset)\n",
        "* Separate models for each identified cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load required libraries\n",
        "library(tidyverse)\n",
        "library(cluster)\n",
        "library(factoextra)\n",
        "library(caret)\n",
        "library(ggplot2)\n",
        "library(gridExtra)\n",
        "library(broom)\n",
        "library(pROC)\n",
        "library(ROCR)\n",
        "library(scales)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set seed for reproducibility\n",
        "set.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Import\n",
        "\n",
        "We use a CSV file `borrower_companies.csv` with financial ratios and a `status` column (1 = default, 0 = paid back)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the data (assume file is in working directory)\n",
        "dataset <- read_csv('borrower_companies.csv')\n",
        "glimpse(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration\n",
        "\n",
        "Let's check the structure, missing values, and summary statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check dimensions and missing values\n",
        "dim(dataset)\n",
        "colSums(is.na(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary statistics\n",
        "summary(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Feature Distributions\n",
        "\n",
        "Boxplots (standardized) for all features except `status`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Standardize features (excluding status)\n",
        "features <- dataset %>% select(-status)\n",
        "features_scaled <- as_tibble(scale(features))\n",
        "features_scaled_long <- features_scaled %>% \n",
        "  mutate(row = row_number()) %>%\n",
        "  pivot_longer(-row, names_to = 'variable', values_to = 'value')\n",
        "\n",
        "ggplot(features_scaled_long, aes(x = value, y = variable)) +\n",
        "  geom_boxplot(fill = 'skyblue', outlier.alpha = 0.2) +\n",
        "  labs(title = 'Standardized Feature Distributions', x = '', y = '') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outlier Removal (Z-score method)\n",
        "\n",
        "Remove rows where any feature has |z| > 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z_scores <- as_tibble(scale(features))\n",
        "outlier_mask <- apply(abs(z_scores), 1, function(x) all(x < 4))\n",
        "dataset_o <- dataset[outlier_mask, ]\n",
        "dim(dataset_o)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Boxplot after outlier removal\n",
        "features_o <- dataset_o %>% select(-status)\n",
        "features_o_scaled <- as_tibble(scale(features_o))\n",
        "features_o_scaled_long <- features_o_scaled %>% \n",
        "  mutate(row = row_number()) %>%\n",
        "  pivot_longer(-row, names_to = 'variable', values_to = 'value')\n",
        "\n",
        "ggplot(features_o_scaled_long, aes(x = value, y = variable)) +\n",
        "  geom_boxplot(fill = 'lightgreen', outlier.alpha = 0.2) +\n",
        "  labs(title = 'Standardized Feature Distributions (Outliers Removed)', x = '', y = '') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data for Clustering\n",
        "\n",
        "Standardize features for clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X <- dataset_o %>% select(-status)\n",
        "X_scaled <- scale(X)\n",
        "y <- dataset_o$status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "\n",
        "Visualize explained variance to understand dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca <- prcomp(X_scaled, center = TRUE, scale. = TRUE)\n",
        "explained_var <- pca$sdev^2 / sum(pca$sdev^2)\n",
        "cum_var <- cumsum(explained_var)\n",
        "\n",
        "tibble(PC = 1:length(explained_var),\n",
        "       Explained = explained_var,\n",
        "       Cumulative = cum_var) %>%\n",
        "  ggplot(aes(x = PC)) +\n",
        "  geom_bar(aes(y = Explained), stat = 'identity', fill = 'steelblue', alpha = 0.6) +\n",
        "  geom_line(aes(y = Cumulative), color = 'red', size = 1) +\n",
        "  geom_point(aes(y = Cumulative), color = 'red', size = 2) +\n",
        "  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n",
        "  labs(title = 'PCA: Explained Variance', y = 'Variance', x = 'Principal Component') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-means Clustering: Try Different k\n",
        "\n",
        "Evaluate clusters using silhouette and WCSS (within-cluster sum of squares)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_k <- 7\n",
        "silhouette_scores <- numeric(max_k - 1)\n",
        "wcss <- numeric(max_k - 1)\n",
        "labels_list <- list()\n",
        "\n",
        "for (k in 2:max_k) {\n",
        "  km <- kmeans(X_scaled, centers = k, nstart = 25)\n",
        "  ss <- silhouette(km$cluster, dist(X_scaled))\n",
        "  silhouette_scores[k-1] <- mean(ss[, 3])\n",
        "  wcss[k-1] <- km$tot.withinss\n",
        "  labels_list[[as.character(k)]] <- km$cluster\n",
        "}\n",
        "\n",
        "tibble(Clusters = 2:max_k, Silhouette = silhouette_scores, WCSS = wcss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize clusters in PCA space for each k\n",
        "pca_scores <- as_tibble(pca$x[, 1:2])\n",
        "plots <- list()\n",
        "for (k in 2:max_k) {\n",
        "  clust <- as.factor(labels_list[[as.character(k)]])\n",
        "  plots[[k-1]] <- ggplot(pca_scores, aes(x = PC1, y = PC2, color = clust)) +\n",
        "    geom_point(alpha = 0.6) +\n",
        "    labs(title = paste('k =', k), color = 'Cluster') +\n",
        "    theme_minimal()\n",
        "}\n",
        "do.call(grid.arrange, c(plots, ncol = 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Elbow and Silhouette Plots\n",
        "\n",
        "Choose the optimal number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "elbow_df <- tibble(Clusters = 2:max_k, Silhouette = silhouette_scores, WCSS = wcss)\n",
        "\n",
        "ggplot(elbow_df, aes(x = Clusters)) +\n",
        "  geom_line(aes(y = Silhouette), color = 'blue') +\n",
        "  geom_point(aes(y = Silhouette), color = 'blue') +\n",
        "  scale_y_continuous(sec.axis = sec_axis(~ ., name = 'WCSS', labels = comma)) +\n",
        "  geom_line(aes(y = rescale(WCSS, to = range(Silhouette))), color = 'red') +\n",
        "  geom_point(aes(y = rescale(WCSS, to = range(Silhouette))), color = 'red') +\n",
        "  labs(y = 'Silhouette', x = 'Number of clusters',\n",
        "       title = 'Elbow & Silhouette for k-means') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Cluster Feature Distributions\n",
        "\n",
        "Pick k = 3 for illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chosen_k <- 3\n",
        "cluster_labels <- labels_list[[as.character(chosen_k)]]\n",
        "X_labeled <- X_scaled %>% as_tibble() %>% mutate(cluster = factor(cluster_labels))\n",
        "\n",
        "X_long <- X_labeled %>%\n",
        "  pivot_longer(-cluster, names_to = 'variable', values_to = 'value')\n",
        "\n",
        "ggplot(X_long, aes(x = value, fill = cluster)) +\n",
        "  geom_density(alpha = 0.4) +\n",
        "  facet_wrap(~ variable, scales = 'free', ncol = 2) +\n",
        "  labs(title = 'Feature Distributions by Cluster', x = '', y = '') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Learning: Logistic Regression\n",
        "\n",
        "Compare a model trained on the full dataset vs. one per cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Downsample to balance classes (undersample majority class)\n",
        "library(rsample)\n",
        "library(recipes)\n",
        "\n",
        "dataset_o$status <- as.factor(dataset_o$status)\n",
        "minority <- dataset_o %>% filter(status == 1)\n",
        "majority <- dataset_o %>% filter(status == 0)\n",
        "set_size <- nrow(minority) * 2\n",
        "majority_down <- majority %>% sample_n(set_size)\n",
        "balanced <- bind_rows(minority, majority_down)\n",
        "balanced <- balanced %>% sample_frac(1) # shuffle\n",
        "table(balanced$status)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split into train/test\n",
        "set.seed(42)\n",
        "split <- initial_split(balanced, prop = 0.8, strata = status)\n",
        "train <- training(split)\n",
        "test <- testing(split)\n",
        "\n",
        "# Standardize features\n",
        "rec <- recipe(status ~ ., data = train) %>%\n",
        "  step_center(all_predictors()) %>%\n",
        "  step_scale(all_predictors()) %>%\n",
        "  prep()\n",
        "X_train <- bake(rec, new_data = train) %>% select(-status)\n",
        "y_train <- train$status\n",
        "X_test <- bake(rec, new_data = test) %>% select(-status)\n",
        "y_test <- test$status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit logistic regression\n",
        "model <- glm(status ~ ., data = cbind(X_train, status = y_train), family = binomial())\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict and evaluate\n",
        "pred_probs <- predict(model, newdata = X_test, type = 'response')\n",
        "pred_class <- ifelse(pred_probs > 0.5, 1, 0)\n",
        "conf_mat <- table(Predicted = pred_class, Actual = as.numeric(as.character(y_test)))\n",
        "conf_mat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Classification report\n",
        "caret::confusionMatrix(as.factor(pred_class), y_test, positive = '1')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ROC curve and AUC\n",
        "roc_obj <- roc(as.numeric(as.character(y_test)), pred_probs)\n",
        "plot(roc_obj, col = 'blue', main = 'ROC Curve (Full Dataset)')\n",
        "auc(roc_obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Per-Cluster Logistic Regression\n",
        "\n",
        "Repeat the above for each cluster (example for cluster 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for (cl in 1:chosen_k) {\n",
        "  cat('---\\nCluster', cl, '\\n')\n",
        "  idx <- which(cluster_labels == cl)\n",
        "  cluster_data <- dataset_o[idx, ]\n",
        "  cluster_data$status <- as.factor(cluster_data$status)\n",
        "  minority <- cluster_data %>% filter(status == 1)\n",
        "  majority <- cluster_data %>% filter(status == 0)\n",
        "  if (nrow(minority) < 5 | nrow(majority) < 5) {\n",
        "    cat('Too few samples, skipping\\n')\n",
        "    next\n",
        "  }\n",
        "  set_size <- nrow(minority) * 2\n",
        "  majority_down <- majority %>% sample_n(min(set_size, nrow(majority)))\n",
        "  balanced <- bind_rows(minority, majority_down) %>% sample_frac(1)\n",
        "  split <- initial_split(balanced, prop = 0.8, strata = status)\n",
        "  train <- training(split)\n",
        "  test <- testing(split)\n",
        "  rec <- recipe(status ~ ., data = train) %>%\n",
        "    step_center(all_predictors()) %>%\n",
        "    step_scale(all_predictors()) %>%\n",
        "    prep()\n",
        "  X_train <- bake(rec, new_data = train) %>% select(-status)\n",
        "  y_train <- train$status\n",
        "  X_test <- bake(rec, new_data = test) %>% select(-status)\n",
        "  y_test <- test$status\n",
        "  model <- glm(status ~ ., data = cbind(X_train, status = y_train), family = binomial())\n",
        "  pred_probs <- predict(model, newdata = X_test, type = 'response')\n",
        "  pred_class <- ifelse(pred_probs > 0.5, 1, 0)\n",
        "  conf_mat <- table(Predicted = pred_class, Actual = as.numeric(as.character(y_test)))\n",
        "  print(conf_mat)\n",
        "  print(caret::confusionMatrix(as.factor(pred_class), y_test, positive = '1'))\n",
        "  roc_obj <- roc(as.numeric(as.character(y_test)), pred_probs)\n",
        "  plot(roc_obj, col = 'red', main = paste('ROC Curve (Cluster', cl, ')'))\n",
        "  print(auc(roc_obj))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "This notebook demonstrates a full unsupervised + supervised learning workflow in R, closely paralleling the Python version for easy comparison. All code uses tidyverse and modern R best practices."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
