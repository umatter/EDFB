{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practical of Real Financial Data (R version)\n",
        "\n",
        "---\n",
        "This notebook covers an end-to-end unsupervised and supervised learning task on real financial data, focusing on SMEs applying for loans at a P2P lending platform. The workflow mirrors the Python version, but uses idiomatic R and tidyverse approaches for clarity and comparison.\n",
        "\n",
        "## Topics covered\n",
        "\n",
        "* Data description and pre-processing\n",
        "* K-means clustering with different k values\n",
        "* Cluster evaluation and selection of best k\n",
        "* Logistic regression classifier for loan default prediction (full dataset)\n",
        "* Separate models for each identified cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load required libraries\n",
        "# tidyverse: Collection of R packages for data manipulation and visualization\n",
        "# cluster: Functions for clustering analysis\n",
        "# factoextra: Extract and visualize results of multivariate data analyses\n",
        "# caret: Classification and Regression Training\n",
        "# ggplot2: Grammar of graphics for creating plots\n",
        "# gridExtra: Arrange multiple plots in a grid\n",
        "# broom: Convert statistical analysis objects into tidy tibbles\n",
        "# pROC: Tools for ROC curve analysis\n",
        "# ROCR: Visualizing classifier performance\n",
        "# scales: Scale functions for visualization\n",
        "\n",
        "library(tidyverse)\n",
        "library(cluster)\n",
        "library(factoextra)\n",
        "library(caret)\n",
        "library(ggplot2)\n",
        "library(gridExtra)\n",
        "library(broom)\n",
        "library(pROC)\n",
        "library(ROCR)\n",
        "library(scales)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set seed for reproducibility\n",
        "# This ensures that random processes (like clustering) produce the same results each time\n",
        "set.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Import\n",
        "\n",
        "We use a CSV file `borrower_companies.csv` with financial ratios and a `status` column (1 = default, 0 = paid back)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the data (assume file is in working directory)\n",
        "# read_csv() loads CSV files into a tibble (modern data frame)\n",
        "# glimpse() shows the structure of the data - like str() but more readable\n",
        "dataset <- read_csv('borrower_companies.csv')\n",
        "glimpse(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration\n",
        "\n",
        "Let's check the structure, missing values, and summary statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check dimensions and missing values\n",
        "# dim() returns number of rows and columns\n",
        "# is.na() checks for missing values, colSums() counts them by column\n",
        "cat(\"Dataset dimensions (rows, columns):\\n\")\n",
        "dim(dataset)\n",
        "cat(\"\\nMissing values per column:\\n\")\n",
        "colSums(is.na(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary statistics for all variables\n",
        "# summary() provides min, max, median, mean, and quartiles for numeric variables\n",
        "summary(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Feature Distributions\n",
        "\n",
        "Boxplots (standardized) for all features except `status`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Standardize features (excluding status column)\n",
        "# Standardization converts all features to have mean=0 and standard deviation=1\n",
        "# This is important for clustering as it prevents features with larger scales from dominating\n",
        "\n",
        "features <- dataset %>% select(-status)  # Remove the target variable\n",
        "features_scaled <- as_tibble(scale(features))  # Standardize all features\n",
        "\n",
        "# Reshape data for plotting (convert from wide to long format)\n",
        "# This allows us to plot all features in one chart\n",
        "features_scaled_long <- features_scaled %>% \n",
        "  mutate(row = row_number()) %>%  # Add row numbers for identification\n",
        "  pivot_longer(-row, names_to = 'variable', values_to = 'value')  # Reshape to long format\n",
        "\n",
        "# Create boxplots to visualize the distribution of each standardized feature\n",
        "# Boxplots show median, quartiles, and outliers for each variable\n",
        "ggplot(features_scaled_long, aes(x = value, y = variable)) +\n",
        "  geom_boxplot(fill = 'skyblue', outlier.alpha = 0.2) +\n",
        "  labs(title = 'Standardized Feature Distributions', \n",
        "       subtitle = 'All features now have mean=0 and std=1',\n",
        "       x = 'Standardized Value', y = 'Financial Ratios') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outlier Removal (Z-score method)\n",
        "\n",
        "Remove rows where any feature has |z| > 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Remove extreme outliers using Z-score method\n",
        "# Z-score measures how many standard deviations away from the mean a value is\n",
        "# We remove rows where ANY feature has |z-score| > 4 (very extreme values)\n",
        "\n",
        "z_scores <- as_tibble(scale(features))  # Calculate z-scores for all features\n",
        "# Create a mask: TRUE if ALL z-scores in a row are < 4 in absolute value\n",
        "outlier_mask <- apply(abs(z_scores), 1, function(x) all(x < 4))\n",
        "dataset_o <- dataset[outlier_mask, ]  # Keep only non-outlier rows\n",
        "\n",
        "cat(\"Original dataset size:\", nrow(dataset), \"rows\\n\")\n",
        "cat(\"After outlier removal:\", nrow(dataset_o), \"rows\\n\")\n",
        "cat(\"Removed\", nrow(dataset) - nrow(dataset_o), \"outlier rows\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Boxplot after outlier removal\n",
        "features_o <- dataset_o %>% select(-status)\n",
        "features_o_scaled <- as_tibble(scale(features_o))\n",
        "features_o_scaled_long <- features_o_scaled %>% \n",
        "  mutate(row = row_number()) %>%\n",
        "  pivot_longer(-row, names_to = 'variable', values_to = 'value')\n",
        "\n",
        "ggplot(features_o_scaled_long, aes(x = value, y = variable)) +\n",
        "  geom_boxplot(fill = 'lightgreen', outlier.alpha = 0.2) +\n",
        "  labs(title = 'Standardized Feature Distributions (Outliers Removed)', x = '', y = '') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data for Clustering\n",
        "\n",
        "Standardize features for clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare data for clustering\n",
        "# X contains the features (financial ratios) for clustering\n",
        "# y contains the target variable (loan status: 0=paid back, 1=default)\n",
        "# Note: Clustering is unsupervised, so we don't use y for clustering itself\n",
        "\n",
        "X <- dataset_o %>% select(-status)  # Features only (remove target variable)\n",
        "X_scaled <- scale(X)  # Standardize features for clustering\n",
        "y <- dataset_o$status  # Target variable (for later supervised learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "\n",
        "Visualize explained variance to understand dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Principal Component Analysis (PCA)\n",
        "# PCA reduces dimensionality by finding the directions of maximum variance\n",
        "# This helps us understand how much information each dimension contains\n",
        "\n",
        "pca <- prcomp(X_scaled, center = TRUE, scale. = TRUE)\n",
        "# Calculate the proportion of variance explained by each principal component\n",
        "explained_var <- pca$sdev^2 / sum(pca$sdev^2)\n",
        "cum_var <- cumsum(explained_var)  # Cumulative variance explained\n",
        "\n",
        "# Create a visualization showing individual and cumulative explained variance\n",
        "tibble(PC = 1:length(explained_var),\n",
        "       Explained = explained_var,\n",
        "       Cumulative = cum_var) %>%\n",
        "  ggplot(aes(x = PC)) +\n",
        "  geom_bar(aes(y = Explained), stat = 'identity', fill = 'steelblue', alpha = 0.6) +\n",
        "  geom_line(aes(y = Cumulative), color = 'red', size = 1) +\n",
        "  geom_point(aes(y = Cumulative), color = 'red', size = 2) +\n",
        "  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n",
        "  labs(title = 'PCA: Explained Variance', \n",
        "       subtitle = 'Bars show individual variance, red line shows cumulative',\n",
        "       y = 'Proportion of Variance Explained', \n",
        "       x = 'Principal Component') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-means Clustering: Try Different k\n",
        "\n",
        "Evaluate clusters using silhouette and WCSS (within-cluster sum of squares)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# K-means clustering: Try different numbers of clusters (k)\n",
        "# We'll evaluate each k using two metrics:\n",
        "# 1. Silhouette Score: measures how well-separated clusters are (higher = better)\n",
        "# 2. WCSS (Within-Cluster Sum of Squares): measures compactness (lower = better)\n",
        "\n",
        "max_k <- 7  # Test up to 7 clusters\n",
        "silhouette_scores <- numeric(max_k - 1)  # Store silhouette scores\n",
        "wcss <- numeric(max_k - 1)  # Store WCSS values\n",
        "labels_list <- list()  # Store cluster assignments for each k\n",
        "\n",
        "cat(\"Testing different numbers of clusters...\\n\")\n",
        "for (k in 2:max_k) {\n",
        "  cat(\"k =\", k, \"\\n\")\n",
        "  # Run k-means with multiple random starts to find best solution\n",
        "  km <- kmeans(X_scaled, centers = k, nstart = 25)\n",
        "  \n",
        "  # Calculate silhouette score (measures cluster quality)\n",
        "  ss <- silhouette(km$cluster, dist(X_scaled))\n",
        "  silhouette_scores[k-1] <- mean(ss[, 3])\n",
        "  \n",
        "  # Store WCSS (within-cluster sum of squares)\n",
        "  wcss[k-1] <- km$tot.withinss\n",
        "  \n",
        "  # Save cluster labels for later visualization\n",
        "  labels_list[[as.character(k)]] <- km$cluster\n",
        "}\n",
        "\n",
        "# Display results table\n",
        "results_table <- tibble(Clusters = 2:max_k, \n",
        "                       Silhouette = round(silhouette_scores, 3), \n",
        "                       WCSS = round(wcss, 1))\n",
        "print(results_table)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize clusters in 2D using the first two principal components\n",
        "# This helps us see how well the clusters separate in the most important dimensions\n",
        "\n",
        "pca_scores <- as_tibble(pca$x[, 1:2])  # Get first two principal components\n",
        "plots <- list()\n",
        "\n",
        "# Create a separate plot for each value of k\n",
        "for (k in 2:max_k) {\n",
        "  clust <- as.factor(labels_list[[as.character(k)]])\n",
        "  plots[[k-1]] <- ggplot(pca_scores, aes(x = PC1, y = PC2, color = clust)) +\n",
        "    geom_point(alpha = 0.6, size = 1.5) +\n",
        "    labs(title = paste('k =', k, 'clusters'), \n",
        "         color = 'Cluster',\n",
        "         x = 'First Principal Component',\n",
        "         y = 'Second Principal Component') +\n",
        "    theme_minimal() +\n",
        "    theme(legend.position = 'bottom')\n",
        "}\n",
        "\n",
        "# Arrange all plots in a grid for easy comparison\n",
        "do.call(grid.arrange, c(plots, ncol = 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Elbow and Silhouette Plots\n",
        "\n",
        "Choose the optimal number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create elbow plot to help choose optimal number of clusters\n",
        "# - Silhouette score: higher is better (blue line)\n",
        "# - WCSS: look for \"elbow\" where improvement slows down (red line)\n",
        "\n",
        "elbow_df <- tibble(Clusters = 2:max_k, Silhouette = silhouette_scores, WCSS = wcss)\n",
        "\n",
        "# Create dual-axis plot (this is complex but shows both metrics together)\n",
        "ggplot(elbow_df, aes(x = Clusters)) +\n",
        "  # Silhouette score (blue line) - higher is better\n",
        "  geom_line(aes(y = Silhouette), color = 'blue', size = 1) +\n",
        "  geom_point(aes(y = Silhouette), color = 'blue', size = 3) +\n",
        "  # WCSS (red line, rescaled) - look for elbow\n",
        "  geom_line(aes(y = rescale(WCSS, to = range(Silhouette))), color = 'red', size = 1) +\n",
        "  geom_point(aes(y = rescale(WCSS, to = range(Silhouette))), color = 'red', size = 3) +\n",
        "  scale_y_continuous(\n",
        "    name = 'Silhouette Score (Blue)',\n",
        "    sec.axis = sec_axis(~ rescale(., from = range(elbow_df$Silhouette), to = range(elbow_df$WCSS)), \n",
        "                       name = 'WCSS (Red)', labels = comma)\n",
        "  ) +\n",
        "  labs(x = 'Number of Clusters',\n",
        "       title = 'Cluster Evaluation: Silhouette Score vs WCSS',\n",
        "       subtitle = 'Higher silhouette is better; look for WCSS elbow') +\n",
        "  theme_minimal() +\n",
        "  theme(axis.title.y.left = element_text(color = 'blue'),\n",
        "        axis.title.y.right = element_text(color = 'red'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Cluster Feature Distributions\n",
        "\n",
        "Pick k = 3 for illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect how features differ between clusters\n",
        "# This helps us understand what makes each cluster unique\n",
        "\n",
        "chosen_k <- 3  # Choose k=3 based on the evaluation above\n",
        "cat(\"Analyzing clusters for k =\", chosen_k, \"\\n\")\n",
        "\n",
        "cluster_labels <- labels_list[[as.character(chosen_k)]]\n",
        "X_labeled <- X_scaled %>% as_tibble() %>% mutate(cluster = factor(cluster_labels))\n",
        "\n",
        "# Show cluster sizes\n",
        "cat(\"Cluster sizes:\\n\")\n",
        "print(table(cluster_labels))\n",
        "\n",
        "# Reshape data for plotting density curves\n",
        "X_long <- X_labeled %>%\n",
        "  pivot_longer(-cluster, names_to = 'variable', values_to = 'value')\n",
        "\n",
        "# Create density plots showing how each feature differs between clusters\n",
        "# Each panel shows one financial ratio, with different colors for each cluster\n",
        "ggplot(X_long, aes(x = value, fill = cluster)) +\n",
        "  geom_density(alpha = 0.4) +  # Semi-transparent density curves\n",
        "  facet_wrap(~ variable, scales = 'free', ncol = 2) +  # Separate panel per feature\n",
        "  labs(title = 'Feature Distributions by Cluster', \n",
        "       subtitle = 'Each panel shows how one financial ratio differs between clusters',\n",
        "       x = 'Standardized Value', \n",
        "       y = 'Density',\n",
        "       fill = 'Cluster') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Learning: Logistic Regression\n",
        "\n",
        "Compare a model trained on the full dataset vs. one per cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Balance the dataset for supervised learning\n",
        "# Many real-world datasets have imbalanced classes (more non-defaults than defaults)\n",
        "# We'll undersample the majority class to create a balanced dataset\n",
        "\n",
        "library(rsample)  # For data splitting\n",
        "library(recipes)  # For data preprocessing\n",
        "\n",
        "dataset_o$status <- as.factor(dataset_o$status)  # Convert to factor for classification\n",
        "\n",
        "# Separate majority and minority classes\n",
        "minority <- dataset_o %>% filter(status == 1)  # Defaults (usually fewer)\n",
        "majority <- dataset_o %>% filter(status == 0)  # Non-defaults (usually more)\n",
        "\n",
        "cat(\"Original class distribution:\\n\")\n",
        "print(table(dataset_o$status))\n",
        "\n",
        "# Undersample majority class to balance the dataset\n",
        "set_size <- nrow(minority) * 2  # Take 2x minority class size from majority\n",
        "majority_down <- majority %>% sample_n(min(set_size, nrow(majority)))\n",
        "balanced <- bind_rows(minority, majority_down)\n",
        "balanced <- balanced %>% sample_frac(1)  # Shuffle the combined dataset\n",
        "\n",
        "cat(\"\\nBalanced class distribution:\\n\")\n",
        "print(table(balanced$status))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split data into training and testing sets\n",
        "# Training set: used to build the model\n",
        "# Testing set: used to evaluate model performance on unseen data\n",
        "\n",
        "set.seed(42)  # For reproducible splits\n",
        "# Use stratified sampling to maintain class balance in both sets\n",
        "split <- initial_split(balanced, prop = 0.8, strata = status)\n",
        "train <- training(split)  # 80% for training\n",
        "test <- testing(split)    # 20% for testing\n",
        "\n",
        "cat(\"Training set size:\", nrow(train), \"\\n\")\n",
        "cat(\"Testing set size:\", nrow(test), \"\\n\")\n",
        "\n",
        "# Create preprocessing recipe\n",
        "# This standardizes features (mean=0, sd=1) using training data statistics\n",
        "rec <- recipe(status ~ ., data = train) %>%\n",
        "  step_center(all_predictors()) %>%  # Subtract mean\n",
        "  step_scale(all_predictors()) %>%   # Divide by standard deviation\n",
        "  prep()  # Calculate the preprocessing parameters\n",
        "\n",
        "# Apply preprocessing to both training and testing sets\n",
        "X_train <- bake(rec, new_data = train) %>% select(-status)\n",
        "y_train <- train$status\n",
        "X_test <- bake(rec, new_data = test) %>% select(-status)\n",
        "y_test <- test$status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit logistic regression model\n",
        "# Logistic regression predicts the probability of default (status = 1)\n",
        "# It uses a logistic function to map any real number to a probability (0-1)\n",
        "\n",
        "model <- glm(status ~ ., data = cbind(X_train, status = y_train), family = binomial())\n",
        "\n",
        "cat(\"Logistic Regression Model Summary:\\n\")\n",
        "cat(\"=====================================\\n\")\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Make predictions and evaluate model performance\n",
        "# The model outputs probabilities, which we convert to class predictions\n",
        "\n",
        "# Get predicted probabilities of default\n",
        "pred_probs <- predict(model, newdata = X_test, type = 'response')\n",
        "\n",
        "# Convert probabilities to class predictions using 0.5 threshold\n",
        "pred_class <- ifelse(pred_probs > 0.5, 1, 0)\n",
        "\n",
        "# Create confusion matrix to see prediction accuracy\n",
        "conf_mat <- table(Predicted = pred_class, Actual = as.numeric(as.character(y_test)))\n",
        "cat(\"Confusion Matrix:\\n\")\n",
        "cat(\"(Rows = Predicted, Columns = Actual)\\n\")\n",
        "print(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Detailed classification metrics\n",
        "# This provides precision, recall, F1-score, and other important metrics\n",
        "cat(\"\\nDetailed Classification Report:\\n\")\n",
        "cat(\"==============================\\n\")\n",
        "caret::confusionMatrix(as.factor(pred_class), y_test, positive = '1')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ROC Curve and AUC Score\n",
        "# ROC curve shows trade-off between true positive rate and false positive rate\n",
        "# AUC (Area Under Curve) summarizes performance: 1.0 = perfect, 0.5 = random\n",
        "\n",
        "roc_obj <- roc(as.numeric(as.character(y_test)), pred_probs)\n",
        "plot(roc_obj, col = 'blue', main = 'ROC Curve (Full Dataset)', \n",
        "     xlab = 'False Positive Rate (1 - Specificity)',\n",
        "     ylab = 'True Positive Rate (Sensitivity)')\n",
        "# Add diagonal line for reference (random classifier)\n",
        "abline(a = 0, b = 1, lty = 2, col = 'gray')\n",
        "\n",
        "auc_score <- auc(roc_obj)\n",
        "cat(\"\\nAUC Score:\", round(auc_score, 3), \"\\n\")\n",
        "cat(\"(1.0 = perfect classifier, 0.5 = random guessing)\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Per-Cluster Logistic Regression\n",
        "\n",
        "Repeat the above for each cluster (example for cluster 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build separate logistic regression models for each cluster\n",
        "# Hypothesis: Companies in different clusters might have different default patterns\n",
        "# This allows us to create specialized models for each group\n",
        "\n",
        "cat(\"Building cluster-specific models...\\n\")\n",
        "cat(\"===================================\\n\")\n",
        "\n",
        "for (cl in 1:chosen_k) {\n",
        "  cat('\\n--- CLUSTER', cl, '---\\n')\n",
        "  \n",
        "  # Get data for this cluster only\n",
        "  idx <- which(cluster_labels == cl)\n",
        "  cluster_data <- dataset_o[idx, ]\n",
        "  cluster_data$status <- as.factor(cluster_data$status)\n",
        "  \n",
        "  cat('Cluster size:', nrow(cluster_data), 'companies\\n')\n",
        "  \n",
        "  # Check if we have enough data for both classes\n",
        "  minority <- cluster_data %>% filter(status == 1)\n",
        "  majority <- cluster_data %>% filter(status == 0)\n",
        "  \n",
        "  cat('Defaults:', nrow(minority), ', Non-defaults:', nrow(majority), '\\n')\n",
        "  \n",
        "  if (nrow(minority) < 5 | nrow(majority) < 5) {\n",
        "    cat('Too few samples in one class, skipping this cluster\\n')\n",
        "    next\n",
        "  }\n",
        "  \n",
        "  # Balance the cluster data\n",
        "  set_size <- nrow(minority) * 2\n",
        "  majority_down <- majority %>% sample_n(min(set_size, nrow(majority)))\n",
        "  balanced <- bind_rows(minority, majority_down) %>% sample_frac(1)\n",
        "  \n",
        "  # Split and preprocess\n",
        "  split <- initial_split(balanced, prop = 0.8, strata = status)\n",
        "  train <- training(split)\n",
        "  test <- testing(split)\n",
        "  \n",
        "  # Standardize features\n",
        "  rec <- recipe(status ~ ., data = train) %>%\n",
        "    step_center(all_predictors()) %>%\n",
        "    step_scale(all_predictors()) %>%\n",
        "    prep()\n",
        "  \n",
        "  X_train <- bake(rec, new_data = train) %>% select(-status)\n",
        "  y_train <- train$status\n",
        "  X_test <- bake(rec, new_data = test) %>% select(-status)\n",
        "  y_test <- test$status\n",
        "  \n",
        "  # Fit cluster-specific model\n",
        "  model <- glm(status ~ ., data = cbind(X_train, status = y_train), family = binomial())\n",
        "  \n",
        "  # Make predictions\n",
        "  pred_probs <- predict(model, newdata = X_test, type = 'response')\n",
        "  pred_class <- ifelse(pred_probs > 0.5, 1, 0)\n",
        "  \n",
        "  # Evaluate performance\n",
        "  conf_mat <- table(Predicted = pred_class, Actual = as.numeric(as.character(y_test)))\n",
        "  cat('Confusion Matrix:\\n')\n",
        "  print(conf_mat)\n",
        "  \n",
        "  cat('\\nDetailed Metrics:\\n')\n",
        "  print(caret::confusionMatrix(as.factor(pred_class), y_test, positive = '1'))\n",
        "  \n",
        "  # ROC curve\n",
        "  roc_obj <- roc(as.numeric(as.character(y_test)), pred_probs)\n",
        "  plot(roc_obj, col = 'red', main = paste('ROC Curve (Cluster', cl, ')'),\n",
        "       xlab = 'False Positive Rate', ylab = 'True Positive Rate')\n",
        "  abline(a = 0, b = 1, lty = 2, col = 'gray')\n",
        "  \n",
        "  auc_score <- auc(roc_obj)\n",
        "  cat('AUC Score:', round(auc_score, 3), '\\n')\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete machine learning workflow combining:\n",
        "\n",
        "1. **Unsupervised Learning (Clustering)**: We used k-means to identify groups of similar companies based on their financial ratios\n",
        "2. **Supervised Learning (Classification)**: We built logistic regression models to predict loan defaults\n",
        "\n",
        "**Key Insights:**\n",
        "- Clustering helps identify distinct company profiles in the financial data\n",
        "- Cluster-specific models may perform differently than a single global model\n",
        "- The combination of clustering and classification can provide both interpretability and predictive power\n",
        "\n",
        "**R Programming Notes:**\n",
        "- All code uses tidyverse and modern R best practices\n",
        "- The workflow closely parallels Python implementations for easy comparison\n",
        "- Comments explain both the statistical concepts and R-specific syntax\n",
        "\n",
        "This approach is valuable in finance for risk assessment, where different types of companies may have different risk profiles that warrant specialized models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
