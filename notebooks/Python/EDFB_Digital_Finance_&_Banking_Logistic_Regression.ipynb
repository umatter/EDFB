{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEL8RD9uMQt"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/umatter/EDFB/blob/main/notebooks/Python/EDFB_Digital_Finance_%26_Banking_Logistic_Regression.ipynb)\n",
        "\n",
        "# EDFB - Digital Finance & Banking - Logistic Regression\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates how to train and evaluate a logistic regression classifier in Python. It is prepared for GitHub + Colab sharing: the first code cell bootstraps exact dependencies, and the dataset is loaded from the repo (or downloaded) so it runs end-to-end without manual uploads.\n",
        "\n",
        "Tested on: Colab Python 3.10, Ubuntu 22.04\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT1tRxsjuDXq"
      },
      "outputs": [],
      "source": [
        "# @title Setup (installs exact versions; safe to rerun)\n",
        "import sys\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install \"numpy>=2.0.0,<2.1.0\" pandas==2.2.2 \"scikit-learn>=1.6.0\" matplotlib==3.9.0 seaborn==0.13.2\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import io\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "%matplotlib inline\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Loaded versions:')\n",
        "print('- numpy', np.__version__)\n",
        "print('- pandas', pd.__version__)\n",
        "import sklearn, matplotlib\n",
        "print('- scikit-learn', sklearn.__version__)\n",
        "print('- matplotlib', matplotlib.__version__)\n",
        "print('- seaborn', sns.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSS2APamuO32"
      },
      "outputs": [],
      "source": [
        "# To make this notebook's output stable across runs (we make the output reproducable)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "collapsed": true,
        "id": "bPsaJ-cluP2X",
        "outputId": "51c80726-98f2-4bd8-8bdf-9eb466011bb7"
      },
      "outputs": [],
      "source": [
        "# Load dataset 'banking.csv' from repo if available; otherwise download\n",
        "data_path = Path(\"data/banking.csv\")\n",
        "data_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "if data_path.exists():\n",
        "    print(\"Loading data from\", data_path)\n",
        "    dataset = pd.read_csv(data_path)\n",
        "else:\n",
        "    url = \"https://raw.githubusercontent.com/umatter/EDFB/main/data/banking.csv\"\n",
        "    try:\n",
        "        print(\"Attempting to download banking.csv from\", url)\n",
        "        urllib.request.urlretrieve(url, data_path)\n",
        "        dataset = pd.read_csv(data_path)\n",
        "        print(\"Downloaded to\", data_path)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Could not obtain banking.csv: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf_QsBcBuRCR"
      },
      "outputs": [],
      "source": [
        "# Data is loaded into `dataset` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N6GHSsdJuTlI",
        "outputId": "d07ee88c-2c8d-49b7-93e5-19b5b6a6d016"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "sJuw_a-ouV5a",
        "outputId": "cb4ef07e-d25a-46d9-80ff-9f098c23cdc2"
      },
      "outputs": [],
      "source": [
        "dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz52USwauXU5"
      },
      "outputs": [],
      "source": [
        "# Define set of numerical and categorical variables\n",
        "num_var = dataset.drop(columns=['y']).select_dtypes([np.number]).columns\n",
        "cat_var = dataset.drop(columns=['y']).select_dtypes(include=object).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okZOkGVYuXwT",
        "outputId": "83ead278-54b1-4cdf-f532-b85acbcbb3cf"
      },
      "outputs": [],
      "source": [
        "num_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcFf9r-muZ_j",
        "outputId": "0bdebc4a-bf5d-4588-db5f-1de31366ddcd"
      },
      "outputs": [],
      "source": [
        "cat_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "yKcy8Bkoua86",
        "outputId": "d1757815-939b-4741-872c-84373d5d4f85"
      },
      "outputs": [],
      "source": [
        "# Check NAs\n",
        "dataset.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fq-JZbVnucLU",
        "outputId": "c6d26a1b-f0f7-44ee-e632-4adadf2343a4"
      },
      "outputs": [],
      "source": [
        "# Get basic statistics for numerical variables\n",
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "OZ7BbXJLuesK",
        "outputId": "09f2dd49-6e9a-4951-fbc8-78b31b9a1f21"
      },
      "outputs": [],
      "source": [
        "# Check dispersion with box plot\n",
        "from sklearn import preprocessing\n",
        "def box_plot(df, standardize=True):\n",
        "\n",
        "    fig=plt.figure(figsize=(20,10))\n",
        "\n",
        "    if standardize==True:\n",
        "        # standardize columns for better visualization\n",
        "        df=pd.DataFrame(preprocessing.StandardScaler().fit_transform(df.values), columns = df.columns)\n",
        "    fig=sns.boxplot(x='value', y='variable', data=pd.melt(df.reset_index(), id_vars='index', value_vars=list(df.columns)),\n",
        "               orient='h')\n",
        "    fig.tick_params(labelsize=10)\n",
        "    fig.set_xlabel('')\n",
        "    fig.set_ylabel('')\n",
        "    fig.set_title('Note that variables are standardized\\nfor better visualization', fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "box_plot(dataset[num_var], standardize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81acPfUVugJC"
      },
      "outputs": [],
      "source": [
        "# We remove duration, pdays and previous\n",
        "dataset=dataset.drop(columns=['duration', 'pdays', 'age', 'campaign', 'previous'])\n",
        "num_var= dataset.drop(columns=['y']).select_dtypes([np.number]).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "0clA5hdPuiPi",
        "outputId": "a4c4a4d2-b1b5-477e-83d8-6da109f87153"
      },
      "outputs": [],
      "source": [
        "# Check distribution for target variable\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.catplot(x='y', kind=\"count\", data=dataset) # categorical plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvR5c-y1ujyK",
        "outputId": "f33d4a25-ede4-47ff-8a53-e3cc6f2828a1"
      },
      "outputs": [],
      "source": [
        "# Dataset is very unbalanced so we remove some observation for y=0 to be equal to 2*size of y=1.\n",
        "# This is called \"undersampling\"\n",
        "\n",
        "# We keep all y=1\n",
        "from sklearn.model_selection import train_test_split\n",
        "data_1 = dataset[dataset['y'] == 1]\n",
        "print(data_1.shape)\n",
        "\n",
        "# We take y=0 as double the size of data_1\n",
        "# Moreover we \"stratify\" the sampling in order to take the same distribution for each variable\n",
        "# We use the train_test_split function and we keep the test only\n",
        "all_data_0 = dataset[dataset['y'] == 0]\n",
        "percentage_corresponding_to_double_size = 2*data_1.shape[0] / all_data_0.shape[0] # 2*size_1 compared to size_0\n",
        "\n",
        "X = all_data_0.drop(columns=['y'])\n",
        "y = all_data_0['y'].to_frame()\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "data_0_big, data_0_small = train_test_split(all_data_0, test_size=percentage_corresponding_to_double_size,\n",
        "                                                    random_state=0, shuffle=True)\n",
        "print(data_0_big.shape) # remaining from the dataset\n",
        "print(data_0_small.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEqxjEViulhA",
        "outputId": "00fd5182-593f-498d-b4bb-1c87007e7243"
      },
      "outputs": [],
      "source": [
        "# Merge two dataset\n",
        "\n",
        "dataset=pd.concat([data_1, data_0_small], axis= 0).reset_index(drop=True)  # axis = 1 by column and = 0 by row\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "rHVZJ2X1umgk",
        "outputId": "70333985-8c6d-424c-c245-389c8ce5b552"
      },
      "outputs": [],
      "source": [
        "# Check distribution for target variable after downsampling\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.catplot(x='y', kind=\"count\", data=dataset)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G52xWXIq9eEB",
        "outputId": "5ef90309-03fc-4d9d-c0f1-90414a8d1e49"
      },
      "outputs": [],
      "source": [
        "# Plot the distribution and the boxplot of the numerical variables included in the dataset compared to the target (it's only 0 or 1)\n",
        "\n",
        "fig = plt.figure(figsize=(15,30))\n",
        "plot_count=1\n",
        "\n",
        "# scale variable for better visualizing boxplot\n",
        "dataset_scaled=pd.DataFrame(preprocessing.StandardScaler().fit_transform(dataset[num_var].values),columns = num_var)\n",
        "dataset_scaled['y']=dataset['y'].astype(str)\n",
        "y_1 = dataset.loc[dataset['y'] == 1] #.loc - access group of values using labels.\n",
        "y_0 = dataset.loc[dataset['y'] == 0]\n",
        "\n",
        "for var in num_var:\n",
        "    # plot variable distribution\n",
        "    ax = fig.add_subplot(math.ceil(len(num_var) / 2), 2, plot_count)\n",
        "    sns.distplot(y_1[var], label='1', ax=ax)\n",
        "    sns.distplot(y_0[var], label='0', ax=ax)\n",
        "    ax.set_title('Distribution of ' + var, fontsize=20)\n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xlabel('')\n",
        "    ax.legend(fontsize=16)\n",
        "    plot_count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UxWxnfJVuqXY",
        "outputId": "50b73438-18c3-44ed-bc72-cb12776931ce"
      },
      "outputs": [],
      "source": [
        "# Check the distribution of the levels of the categorical variables compared with the target\n",
        "\n",
        "fig = plt.figure(figsize=(15,30))\n",
        "plot_count=1\n",
        "\n",
        "for var in cat_var:\n",
        "    # plot variable distribution\n",
        "    ax = fig.add_subplot(math.ceil(len(cat_var) / 2), 2, plot_count)\n",
        "    plot_set = dataset.groupby([var, 'y']).size().reset_index().pivot(columns='y', index=var, values=0)\n",
        "    plot_set=plot_set.div(plot_set.sum(axis=1), axis=0).plot(kind='barh', stacked=True, ax=ax)\n",
        "    ax.set_title('Target variable distribution for each\\nlevel (' + str(len(dataset[var].unique())) +\n",
        "                 ') of ' + var, fontsize=20)\n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_ylabel('')\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize=16)\n",
        "    plot_count += 1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SLly_nOSusI4",
        "outputId": "3a301e01-4f1c-4208-e974-d06808c57872"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPFz8OxduupH"
      },
      "outputs": [],
      "source": [
        "# Create dummy variables & standardize the dataset\n",
        "dataset_dummy=pd.get_dummies(dataset.copy(), dummy_na=False, drop_first=True) # Whether to get k-1 dummies out of k categorical levels by removing the first level.\n",
        "dataset_dummy[num_var]=pd.DataFrame(preprocessing.StandardScaler().fit_transform(dataset[num_var].values),columns = num_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "dHA8jonwuvoP",
        "outputId": "dca486e4-fdad-425e-b945-56b857357487"
      },
      "outputs": [],
      "source": [
        "dataset_dummy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLB5Qn78uwsf"
      },
      "outputs": [],
      "source": [
        "# Check the correlations between variables\n",
        "corrmat = dataset_dummy.corr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "w8VyCv_b_YWN",
        "outputId": "8ba66e3e-2765-46a2-800f-6d281c3a6769"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix in key-values pairs\n",
        "corrmat *= np.where(np.tri(*corrmat.shape, k=-1)==0, np.nan, 1)  # puts NaN on upper triangular matrix, including diagonal (k=-1)\n",
        "corrmat_list=corrmat.unstack().to_frame()\n",
        "\n",
        "# Check highest correlations\n",
        "corrmat_list.columns=['correlation']\n",
        "corrmat_list['abs_corr']=corrmat_list.correlation.abs()\n",
        "corrmat_list.sort_values(by=['abs_corr'], ascending=False, na_position='last', inplace=True)\n",
        "corrmat_list.drop(columns=['abs_corr']).head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-X_0GJ9Nu6t5",
        "outputId": "f0903ad9-5799-4647-ee64-9bd209981889"
      },
      "outputs": [],
      "source": [
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(corrmat, cmap =\"YlGnBu\", linewidths = 0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWGR2m3u9LB"
      },
      "outputs": [],
      "source": [
        "# Drop highly correlated columns\n",
        "dataset_original=dataset.copy() # save original dataset\n",
        "\n",
        "# Rename dataset_dummy and drop columns\n",
        "col_to_drop=['emp_var_rate', 'cons_price_idx', 'euribor3m', 'nr_employed', 'loan_unknown', 'housing_unknown']\n",
        "dataset=dataset_dummy.drop(columns=col_to_drop)\n",
        "num_var=dataset.columns.intersection(num_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUhL0Zxc_52q",
        "outputId": "f387cb7f-409c-45c5-ad8e-d0010a903d0b"
      },
      "outputs": [],
      "source": [
        "# Ready to train and test our clasifer!\n",
        "X = dataset.drop(columns=['y'])\n",
        "y = dataset['y'].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pomfgiFvAEN",
        "outputId": "1da13ff2-1dd7-425e-96fe-793f0011db5b"
      },
      "outputs": [],
      "source": [
        "# Split train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=dataset['y'])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "2G3NZ2MwA8bp",
        "outputId": "72b4bd6b-6828-422b-fe95-2fd52b4ba7a2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='lbfgs', random_state=0) # solver (https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451)\n",
        "model.fit(X_train, y_train) # training the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "1KUIl-tCwAA4",
        "outputId": "f2174fbe-f0a2-4e57-c257-678002d25152"
      },
      "outputs": [],
      "source": [
        "# Get fitted value on test set\n",
        "y_test_predicted = model.predict(X_test)\n",
        "\n",
        "# Compare predictions\n",
        "display(pd.DataFrame({'True': y_test.flatten(), 'Predicted': y_test_predicted.flatten()}))\n",
        "\n",
        "# Compare predicted probabilities (default threshold for converting to 0 or 1 is 0.5)\n",
        "y_test_predicted_prob = model.predict_proba(X_test)[:,1]\n",
        "display(pd.DataFrame({'True': y_test.flatten(), 'Predicted_prob': y_test_predicted_prob.flatten(), 'Predicted': y_test_predicted.flatten()}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekdOKief53Zp",
        "outputId": "226da415-725d-4152-f422-c68639834bd5"
      },
      "outputs": [],
      "source": [
        "# Evaluate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_test_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "4eWqDpCfxGXl",
        "outputId": "30563949-f9e9-4677-b802-9355d32e18d8"
      },
      "outputs": [],
      "source": [
        "# Evaluate confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = ['0', '1']\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_test_predicted)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUm4fOFtxPxB",
        "outputId": "46b8400d-73d9-467e-9f1e-a777b66d6e16"
      },
      "outputs": [],
      "source": [
        "# Evaluate precision, recall, F1-score on train set\n",
        "# A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally),\n",
        "# whereas a micro-average will aggregate the contributions of all classes to compute the average metric.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_test_predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0VacNokWxQU1",
        "outputId": "4e320dc4-300c-471a-9a73-bff023f9720a"
      },
      "outputs": [],
      "source": [
        "# Evaluate ROC curve\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y_test, y_test_predicted)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_predicted_prob)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
