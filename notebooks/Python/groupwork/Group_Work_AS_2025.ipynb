{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Work AS 2025: ESG Investment Analysis and ML Portfolio Optimization\n",
    "\n",
    "This notebook provides the data analysis and machine learning implementation for the Group Work AS 2025 assignment. \n",
    "\n",
    "**For complete assignment details, deliverables, and requirements, please refer to the [Group Assignment PDF](https://github.com/umatter/EDFB/blob/main/_groupwork_dev/prev_groupwork/groupwork_AS_2025/Group_assignment_AS_2025.pdf).**\n",
    "\n",
    "## Dataset Details:\n",
    "- **Source**: ESG & Financial Performance Dataset by Shriyash Jagtap (Kaggle)\n",
    "- **License**: Creative Commons Attribution 4.0 International (CC BY 4.0)\n",
    "- **Original URL**: https://www.kaggle.com/datasets/shriyashjagtap/esg-and-financial-performance-dataset\n",
    "- **Size**: 11,000 observations across 1,000 companies (2015-2025)\n",
    "- **Variables**: Company info, financial metrics, ESG scores, environmental impact data\n",
    "- **Format**: CSV file loaded directly from GitHub repository\n",
    "\n",
    "## Instructions:\n",
    "1. Make a copy of this notebook (File → Save a copy in Drive)\n",
    "2. Run each cell sequentially\n",
    "3. The dataset is automatically loaded from the GitHub repository\n",
    "4. Use the analysis results for your written report and presentation\n",
    "5. Submit the completed notebook along with your other deliverables\n",
    "\n",
    "**Important**: This notebook uses real ESG data under CC BY 4.0 license. Please maintain proper attribution in your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Portfolio optimization\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ESG dataset from GitHub repository\n",
    "# Dataset: ESG & Financial Performance Dataset by Shriyash Jagtap\n",
    "# Source: https://www.kaggle.com/datasets/shriyashjagtap/esg-and-financial-performance-dataset\n",
    "# License: CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "print(\"Loading ESG & Financial Performance Dataset...\")\n",
    "print(\"Dataset Attribution:\")\n",
    "print(\"- Author: Shriyash Jagtap\")\n",
    "print(\"- License: Creative Commons Attribution 4.0 International (CC BY 4.0)\")\n",
    "print(\"- Source: https://www.kaggle.com/datasets/shriyashjagtap/esg-and-financial-performance-dataset\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Load data directly from GitHub repository\n",
    "github_data_url = \"https://raw.githubusercontent.com/umatter/EDFB/main/data/company_esg_financial_dataset.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    esg_data = pd.read_csv(github_data_url)\n",
    "    \n",
    "    # Rename columns to match the expected format in the rest of the notebook\n",
    "    column_mapping = {\n",
    "        'CompanyID': 'Company_ID',\n",
    "        'CompanyName': 'Company_Name', \n",
    "        'GrowthRate': 'Growth_Rate',\n",
    "        'ESG_Overall': 'ESG_Score',\n",
    "        'ESG_Environmental': 'Environmental_Score',\n",
    "        'ESG_Social': 'Social_Score',\n",
    "        'ESG_Governance': 'Governance_Score',\n",
    "        'ProfitMargin': 'Profit_Margin',\n",
    "        'MarketCap': 'Market_Cap',\n",
    "        'CarbonEmissions': 'Carbon_Emissions',\n",
    "        'WaterUsage': 'Water_Usage',\n",
    "        'EnergyConsumption': 'Energy_Consumption'\n",
    "    }\n",
    "    \n",
    "    esg_data = esg_data.rename(columns=column_mapping)\n",
    "    \n",
    "    # Handle missing values in Growth_Rate column (first year for each company)\n",
    "    esg_data['Growth_Rate'] = esg_data['Growth_Rate'].fillna(0)\n",
    "    \n",
    "    print(f\"✓ Dataset loaded successfully!\")\n",
    "    print(f\"✓ {len(esg_data):,} observations\")\n",
    "    print(f\"✓ {esg_data['Company_Name'].nunique():,} companies\")  \n",
    "    print(f\"✓ Time period: {esg_data['Year'].min()}-{esg_data['Year'].max()}\")\n",
    "    print(f\"✓ Industries: {esg_data['Industry'].nunique()}\")\n",
    "    print(f\"✓ Regions: {esg_data['Region'].nunique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading dataset: {e}\")\n",
    "    print(\"\\nFallback: Creating sample dataset for demonstration...\")\n",
    "    \n",
    "    # Fallback to sample data if GitHub load fails\n",
    "    sample_data = {\n",
    "        'Company_ID': [1, 1, 2, 2],\n",
    "        'Company_Name': ['Company_1', 'Company_1', 'Company_2', 'Company_2'],\n",
    "        'Industry': ['Technology', 'Technology', 'Healthcare', 'Healthcare'],\n",
    "        'Region': ['North America', 'North America', 'Europe', 'Europe'],\n",
    "        'Year': [2023, 2024, 2023, 2024],\n",
    "        'Revenue': [1000, 1100, 800, 850],\n",
    "        'Profit_Margin': [15.5, 16.2, 12.8, 13.1],\n",
    "        'Market_Cap': [5000, 5500, 4000, 4200],\n",
    "        'Growth_Rate': [10.0, 8.5, 6.2, 7.1],\n",
    "        'ESG_Score': [75.2, 76.8, 68.5, 69.9],\n",
    "        'Environmental_Score': [78.1, 79.2, 65.3, 67.1],\n",
    "        'Social_Score': [72.8, 74.5, 71.2, 72.8],\n",
    "        'Governance_Score': [74.9, 76.7, 69.0, 69.4],\n",
    "        'Carbon_Emissions': [25000, 24000, 28000, 27500],\n",
    "        'Water_Usage': [15000, 14500, 18000, 17800],\n",
    "        'Energy_Consumption': [45000, 44000, 50000, 49500]\n",
    "    }\n",
    "    esg_data = pd.DataFrame(sample_data)\n",
    "    print(\"Sample dataset created for testing purposes.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "esg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset dimensions and basic info\n",
    "print(\"Dataset Shape:\", esg_data.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(esg_data.dtypes)\n",
    "print(\"\\nBasic Information:\")\n",
    "esg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = esg_data.isnull().sum()\n",
    "print(\"Missing Values per Column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "esg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis by industry and region\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Industry distribution\n",
    "industry_counts = esg_data['Industry'].value_counts()\n",
    "axes[0, 0].pie(industry_counts.values, labels=industry_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Distribution by Industry')\n",
    "\n",
    "# Region distribution\n",
    "region_counts = esg_data['Region'].value_counts()\n",
    "axes[0, 1].pie(region_counts.values, labels=region_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 1].set_title('Distribution by Region')\n",
    "\n",
    "# ESG Score distribution\n",
    "axes[1, 0].hist(esg_data['ESG_Score'], bins=30, alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Distribution of ESG Scores')\n",
    "axes[1, 0].set_xlabel('ESG Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Year distribution\n",
    "year_counts = esg_data['Year'].value_counts().sort_index()\n",
    "axes[1, 1].bar(year_counts.index, year_counts.values)\n",
    "axes[1, 1].set_title('Distribution by Year')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Number of Companies')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Score components analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG components distribution\n",
    "esg_components = ['Environmental_Score', 'Social_Score', 'Governance_Score']\n",
    "colors = ['green', 'blue', 'orange']\n",
    "\n",
    "for i, (component, color) in enumerate(zip(esg_components, colors)):\n",
    "    if i < 3:\n",
    "        row, col = i // 2, i % 2\n",
    "        axes[row, col].hist(esg_data[component], bins=30, alpha=0.7, color=color, label=component)\n",
    "        axes[row, col].set_title(f'Distribution of {component.replace(\"_\", \" \")}')\n",
    "        axes[row, col].set_xlabel('Score')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "# ESG trend over time\n",
    "esg_trend = esg_data.groupby('Year')['ESG_Score'].mean()\n",
    "axes[1, 1].plot(esg_trend.index, esg_trend.values, marker='o', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_title('Average ESG Score Trend Over Time')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Average ESG Score')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Outlier Detection and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns for outlier analysis\n",
    "numerical_cols = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate', \n",
    "                  'ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score',\n",
    "                  'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']\n",
    "\n",
    "# Box plot visualization for outlier detection\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < len(axes):\n",
    "        # Use log scale for financial and environmental metrics for better visualization\n",
    "        if col in ['Revenue', 'Market_Cap', 'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']:\n",
    "            data_to_plot = np.log1p(esg_data[col])  # log(1+x) to handle zeros\n",
    "            axes[i].set_ylabel(f'Log({col})')\n",
    "        else:\n",
    "            data_to_plot = esg_data[col]\n",
    "            axes[i].set_ylabel(col)\n",
    "        \n",
    "        axes[i].boxplot(data_to_plot, patch_artist=True)\n",
    "        axes[i].set_title(f'Box Plot: {col}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "\n",
    "# Count outliers for each numerical column\n",
    "outlier_counts = {}\n",
    "for col in numerical_cols:\n",
    "    outliers = detect_outliers_iqr(esg_data, col)\n",
    "    outlier_counts[col] = outliers.sum()\n",
    "\n",
    "print(\"Outlier Counts by Column (using IQR method):\")\n",
    "print(\"-\" * 45)\n",
    "for col, count in outlier_counts.items():\n",
    "    percentage = (count / len(esg_data)) * 100\n",
    "    print(f\"{col:20s}: {count:4d} ({percentage:.1f}%)\")\n",
    "\n",
    "total_outliers = sum(outlier_counts.values())\n",
    "print(f\"\\nTotal outlier instances: {total_outliers}\")\n",
    "print(f\"Percentage of dataset with outliers: {(total_outliers / (len(esg_data) * len(numerical_cols))) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned dataset by capping outliers at 95th and 5th percentiles\n",
    "esg_data_clean = esg_data.copy()\n",
    "\n",
    "outlier_treatment_log = {}\n",
    "\n",
    "for col in numerical_cols:\n",
    "    original_outliers = detect_outliers_iqr(esg_data, col).sum()\n",
    "    \n",
    "    # Cap outliers at 5th and 95th percentiles\n",
    "    lower_cap = esg_data[col].quantile(0.05)\n",
    "    upper_cap = esg_data[col].quantile(0.95)\n",
    "    \n",
    "    esg_data_clean[col] = esg_data_clean[col].clip(lower=lower_cap, upper=upper_cap)\n",
    "    \n",
    "    new_outliers = detect_outliers_iqr(esg_data_clean, col).sum()\n",
    "    outlier_treatment_log[col] = {\n",
    "        'original_outliers': original_outliers,\n",
    "        'remaining_outliers': new_outliers,\n",
    "        'reduction': original_outliers - new_outliers\n",
    "    }\n",
    "\n",
    "print(\"Outlier Treatment Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Column':<20} {'Original':<10} {'Remaining':<10} {'Reduced':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for col, stats in outlier_treatment_log.items():\n",
    "    print(f\"{col:<20} {stats['original_outliers']:<10} {stats['remaining_outliers']:<10} {stats['reduction']:<10}\")\n",
    "\n",
    "print(f\"\\nDataset shape after outlier treatment: {esg_data_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for key variables\n",
    "correlation_vars = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate', \n",
    "                   'ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score']\n",
    "\n",
    "correlation_matrix = esg_data_clean[correlation_vars].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlGn', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'},\n",
    "            mask=mask)\n",
    "plt.title('Correlation Matrix: Financial Performance vs ESG Scores', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Correlations with ESG Score:\")\n",
    "print(\"-\" * 35)\n",
    "esg_correlations = correlation_matrix['ESG_Score'].drop('ESG_Score').sort_values(key=abs, ascending=False)\n",
    "for var, corr in esg_correlations.items():\n",
    "    print(f\"{var:<20}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Score vs Financial Performance Scatter Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "financial_metrics = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate']\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(financial_metrics, colors)):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Use log scale for Revenue and Market_Cap for better visualization\n",
    "    if metric in ['Revenue', 'Market_Cap']:\n",
    "        y_data = np.log1p(esg_data_clean[metric])\n",
    "        axes[row, col].set_ylabel(f'Log({metric})')\n",
    "    else:\n",
    "        y_data = esg_data_clean[metric]\n",
    "        axes[row, col].set_ylabel(metric)\n",
    "    \n",
    "    axes[row, col].scatter(esg_data_clean['ESG_Score'], y_data, alpha=0.5, color=color)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(esg_data_clean['ESG_Score'], y_data, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[row, col].plot(esg_data_clean['ESG_Score'], p(esg_data_clean['ESG_Score']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Calculate and display correlation\n",
    "    corr = esg_data_clean['ESG_Score'].corr(y_data)\n",
    "    axes[row, col].set_title(f'ESG Score vs {metric}\\n(Correlation: {corr:.3f})')\n",
    "    axes[row, col].set_xlabel('ESG Score')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry-wise ESG and Financial Performance Analysis\n",
    "industry_analysis = esg_data_clean.groupby('Industry').agg({\n",
    "    'ESG_Score': ['mean', 'std'],\n",
    "    'Revenue': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Growth_Rate': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "industry_analysis.columns = ['_'.join(col).strip() for col in industry_analysis.columns]\n",
    "industry_analysis = industry_analysis.sort_values('ESG_Score_mean', ascending=False)\n",
    "\n",
    "print(\"Industry-wise ESG and Financial Performance:\")\n",
    "print(\"=\" * 80)\n",
    "print(industry_analysis)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG Score by Industry\n",
    "industry_esg = esg_data_clean.groupby('Industry')['ESG_Score'].mean().sort_values(ascending=True)\n",
    "axes[0, 0].barh(industry_esg.index, industry_esg.values, color='green', alpha=0.7)\n",
    "axes[0, 0].set_title('Average ESG Score by Industry')\n",
    "axes[0, 0].set_xlabel('Average ESG Score')\n",
    "\n",
    "# Revenue by Industry\n",
    "industry_revenue = esg_data_clean.groupby('Industry')['Revenue'].mean().sort_values(ascending=True)\n",
    "axes[0, 1].barh(industry_revenue.index, industry_revenue.values / 1e6, color='blue', alpha=0.7)\n",
    "axes[0, 1].set_title('Average Revenue by Industry')\n",
    "axes[0, 1].set_xlabel('Average Revenue (Millions)')\n",
    "\n",
    "# Profit Margin by Industry\n",
    "industry_margin = esg_data_clean.groupby('Industry')['Profit_Margin'].mean().sort_values(ascending=True)\n",
    "axes[1, 0].barh(industry_margin.index, industry_margin.values, color='orange', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Profit Margin by Industry')\n",
    "axes[1, 0].set_xlabel('Average Profit Margin (%)')\n",
    "\n",
    "# Growth Rate by Industry\n",
    "industry_growth = esg_data_clean.groupby('Industry')['Growth_Rate'].mean().sort_values(ascending=True)\n",
    "axes[1, 1].barh(industry_growth.index, industry_growth.values, color='red', alpha=0.7)\n",
    "axes[1, 1].set_title('Average Growth Rate by Industry')\n",
    "axes[1, 1].set_xlabel('Average Growth Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Machine Learning Models for Return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "# We'll predict Growth_Rate (as a proxy for returns) using ESG scores and other features\n",
    "\n",
    "# Encode categorical variables\n",
    "le_industry = LabelEncoder()\n",
    "le_region = LabelEncoder()\n",
    "\n",
    "ml_data = esg_data_clean.copy()\n",
    "ml_data['Industry_encoded'] = le_industry.fit_transform(ml_data['Industry'])\n",
    "ml_data['Region_encoded'] = le_region.fit_transform(ml_data['Region'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "feature_cols = ['ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score',\n",
    "                'Revenue', 'Profit_Margin', 'Market_Cap', 'Year', \n",
    "                'Industry_encoded', 'Region_encoded']\n",
    "\n",
    "X = ml_data[feature_cols]\n",
    "y = ml_data['Growth_Rate']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {feature_cols}\")\n",
    "print(f\"Target: Growth_Rate (as proxy for returns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"Mean: {y.mean():.2f}%\")\n",
    "print(f\"Std: {y.std():.2f}%\")\n",
    "print(f\"Min: {y.min():.2f}%\")\n",
    "print(f\"Max: {y.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple machine learning models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "print(\"Model Training and Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        model.fit(X_train, y_train)  # Tree-based models don't need scaling\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions_train': y_pred_train,\n",
    "        'predictions_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Training R²: {train_r2:.4f}\")\n",
    "    print(f\"  Testing R²:  {test_r2:.4f}\")\n",
    "    print(f\"  Training RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  Testing RMSE:  {test_rmse:.4f}\")\n",
    "    print(f\"  CV R² Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "\n",
    "# Select best model based on test R²\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['test_r2'])\n",
    "best_model = model_results[best_model_name]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"Best Model: {best_model_name} (Test R² = {best_model['test_r2']:.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for Random Forest\n",
    "rf_model = model_results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(\"-\" * 40)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:<20}: {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance['feature'][::-1], feature_importance['importance'][::-1])\n",
    "plt.title('Feature Importance for Growth Rate Prediction (Random Forest)', fontsize=16)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Actual vs Predicted plots for both models\n",
    "for i, (name, results) in enumerate(model_results.items()):\n",
    "    # Training set\n",
    "    axes[i, 0].scatter(y_train, results['predictions_train'], alpha=0.5)\n",
    "    axes[i, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "    axes[i, 0].set_xlabel('Actual Growth Rate (%)')\n",
    "    axes[i, 0].set_ylabel('Predicted Growth Rate (%)')\n",
    "    axes[i, 0].set_title(f'{name} - Training Set\\n(R² = {results[\"train_r2\"]:.4f})')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Testing set\n",
    "    axes[i, 1].scatter(y_test, results['predictions_test'], alpha=0.5, color='orange')\n",
    "    axes[i, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    axes[i, 1].set_xlabel('Actual Growth Rate (%)')\n",
    "    axes[i, 1].set_ylabel('Predicted Growth Rate (%)')\n",
    "    axes[i, 1].set_title(f'{name} - Testing Set\\n(R² = {results[\"test_r2\"]:.4f})')\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Portfolio Optimization with ESG Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio optimization using Modern Portfolio Theory with ESG constraints\n",
    "# We'll create portfolios based on different ESG criteria\n",
    "\n",
    "# Get latest year data for portfolio construction\n",
    "latest_year = esg_data_clean['Year'].max()\n",
    "portfolio_data = esg_data_clean[esg_data_clean['Year'] == latest_year].copy()\n",
    "\n",
    "# Select top companies by different criteria for portfolio construction\n",
    "n_assets = 50  # Number of assets in portfolio\n",
    "\n",
    "# Portfolio 1: Traditional - highest returns (Growth Rate)\n",
    "traditional_portfolio = portfolio_data.nlargest(n_assets, 'Growth_Rate')\n",
    "\n",
    "# Portfolio 2: ESG-focused - highest ESG scores\n",
    "esg_portfolio = portfolio_data.nlargest(n_assets, 'ESG_Score')\n",
    "\n",
    "# Portfolio 3: Balanced - combination of returns and ESG\n",
    "portfolio_data['Combined_Score'] = (0.6 * portfolio_data['Growth_Rate'].rank(pct=True) + \n",
    "                                   0.4 * portfolio_data['ESG_Score'].rank(pct=True))\n",
    "balanced_portfolio = portfolio_data.nlargest(n_assets, 'Combined_Score')\n",
    "\n",
    "portfolios = {\n",
    "    'Traditional': traditional_portfolio,\n",
    "    'ESG-Focused': esg_portfolio,\n",
    "    'Balanced': balanced_portfolio\n",
    "}\n",
    "\n",
    "print(f\"Portfolio Analysis ({latest_year} data, {n_assets} assets each):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "portfolio_stats = {}\n",
    "for name, data in portfolios.items():\n",
    "    stats = {\n",
    "        'avg_return': data['Growth_Rate'].mean(),\n",
    "        'return_std': data['Growth_Rate'].std(),\n",
    "        'avg_esg': data['ESG_Score'].mean(),\n",
    "        'esg_std': data['ESG_Score'].std(),\n",
    "        'avg_revenue': data['Revenue'].mean(),\n",
    "        'avg_margin': data['Profit_Margin'].mean(),\n",
    "        'sharpe_ratio': data['Growth_Rate'].mean() / data['Growth_Rate'].std() if data['Growth_Rate'].std() > 0 else 0\n",
    "    }\n",
    "    portfolio_stats[name] = stats\n",
    "    \n",
    "    print(f\"\\n{name} Portfolio:\")\n",
    "    print(f\"  Average Return: {stats['avg_return']:.2f}% (σ = {stats['return_std']:.2f}%)\")\n",
    "    print(f\"  Average ESG Score: {stats['avg_esg']:.1f} (σ = {stats['esg_std']:.1f})\")\n",
    "    print(f\"  Sharpe Ratio: {stats['sharpe_ratio']:.3f}\")\n",
    "    print(f\"  Average Revenue: ${stats['avg_revenue']/1e6:.1f}M\")\n",
    "    print(f\"  Average Profit Margin: {stats['avg_margin']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Risk-Return scatter plot\n",
    "for name, stats in portfolio_stats.items():\n",
    "    axes[0, 0].scatter(stats['return_std'], stats['avg_return'], \n",
    "                      s=200, alpha=0.7, label=name)\n",
    "    axes[0, 0].annotate(name, (stats['return_std'], stats['avg_return']), \n",
    "                       xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "axes[0, 0].set_xlabel('Risk (Return Std Dev %)')\n",
    "axes[0, 0].set_ylabel('Expected Return (%)')\n",
    "axes[0, 0].set_title('Risk-Return Profile by Portfolio Type')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG vs Return comparison\n",
    "portfolio_names = list(portfolio_stats.keys())\n",
    "esg_scores = [portfolio_stats[p]['avg_esg'] for p in portfolio_names]\n",
    "returns = [portfolio_stats[p]['avg_return'] for p in portfolio_names]\n",
    "\n",
    "axes[0, 1].bar(portfolio_names, esg_scores, alpha=0.7, color='green')\n",
    "axes[0, 1].set_ylabel('Average ESG Score', color='green')\n",
    "axes[0, 1].set_title('ESG Scores by Portfolio Type')\n",
    "axes[0, 1].tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# Create second y-axis for returns\n",
    "ax2 = axes[0, 1].twinx()\n",
    "ax2.plot(portfolio_names, returns, color='red', marker='o', linewidth=2, markersize=8)\n",
    "ax2.set_ylabel('Average Return (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Industry diversification comparison\n",
    "for i, (name, data) in enumerate(portfolios.items()):\n",
    "    industry_dist = data['Industry'].value_counts()\n",
    "    if i == 0:\n",
    "        axes[1, 0].pie(industry_dist.values, labels=industry_dist.index, \n",
    "                      autopct='%1.1f%%', startangle=90)\n",
    "        axes[1, 0].set_title(f'{name} Portfolio - Industry Distribution')\n",
    "    elif i == 1:\n",
    "        axes[1, 1].pie(industry_dist.values, labels=industry_dist.index, \n",
    "                      autopct='%1.1f%%', startangle=90)\n",
    "        axes[1, 1].set_title(f'{name} Portfolio - Industry Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional industry distribution for Balanced portfolio\n",
    "plt.figure(figsize=(10, 8))\n",
    "industry_dist = portfolios['Balanced']['Industry'].value_counts()\n",
    "plt.pie(industry_dist.values, labels=industry_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Balanced Portfolio - Industry Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Frontier calculation (simplified version)\n",
    "# Calculate expected returns and covariance matrix for efficient frontier\n",
    "\n",
    "def calculate_portfolio_metrics(weights, returns, cov_matrix):\n",
    "    portfolio_return = np.sum(weights * returns)\n",
    "    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_return, portfolio_std\n",
    "\n",
    "# Use the traditional portfolio companies for efficient frontier\n",
    "ef_data = traditional_portfolio[['Company_Name', 'Growth_Rate']].set_index('Company_Name')\n",
    "\n",
    "# Simulate historical returns (in reality, you would use actual historical data)\n",
    "n_periods = 12  # 12 months of data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic return series for each company\n",
    "returns_data = pd.DataFrame(index=range(n_periods), columns=ef_data.index)\n",
    "for company in ef_data.index:\n",
    "    expected_return = ef_data.loc[company, 'Growth_Rate'] / 12  # Monthly return\n",
    "    volatility = abs(expected_return) * 0.5  # Assume volatility is 50% of return\n",
    "    returns_data[company] = np.random.normal(expected_return, volatility, n_periods)\n",
    "\n",
    "# Calculate expected returns and covariance matrix\n",
    "expected_returns = returns_data.mean()\n",
    "cov_matrix = returns_data.cov()\n",
    "\n",
    "# Generate random portfolios for efficient frontier\n",
    "n_portfolios = 10000\n",
    "results = np.zeros((3, n_portfolios))\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(n_portfolios):\n",
    "    # Generate random weights\n",
    "    weights = np.random.random(len(expected_returns))\n",
    "    weights /= np.sum(weights)  # Normalize to sum to 1\n",
    "    \n",
    "    # Calculate portfolio metrics\n",
    "    port_return, port_std = calculate_portfolio_metrics(weights, expected_returns, cov_matrix)\n",
    "    \n",
    "    # Store results\n",
    "    results[0, i] = port_return * 12  # Annualize\n",
    "    results[1, i] = port_std * np.sqrt(12)  # Annualize\n",
    "    results[2, i] = results[0, i] / results[1, i]  # Sharpe ratio\n",
    "\n",
    "# Create DataFrame for results\n",
    "ef_results = pd.DataFrame({\n",
    "    'Return': results[0],\n",
    "    'Volatility': results[1], \n",
    "    'Sharpe': results[2]\n",
    "})\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(ef_results['Volatility'], ef_results['Return'], \n",
    "                     c=ef_results['Sharpe'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Sharpe Ratio')\n",
    "\n",
    "# Highlight max Sharpe ratio portfolio\n",
    "max_sharpe_idx = ef_results['Sharpe'].idxmax()\n",
    "plt.scatter(ef_results.loc[max_sharpe_idx, 'Volatility'], \n",
    "           ef_results.loc[max_sharpe_idx, 'Return'], \n",
    "           marker='*', s=500, color='red', label='Max Sharpe Ratio')\n",
    "\n",
    "plt.xlabel('Volatility (%)')\n",
    "plt.ylabel('Expected Return (%)')\n",
    "plt.title('Efficient Frontier - Traditional Portfolio Assets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal Portfolio (Max Sharpe Ratio):\")\n",
    "print(f\"Expected Return: {ef_results.loc[max_sharpe_idx, 'Return']:.2f}%\")\n",
    "print(f\"Volatility: {ef_results.loc[max_sharpe_idx, 'Volatility']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {ef_results.loc[max_sharpe_idx, 'Sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ESG Impact Analysis and Investment Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Impact Analysis\n",
    "# Analyze how ESG scores have evolved over time and their impact on financial performance\n",
    "\n",
    "# ESG score evolution over time\n",
    "esg_evolution = esg_data_clean.groupby('Year').agg({\n",
    "    'ESG_Score': 'mean',\n",
    "    'Environmental_Score': 'mean',\n",
    "    'Social_Score': 'mean', \n",
    "    'Governance_Score': 'mean',\n",
    "    'Growth_Rate': 'mean',\n",
    "    'Profit_Margin': 'mean'\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG component evolution\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['ESG_Score'], marker='o', linewidth=2, label='Overall ESG')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Environmental_Score'], marker='s', linewidth=2, label='Environmental')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Social_Score'], marker='^', linewidth=2, label='Social')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Governance_Score'], marker='d', linewidth=2, label='Governance')\n",
    "axes[0, 0].set_title('ESG Score Evolution Over Time')\n",
    "axes[0, 0].set_xlabel('Year')\n",
    "axes[0, 0].set_ylabel('Average Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG vs Financial Performance over time\n",
    "ax1 = axes[0, 1]\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "line1 = ax1.plot(esg_evolution.index, esg_evolution['ESG_Score'], 'g-o', linewidth=2, label='ESG Score')\n",
    "line2 = ax2.plot(esg_evolution.index, esg_evolution['Growth_Rate'], 'b-s', linewidth=2, label='Growth Rate')\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('ESG Score', color='g')\n",
    "ax2.set_ylabel('Growth Rate (%)', color='b')\n",
    "ax1.set_title('ESG Score vs Financial Performance Over Time')\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ESG quartile analysis\n",
    "latest_data = esg_data_clean[esg_data_clean['Year'] == latest_year]\n",
    "latest_data['ESG_Quartile'] = pd.qcut(latest_data['ESG_Score'], 4, labels=['Q1 (Low)', 'Q2', 'Q3', 'Q4 (High)'])\n",
    "\n",
    "quartile_performance = latest_data.groupby('ESG_Quartile').agg({\n",
    "    'Growth_Rate': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Revenue': 'mean'\n",
    "})\n",
    "\n",
    "quartile_performance['Growth_Rate'].plot(kind='bar', ax=axes[1, 0], color='skyblue', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Growth Rate by ESG Quartile')\n",
    "axes[1, 0].set_ylabel('Growth Rate (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "quartile_performance['Profit_Margin'].plot(kind='bar', ax=axes[1, 1], color='lightcoral', alpha=0.7)\n",
    "axes[1, 1].set_title('Average Profit Margin by ESG Quartile')\n",
    "axes[1, 1].set_ylabel('Profit Margin (%)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ESG Quartile Performance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(quartile_performance.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental impact correlation analysis\n",
    "environmental_impact = esg_data_clean[['ESG_Score', 'Environmental_Score', \n",
    "                                      'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']]\n",
    "\n",
    "# Calculate correlations\n",
    "env_corr = environmental_impact.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(env_corr, annot=True, cmap='RdYlGn', center=0, square=True, fmt='.3f')\n",
    "plt.title('Environmental Impact vs ESG Scores Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Environmental Correlations:\")\n",
    "print(\"-\" * 40)\n",
    "env_esg_corr = env_corr['Environmental_Score'].drop('Environmental_Score').sort_values(key=abs, ascending=False)\n",
    "for var, corr in env_esg_corr.items():\n",
    "    print(f\"{var:<20}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Now it's your turn!\n",
    "\n",
    "## For Your Written Report and Presentation: See the Group_assignment_AS_2025_content.pdf for detailed instructions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
