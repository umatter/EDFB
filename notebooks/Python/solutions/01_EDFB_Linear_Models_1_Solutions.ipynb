{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression Exercises - Solutions\n",
        "\n",
        "This notebook contains detailed solutions to all exercises from the Linear Models notebook, with explanations and business interpretations.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import all necessary libraries and recreate the models from the main notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recreate the banking dataset model from the main notebook\n",
        "banking_url = \"https://raw.githubusercontent.com/umatter/EDFB/main/data/banking.csv\"\n",
        "dataset = pd.read_csv(banking_url)\n",
        "\n",
        "# Prepare the data exactly as in the main notebook\n",
        "df_banking = dataset.copy()\n",
        "df_banking['was_previously_contacted'] = (df_banking['pdays'] != 999).astype(int)\n",
        "df_banking['pdays_clean'] = df_banking['pdays'].replace(999, np.nan)\n",
        "df_banking['pdays_clean'] = df_banking['pdays_clean'].fillna(df_banking['pdays_clean'].median())\n",
        "\n",
        "feature_cols_cat = ['marital', 'education', 'housing', 'loan', 'contact', 'poutcome']\n",
        "feature_cols_num = ['age', 'previous', 'pdays_clean', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'was_previously_contacted']\n",
        "X_df = pd.get_dummies(df_banking[feature_cols_cat + feature_cols_num], drop_first=True)\n",
        "X = X_df.values\n",
        "y = np.log1p(df_banking['duration']).values.reshape(-1,1)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_test_predicted = model.predict(X_test)\n",
        "\n",
        "print(f\"Banking model trained successfully!\")\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of features: {len(X_df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Understanding Model Coefficients\n",
        "\n",
        "**Task:** Interpret the coefficients from the banking dataset model and understand their business meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 1\n",
        "\n",
        "# Create a DataFrame with feature names and coefficients\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Feature': X_df.columns,\n",
        "    'Coefficient': model.coef_[0],\n",
        "    'Abs_Coefficient': np.abs(model.coef_[0])\n",
        "})\n",
        "\n",
        "# Sort by absolute value to see most important features\n",
        "coefficients_df = coefficients_df.sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"=== MODEL COEFFICIENTS ANALYSIS ===\")\n",
        "print(f\"Intercept: {model.intercept_[0]:.4f}\")\n",
        "print(\"\\nAll coefficients (sorted by absolute magnitude):\")\n",
        "print(coefficients_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== TOP 5 POSITIVE COEFFICIENTS ===\")\n",
        "top_positive = coefficients_df[coefficients_df['Coefficient'] > 0].head(5)\n",
        "for _, row in top_positive.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Coefficient']:.4f}\")\n",
        "\n",
        "print(\"\\n=== TOP 5 NEGATIVE COEFFICIENTS ===\")\n",
        "top_negative = coefficients_df[coefficients_df['Coefficient'] < 0].head(5)\n",
        "for _, row in top_negative.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Coefficient']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the most important coefficients\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = coefficients_df.head(15)  # Top 15 most important features\n",
        "\n",
        "colors = ['red' if coef < 0 else 'blue' for coef in top_features['Coefficient']]\n",
        "plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors, alpha=0.7)\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Top 15 Most Important Features (by absolute coefficient value)')\n",
        "plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Business Interpretation of Coefficients\n",
        "\n",
        "**Key Insights:**\n",
        "\n",
        "1. **Positive coefficients** increase call duration (log scale):\n",
        "   - Features that lead to longer, more engaged conversations\n",
        "   - May indicate higher customer interest or more complex discussions\n",
        "\n",
        "2. **Negative coefficients** decrease call duration:\n",
        "   - Features associated with quick rejections or disinterest\n",
        "   - May indicate customers who are not good targets\n",
        "\n",
        "3. **Magnitude matters**: Larger absolute coefficients have stronger impact on call duration\n",
        "\n",
        "**Business Applications:**\n",
        "- Use positive predictors to identify high-engagement prospects\n",
        "- Avoid or deprioritize customers with strong negative predictors\n",
        "- Tailor call scripts based on customer characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: Residual Analysis\n",
        "\n",
        "**Task:** Perform a comprehensive residual analysis to check model assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 2\n",
        "\n",
        "# Calculate residuals for both training and test sets\n",
        "y_train_predicted = model.predict(X_train)\n",
        "residuals_train = y_train.ravel() - y_train_predicted.ravel()\n",
        "residuals_test = y_test.ravel() - y_test_predicted.ravel()\n",
        "\n",
        "print(\"=== RESIDUAL ANALYSIS ===\")\n",
        "print(f\"Training residuals - Mean: {residuals_train.mean():.6f}, Std: {residuals_train.std():.4f}\")\n",
        "print(f\"Test residuals - Mean: {residuals_test.mean():.6f}, Std: {residuals_test.std():.4f}\")\n",
        "\n",
        "# Create comprehensive residual plots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Residuals vs Fitted Values (Training)\n",
        "axes[0,0].scatter(y_train_predicted.ravel(), residuals_train, alpha=0.6)\n",
        "axes[0,0].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0,0].set_xlabel('Fitted Values')\n",
        "axes[0,0].set_ylabel('Residuals')\n",
        "axes[0,0].set_title('Residuals vs Fitted (Training)')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Residuals vs Fitted Values (Test)\n",
        "axes[0,1].scatter(y_test_predicted.ravel(), residuals_test, alpha=0.6, color='orange')\n",
        "axes[0,1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0,1].set_xlabel('Fitted Values')\n",
        "axes[0,1].set_ylabel('Residuals')\n",
        "axes[0,1].set_title('Residuals vs Fitted (Test)')\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Histogram of residuals (Test)\n",
        "axes[0,2].hist(residuals_test, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
        "axes[0,2].set_xlabel('Residuals')\n",
        "axes[0,2].set_ylabel('Frequency')\n",
        "axes[0,2].set_title('Distribution of Residuals (Test)')\n",
        "axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Q-Q Plot for normality check\n",
        "stats.probplot(residuals_test, dist=\"norm\", plot=axes[1,0])\n",
        "axes[1,0].set_title('Q-Q Plot (Test Residuals)')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Residuals over time (index)\n",
        "axes[1,1].plot(residuals_test, alpha=0.7)\n",
        "axes[1,1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[1,1].set_xlabel('Observation Index')\n",
        "axes[1,1].set_ylabel('Residuals')\n",
        "axes[1,1].set_title('Residuals Over Index (Test)')\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Scale-Location plot (sqrt of absolute residuals vs fitted)\n",
        "sqrt_abs_resid = np.sqrt(np.abs(residuals_test))\n",
        "axes[1,2].scatter(y_test_predicted.ravel(), sqrt_abs_resid, alpha=0.6, color='purple')\n",
        "axes[1,2].set_xlabel('Fitted Values')\n",
        "axes[1,2].set_ylabel('√|Residuals|')\n",
        "axes[1,2].set_title('Scale-Location Plot (Test)')\n",
        "axes[1,2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests for assumptions\n",
        "from scipy.stats import shapiro, jarque_bera\n",
        "\n",
        "print(\"=== STATISTICAL TESTS FOR ASSUMPTIONS ===\")\n",
        "\n",
        "# Test for normality of residuals\n",
        "shapiro_stat, shapiro_p = shapiro(residuals_test[:5000])  # Shapiro-Wilk (limited sample)\n",
        "jb_stat, jb_p = jarque_bera(residuals_test)  # Jarque-Bera test\n",
        "\n",
        "print(f\"\\n1. NORMALITY TESTS:\")\n",
        "print(f\"   Shapiro-Wilk test: statistic={shapiro_stat:.4f}, p-value={shapiro_p:.6f}\")\n",
        "print(f\"   Jarque-Bera test: statistic={jb_stat:.4f}, p-value={jb_p:.6f}\")\n",
        "print(f\"   Interpretation: {'Residuals appear normal' if jb_p > 0.05 else 'Residuals deviate from normality'}\")\n",
        "\n",
        "# Check for heteroscedasticity (Breusch-Pagan test would be ideal, but we'll use correlation)\n",
        "fitted_values = y_test_predicted.ravel()\n",
        "abs_residuals = np.abs(residuals_test)\n",
        "hetero_corr = np.corrcoef(fitted_values, abs_residuals)[0,1]\n",
        "\n",
        "print(f\"\\n2. HOMOSCEDASTICITY CHECK:\")\n",
        "print(f\"   Correlation between fitted values and |residuals|: {hetero_corr:.4f}\")\n",
        "print(f\"   Interpretation: {'Homoscedasticity likely' if abs(hetero_corr) < 0.1 else 'Potential heteroscedasticity'}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\n3. RESIDUAL SUMMARY:\")\n",
        "print(f\"   Mean: {residuals_test.mean():.6f} (should be ≈ 0)\")\n",
        "print(f\"   Standard deviation: {residuals_test.std():.4f}\")\n",
        "print(f\"   Skewness: {stats.skew(residuals_test):.4f} (should be ≈ 0)\")\n",
        "print(f\"   Kurtosis: {stats.kurtosis(residuals_test):.4f} (should be ≈ 0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of Residual Analysis\n",
        "\n",
        "**What to look for:**\n",
        "\n",
        "1. **Residuals vs Fitted**: Should show random scatter around zero\n",
        "   - Patterns indicate non-linearity or heteroscedasticity\n",
        "   - Funnel shapes suggest changing variance\n",
        "\n",
        "2. **Q-Q Plot**: Points should follow the diagonal line\n",
        "   - Deviations indicate non-normal residuals\n",
        "   - Heavy tails or skewness are problematic\n",
        "\n",
        "3. **Histogram**: Should approximate normal distribution\n",
        "   - Skewness or multiple peaks are concerning\n",
        "\n",
        "4. **Scale-Location**: Should show constant spread\n",
        "   - Increasing/decreasing trends indicate heteroscedasticity\n",
        "\n",
        "**Business Implications:**\n",
        "- Assumption violations may lead to unreliable predictions\n",
        "- Consider data transformations or different models if violations are severe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Feature Engineering\n",
        "\n",
        "**Task:** Create new features and see if they improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 3\n",
        "\n",
        "print(\"=== FEATURE ENGINEERING EXPERIMENT ===\")\n",
        "\n",
        "# Start with numerical features only for polynomial expansion\n",
        "numerical_features = ['age', 'previous', 'pdays_clean', 'emp_var_rate', 'cons_price_idx', \n",
        "                     'cons_conf_idx', 'euribor3m', 'nr_employed', 'was_previously_contacted']\n",
        "\n",
        "# Get numerical data\n",
        "X_numerical = df_banking[numerical_features].fillna(0)\n",
        "\n",
        "# Create polynomial features (degree 2 for interaction terms and squares)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
        "X_poly = poly.fit_transform(X_numerical)\n",
        "\n",
        "# Get feature names\n",
        "poly_feature_names = poly.get_feature_names_out(numerical_features)\n",
        "\n",
        "print(f\"Original features: {len(numerical_features)}\")\n",
        "print(f\"Polynomial features: {len(poly_feature_names)}\")\n",
        "print(f\"\\nFirst 10 polynomial features:\")\n",
        "for i, name in enumerate(poly_feature_names[:10]):\n",
        "    print(f\"  {i+1}. {name}\")\n",
        "\n",
        "# Split the polynomial data\n",
        "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(\n",
        "    X_poly, y, test_size=0.2, random_state=0\n",
        ")\n",
        "\n",
        "# Scale the features (important for polynomial features)\n",
        "scaler = StandardScaler()\n",
        "X_poly_train_scaled = scaler.fit_transform(X_poly_train)\n",
        "X_poly_test_scaled = scaler.transform(X_poly_test)\n",
        "\n",
        "# Train models\n",
        "# 1. Original model (for comparison)\n",
        "original_model = LinearRegression()\n",
        "original_model.fit(X_train, y_train)\n",
        "y_pred_original = original_model.predict(X_test)\n",
        "\n",
        "# 2. Polynomial model\n",
        "poly_model = LinearRegression()\n",
        "poly_model.fit(X_poly_train_scaled, y_poly_train)\n",
        "y_pred_poly = poly_model.predict(X_poly_test_scaled)\n",
        "\n",
        "# 3. Ridge regression (to handle potential overfitting)\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_poly_train_scaled, y_poly_train)\n",
        "y_pred_ridge = ridge_model.predict(X_poly_test_scaled)\n",
        "\n",
        "# Compare performance\n",
        "models_comparison = {\n",
        "    'Original Linear': {\n",
        "        'R²': r2_score(y_test, y_pred_original),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_original)),\n",
        "        'Features': X_train.shape[1]\n",
        "    },\n",
        "    'Polynomial': {\n",
        "        'R²': r2_score(y_poly_test, y_pred_poly),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_poly_test, y_pred_poly)),\n",
        "        'Features': X_poly_train_scaled.shape[1]\n",
        "    },\n",
        "    'Ridge (Polynomial)': {\n",
        "        'R²': r2_score(y_poly_test, y_pred_ridge),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_poly_test, y_pred_ridge)),\n",
        "        'Features': X_poly_train_scaled.shape[1]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n=== MODEL COMPARISON ===\")\n",
        "comparison_df = pd.DataFrame(models_comparison).T\n",
        "print(comparison_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# R² comparison\n",
        "r2_scores = [models_comparison[model]['R²'] for model in models_comparison.keys()]\n",
        "model_names = list(models_comparison.keys())\n",
        "axes[0].bar(model_names, r2_scores, color=['blue', 'orange', 'green'], alpha=0.7)\n",
        "axes[0].set_ylabel('R² Score')\n",
        "axes[0].set_title('R² Comparison')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSE comparison\n",
        "rmse_scores = [models_comparison[model]['RMSE'] for model in models_comparison.keys()]\n",
        "axes[1].bar(model_names, rmse_scores, color=['blue', 'orange', 'green'], alpha=0.7)\n",
        "axes[1].set_ylabel('RMSE')\n",
        "axes[1].set_title('RMSE Comparison (Lower is Better)')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Feature count comparison\n",
        "feature_counts = [models_comparison[model]['Features'] for model in models_comparison.keys()]\n",
        "axes[2].bar(model_names, feature_counts, color=['blue', 'orange', 'green'], alpha=0.7)\n",
        "axes[2].set_ylabel('Number of Features')\n",
        "axes[2].set_title('Model Complexity')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show some important polynomial features\n",
        "if len(poly_model.coef_[0]) > 0:\n",
        "    poly_coef_df = pd.DataFrame({\n",
        "        'Feature': poly_feature_names,\n",
        "        'Coefficient': poly_model.coef_[0],\n",
        "        'Abs_Coefficient': np.abs(poly_model.coef_[0])\n",
        "    }).sort_values('Abs_Coefficient', ascending=False)\n",
        "    \n",
        "    print(\"\\n=== TOP 10 POLYNOMIAL FEATURES ===\")\n",
        "    print(poly_coef_df.head(10)[['Feature', 'Coefficient']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering Insights\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "1. **Polynomial Features**: Adding interaction terms and squared features\n",
        "   - Captures non-linear relationships\n",
        "   - May improve fit but risk overfitting\n",
        "\n",
        "2. **Regularization**: Ridge regression helps control overfitting\n",
        "   - Balances bias-variance tradeoff\n",
        "   - Often performs better on new data\n",
        "\n",
        "3. **Complexity vs Performance**: More features ≠ better performance\n",
        "   - Diminishing returns from additional complexity\n",
        "   - Simple models often generalize better\n",
        "\n",
        "**Business Implications:**\n",
        "- Feature engineering can capture complex customer behaviors\n",
        "- Balance model complexity with interpretability needs\n",
        "- Always validate on out-of-sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Cross-Validation\n",
        "\n",
        "**Task:** Use cross-validation to get a more robust estimate of model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 4\n",
        "\n",
        "print(\"=== CROSS-VALIDATION ANALYSIS ===\")\n",
        "\n",
        "# Prepare models for cross-validation\n",
        "models_cv = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Baseline (Mean)': DummyRegressor(strategy='mean')\n",
        "}\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_results = {}\n",
        "n_folds = 5\n",
        "\n",
        "for name, model in models_cv.items():\n",
        "    # Use original features for fair comparison\n",
        "    scores = cross_val_score(model, X, y.ravel(), cv=n_folds, scoring='r2')\n",
        "    cv_results[name] = {\n",
        "        'scores': scores,\n",
        "        'mean': scores.mean(),\n",
        "        'std': scores.std(),\n",
        "        'min': scores.min(),\n",
        "        'max': scores.max()\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "print(f\"\\n{n_folds}-Fold Cross-Validation Results (R² scores):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, results in cv_results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Mean R²: {results['mean']:.4f} (±{results['std']:.4f})\")\n",
        "    print(f\"  Range: [{results['min']:.4f}, {results['max']:.4f}]\")\n",
        "    print(f\"  Individual folds: {[f'{score:.4f}' for score in results['scores']]}\")\n",
        "\n",
        "# Statistical significance test\n",
        "lr_scores = cv_results['Linear Regression']['scores']\n",
        "ridge_scores = cv_results['Ridge Regression']['scores']\n",
        "baseline_scores = cv_results['Baseline (Mean)']['scores']\n",
        "\n",
        "# Paired t-test between Linear Regression and Ridge\n",
        "t_stat_lr_ridge, p_val_lr_ridge = stats.ttest_rel(lr_scores, ridge_scores)\n",
        "t_stat_lr_baseline, p_val_lr_baseline = stats.ttest_rel(lr_scores, baseline_scores)\n",
        "\n",
        "print(f\"\\n=== STATISTICAL SIGNIFICANCE TESTS ===\")\n",
        "print(f\"Linear vs Ridge: t-statistic={t_stat_lr_ridge:.4f}, p-value={p_val_lr_ridge:.4f}\")\n",
        "print(f\"Linear vs Baseline: t-statistic={t_stat_lr_baseline:.4f}, p-value={p_val_lr_baseline:.4f}\")\n",
        "print(f\"\\nSignificance level: α = 0.05\")\n",
        "print(f\"Linear vs Ridge: {'Significantly different' if p_val_lr_ridge < 0.05 else 'No significant difference'}\")\n",
        "print(f\"Linear vs Baseline: {'Significantly better' if p_val_lr_baseline < 0.05 else 'No significant improvement'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cross-validation results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Box plot of CV scores\n",
        "cv_data = [cv_results[name]['scores'] for name in cv_results.keys()]\n",
        "cv_labels = list(cv_results.keys())\n",
        "\n",
        "box_plot = axes[0].boxplot(cv_data, labels=cv_labels, patch_artist=True)\n",
        "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
        "for patch, color in zip(box_plot['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "axes[0].set_ylabel('R² Score')\n",
        "axes[0].set_title('Cross-Validation Score Distribution')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Mean scores with error bars\n",
        "means = [cv_results[name]['mean'] for name in cv_results.keys()]\n",
        "stds = [cv_results[name]['std'] for name in cv_results.keys()]\n",
        "\n",
        "bars = axes[1].bar(cv_labels, means, yerr=stds, capsize=5, \n",
        "                   color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_ylabel('Mean R² Score')\n",
        "axes[1].set_title('Mean CV Performance with Standard Deviation')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, mean, std in zip(bars, means, stds):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height + std + 0.01,\n",
        "                f'{mean:.3f}±{std:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Model stability analysis\n",
        "print(\"\\n=== MODEL STABILITY ANALYSIS ===\")\n",
        "for name, results in cv_results.items():\n",
        "    cv_coefficient = results['std'] / results['mean'] if results['mean'] != 0 else float('inf')\n",
        "    stability = \"High\" if cv_coefficient < 0.1 else \"Medium\" if cv_coefficient < 0.2 else \"Low\"\n",
        "    print(f\"{name}: CV = {cv_coefficient:.3f} ({stability} stability)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation Insights\n",
        "\n",
        "**Why Cross-Validation Matters:**\n",
        "\n",
        "1. **Robust Performance Estimate**: Single train-test split can be misleading\n",
        "2. **Model Stability**: Shows how consistent performance is across different data samples\n",
        "3. **Overfitting Detection**: Large gap between training and CV performance indicates overfitting\n",
        "4. **Model Selection**: Compare models fairly using same data splits\n",
        "\n",
        "**Business Implications:**\n",
        "- More reliable estimate of real-world performance\n",
        "- Helps choose between competing models\n",
        "- Identifies models that may fail in production\n",
        "- Builds confidence in model deployment decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5: Synthetic Data Generation\n",
        "\n",
        "**Task:** Create your own synthetic dataset with known relationships and test your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 5\n",
        "\n",
        "print(\"=== SYNTHETIC DATA GENERATION EXPERIMENT ===\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic dataset\n",
        "n_samples = 500\n",
        "true_coefficients = [2.0, 3.0, -1.5]  # Known true relationship\n",
        "true_intercept = 1.0\n",
        "\n",
        "# Generate features\n",
        "X_synthetic = np.random.randn(n_samples, 3)  # 3 features, standard normal\n",
        "feature_names = ['x1', 'x2', 'x3']\n",
        "\n",
        "# Create true relationship: y = 1.0 + 2.0*x1 + 3.0*x2 - 1.5*x3 + noise\n",
        "def generate_target(X, coefficients, intercept, noise_level=0.5):\n",
        "    \"\"\"Generate target variable with known linear relationship\"\"\"\n",
        "    y_true = intercept + np.dot(X, coefficients)\n",
        "    noise = np.random.normal(0, noise_level, len(y_true))\n",
        "    return y_true + noise, y_true\n",
        "\n",
        "# Test different noise levels\n",
        "noise_levels = [0.1, 0.5, 1.0, 2.0]\n",
        "results_by_noise = {}\n",
        "\n",
        "for noise_level in noise_levels:\n",
        "    print(f\"\\n--- Testing with noise level: {noise_level} ---\")\n",
        "    \n",
        "    # Generate data with current noise level\n",
        "    y_synthetic, y_true = generate_target(X_synthetic, true_coefficients, true_intercept, noise_level)\n",
        "    \n",
        "    # Add some outliers (5% of data)\n",
        "    n_outliers = int(0.05 * n_samples)\n",
        "    outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)\n",
        "    y_synthetic[outlier_indices] += np.random.normal(0, 5*noise_level, n_outliers)\n",
        "    \n",
        "    # Split data\n",
        "    X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
        "        X_synthetic, y_synthetic, test_size=0.2, random_state=42\n",
        "    )\n",
        "    \n",
        "    # Train model\n",
        "    model_syn = LinearRegression()\n",
        "    model_syn.fit(X_train_syn, y_train_syn)\n",
        "    \n",
        "    # Evaluate\n",
        "    y_pred_syn = model_syn.predict(X_test_syn)\n",
        "    r2_syn = r2_score(y_test_syn, y_pred_syn)\n",
        "    rmse_syn = np.sqrt(mean_squared_error(y_test_syn, y_pred_syn))\n",
        "    \n",
        "    # Compare recovered coefficients with true coefficients\n",
        "    recovered_coef = model_syn.coef_\n",
        "    recovered_intercept = model_syn.intercept_\n",
        "    \n",
        "    coef_errors = np.abs(recovered_coef - true_coefficients)\n",
        "    intercept_error = abs(recovered_intercept - true_intercept)\n",
        "    \n",
        "    results_by_noise[noise_level] = {\n",
        "        'r2': r2_syn,\n",
        "        'rmse': rmse_syn,\n",
        "        'coef_errors': coef_errors,\n",
        "        'intercept_error': intercept_error,\n",
        "        'recovered_coef': recovered_coef,\n",
        "        'recovered_intercept': recovered_intercept\n",
        "    }\n",
        "    \n",
        "    print(f\"R²: {r2_syn:.4f}, RMSE: {rmse_syn:.4f}\")\n",
        "    print(f\"True coefficients: {true_coefficients}\")\n",
        "    print(f\"Recovered coefficients: {[f'{c:.3f}' for c in recovered_coef]}\")\n",
        "    print(f\"Coefficient errors: {[f'{e:.3f}' for e in coef_errors]}\")\n",
        "    print(f\"True intercept: {true_intercept:.3f}, Recovered: {recovered_intercept:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the effect of noise on model performance\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Extract results for plotting\n",
        "noise_vals = list(results_by_noise.keys())\n",
        "r2_vals = [results_by_noise[n]['r2'] for n in noise_vals]\n",
        "rmse_vals = [results_by_noise[n]['rmse'] for n in noise_vals]\n",
        "\n",
        "# R² vs Noise Level\n",
        "axes[0,0].plot(noise_vals, r2_vals, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0,0].set_xlabel('Noise Level')\n",
        "axes[0,0].set_ylabel('R² Score')\n",
        "axes[0,0].set_title('Model Performance vs Noise Level')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSE vs Noise Level\n",
        "axes[0,1].plot(noise_vals, rmse_vals, 'ro-', linewidth=2, markersize=8)\n",
        "axes[0,1].set_xlabel('Noise Level')\n",
        "axes[0,1].set_ylabel('RMSE')\n",
        "axes[0,1].set_title('RMSE vs Noise Level')\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Coefficient recovery accuracy\n",
        "coef_errors_by_feature = np.array([results_by_noise[n]['coef_errors'] for n in noise_vals])\n",
        "for i, feature in enumerate(feature_names):\n",
        "    axes[1,0].plot(noise_vals, coef_errors_by_feature[:, i], 'o-', \n",
        "                   label=f'{feature} (true: {true_coefficients[i]})', linewidth=2, markersize=6)\n",
        "axes[1,0].set_xlabel('Noise Level')\n",
        "axes[1,0].set_ylabel('Absolute Coefficient Error')\n",
        "axes[1,0].set_title('Coefficient Recovery Accuracy')\n",
        "axes[1,0].legend()\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Scatter plot for highest noise case\n",
        "highest_noise = max(noise_vals)\n",
        "y_synthetic_final, _ = generate_target(X_synthetic, true_coefficients, true_intercept, highest_noise)\n",
        "model_final = LinearRegression().fit(X_synthetic, y_synthetic_final)\n",
        "y_pred_final = model_final.predict(X_synthetic)\n",
        "\n",
        "axes[1,1].scatter(y_synthetic_final, y_pred_final, alpha=0.6)\n",
        "axes[1,1].plot([y_synthetic_final.min(), y_synthetic_final.max()], \n",
        "               [y_synthetic_final.min(), y_synthetic_final.max()], 'r--', linewidth=2)\n",
        "axes[1,1].set_xlabel('True Values')\n",
        "axes[1,1].set_ylabel('Predicted Values')\n",
        "axes[1,1].set_title(f'Predictions vs True (Noise={highest_noise})')\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary table\n",
        "summary_df = pd.DataFrame({\n",
        "    'Noise_Level': noise_vals,\n",
        "    'R²': [f\"{results_by_noise[n]['r2']:.4f}\" for n in noise_vals],\n",
        "    'RMSE': [f\"{results_by_noise[n]['rmse']:.4f}\" for n in noise_vals],\n",
        "    'Mean_Coef_Error': [f\"{np.mean(results_by_noise[n]['coef_errors']):.4f}\" for n in noise_vals],\n",
        "    'Intercept_Error': [f\"{results_by_noise[n]['intercept_error']:.4f}\" for n in noise_vals]\n",
        "})\n",
        "\n",
        "print(\"\\n=== SUMMARY TABLE ===\")\n",
        "print(summary_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Synthetic Data Insights\n",
        "\n",
        "**Key Learnings:**\n",
        "\n",
        "1. **Noise Impact**: Higher noise levels reduce model performance and coefficient accuracy\n",
        "2. **Coefficient Recovery**: Linear regression can recover true relationships when assumptions are met\n",
        "3. **Outlier Effects**: Even small percentages of outliers can significantly impact results\n",
        "4. **Sample Size**: Larger samples generally lead to better coefficient recovery\n",
        "\n",
        "**Business Applications:**\n",
        "- Understand how data quality affects model reliability\n",
        "- Set realistic expectations for model performance\n",
        "- Identify when additional data collection might be needed\n",
        "- Test model robustness before deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 6: Time Series Forecasting Analysis\n",
        "\n",
        "**Task:** Analyze the Bitcoin forecasting model more deeply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 6\n",
        "# First, let's recreate the Bitcoin data and model from the main notebook\n",
        "\n",
        "print(\"=== BITCOIN FORECASTING ANALYSIS ===\")\n",
        "\n",
        "# Load Bitcoin data\n",
        "try:\n",
        "    btc_url = \"https://raw.githubusercontent.com/umatter/EDFB/main/data/data_BTC.csv\"\n",
        "    data_btc = pd.read_csv(btc_url)\n",
        "except:\n",
        "    print(\"Using fallback synthetic Bitcoin data for demonstration...\")\n",
        "    # Create synthetic Bitcoin-like data for demonstration\n",
        "    dates = pd.date_range('2020-01-01', periods=1000, freq='D')\n",
        "    np.random.seed(42)\n",
        "    prices = 10000 * np.exp(np.cumsum(np.random.normal(0.001, 0.02, 1000)))\n",
        "    data_btc = pd.DataFrame({\n",
        "        'Date': dates,\n",
        "        'BTC-USD.Close': prices\n",
        "    })\n",
        "\n",
        "# Create lagged features function\n",
        "def create_lagged_features_btc(data, lag):\n",
        "    df = data.copy()\n",
        "    df['ret'] = np.log(df['BTC-USD.Close']).diff()\n",
        "    for i in range(1, lag+1):\n",
        "        df[f'lag_ret_{i}'] = df['ret'].shift(i)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Test different lag lengths\n",
        "lag_lengths = [1, 3, 5, 10]\n",
        "lag_results = {}\n",
        "\n",
        "for lag in lag_lengths:\n",
        "    print(f\"\\n--- Testing lag length: {lag} ---\")\n",
        "    \n",
        "    # Create features\n",
        "    data_lagged = create_lagged_features_btc(data_btc, lag)\n",
        "    \n",
        "    # Prepare features and target\n",
        "    feature_cols = [f'lag_ret_{i}' for i in range(1, lag+1)]\n",
        "    X_btc = data_lagged[feature_cols]\n",
        "    y_btc = data_lagged['ret']\n",
        "    \n",
        "    # Chronological split (important for time series!)\n",
        "    split_idx = int(len(data_lagged) * 0.8)\n",
        "    X_train_btc = X_btc.iloc[:split_idx]\n",
        "    X_test_btc = X_btc.iloc[split_idx:]\n",
        "    y_train_btc = y_btc.iloc[:split_idx]\n",
        "    y_test_btc = y_btc.iloc[split_idx:]\n",
        "    \n",
        "    # Train model\n",
        "    model_btc = LinearRegression()\n",
        "    model_btc.fit(X_train_btc, y_train_btc)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_btc = model_btc.predict(X_test_btc)\n",
        "    \n",
        "    # Performance metrics\n",
        "    r2_btc = r2_score(y_test_btc, y_pred_btc)\n",
        "    rmse_btc = np.sqrt(mean_squared_error(y_test_btc, y_pred_btc))\n",
        "    \n",
        "    # Directional accuracy\n",
        "    actual_direction = np.sign(y_test_btc)\n",
        "    predicted_direction = np.sign(y_pred_btc)\n",
        "    directional_accuracy = np.mean(actual_direction == predicted_direction)\n",
        "    \n",
        "    # Naive baseline (predict last return)\n",
        "    naive_pred = X_test_btc.iloc[:, 0]  # lag_ret_1\n",
        "    rmse_naive = np.sqrt(mean_squared_error(y_test_btc, naive_pred))\n",
        "    \n",
        "    lag_results[lag] = {\n",
        "        'r2': r2_btc,\n",
        "        'rmse': rmse_btc,\n",
        "        'rmse_naive': rmse_naive,\n",
        "        'directional_accuracy': directional_accuracy,\n",
        "        'y_test': y_test_btc,\n",
        "        'y_pred': y_pred_btc,\n",
        "        'model': model_btc\n",
        "    }\n",
        "    \n",
        "    print(f\"R²: {r2_btc:.4f}\")\n",
        "    print(f\"RMSE (model): {rmse_btc:.6f}\")\n",
        "    print(f\"RMSE (naive): {rmse_naive:.6f}\")\n",
        "    print(f\"RMSE ratio: {rmse_btc/rmse_naive:.3f}\")\n",
        "    print(f\"Directional accuracy: {directional_accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize lag length comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Performance metrics by lag length\n",
        "lags = list(lag_results.keys())\n",
        "r2_scores = [lag_results[lag]['r2'] for lag in lags]\n",
        "rmse_ratios = [lag_results[lag]['rmse'] / lag_results[lag]['rmse_naive'] for lag in lags]\n",
        "dir_accuracies = [lag_results[lag]['directional_accuracy'] for lag in lags]\n",
        "\n",
        "# R² by lag length\n",
        "axes[0,0].plot(lags, r2_scores, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0,0].set_xlabel('Lag Length')\n",
        "axes[0,0].set_ylabel('R² Score')\n",
        "axes[0,0].set_title('R² vs Lag Length')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# RMSE ratio (model/naive)\n",
        "axes[0,1].plot(lags, rmse_ratios, 'ro-', linewidth=2, markersize=8)\n",
        "axes[0,1].set_xlabel('Lag Length')\n",
        "axes[0,1].set_ylabel('RMSE Ratio (Model/Naive)')\n",
        "axes[0,1].set_title('RMSE Improvement vs Lag Length')\n",
        "axes[0,1].axhline(y=1, color='black', linestyle='--', alpha=0.5, label='No improvement')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Directional accuracy\n",
        "axes[1,0].plot(lags, dir_accuracies, 'go-', linewidth=2, markersize=8)\n",
        "axes[1,0].set_xlabel('Lag Length')\n",
        "axes[1,0].set_ylabel('Directional Accuracy')\n",
        "axes[1,0].set_title('Directional Accuracy vs Lag Length')\n",
        "axes[1,0].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random guess')\n",
        "axes[1,0].legend()\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Time series plot for best performing lag\n",
        "best_lag = max(lag_results.keys(), key=lambda x: lag_results[x]['directional_accuracy'])\n",
        "best_results = lag_results[best_lag]\n",
        "\n",
        "# Plot actual vs predicted returns\n",
        "plot_length = min(100, len(best_results['y_test']))  # Plot last 100 observations\n",
        "x_axis = range(plot_length)\n",
        "axes[1,1].plot(x_axis, best_results['y_test'].iloc[-plot_length:], \n",
        "               label='Actual Returns', alpha=0.7, linewidth=1.5)\n",
        "axes[1,1].plot(x_axis, best_results['y_pred'][-plot_length:], \n",
        "               label='Predicted Returns', alpha=0.8, linewidth=1.5)\n",
        "axes[1,1].set_xlabel('Time')\n",
        "axes[1,1].set_ylabel('Returns')\n",
        "axes[1,1].set_title(f'Actual vs Predicted Returns (Lag={best_lag})')\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest performing lag length: {best_lag} (highest directional accuracy: {best_results['directional_accuracy']:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trading strategy analysis\n",
        "print(\"\\n=== TRADING STRATEGY ANALYSIS ===\")\n",
        "\n",
        "# Use best performing model for trading simulation\n",
        "best_results = lag_results[best_lag]\n",
        "y_test_btc = best_results['y_test']\n",
        "y_pred_btc = best_results['y_pred']\n",
        "\n",
        "# Create trading signals\n",
        "# Strategy: Go long if predicted return > threshold, short if < -threshold, hold otherwise\n",
        "thresholds = [0.0, 0.001, 0.002, 0.005]\n",
        "strategy_results = {}\n",
        "\n",
        "for threshold in thresholds:\n",
        "    # Generate signals\n",
        "    signals = np.where(y_pred_btc > threshold, 1,  # Long position\n",
        "                      np.where(y_pred_btc < -threshold, -1, 0))  # Short position, Hold\n",
        "    \n",
        "    # Calculate strategy returns\n",
        "    strategy_returns = signals * y_test_btc.values\n",
        "    \n",
        "    # Performance metrics\n",
        "    total_return = np.sum(strategy_returns)\n",
        "    cumulative_returns = np.cumsum(strategy_returns)\n",
        "    sharpe_ratio = np.mean(strategy_returns) / np.std(strategy_returns) if np.std(strategy_returns) > 0 else 0\n",
        "    max_drawdown = np.max(np.maximum.accumulate(cumulative_returns) - cumulative_returns)\n",
        "    \n",
        "    # Hit rate (percentage of profitable trades)\n",
        "    profitable_trades = np.sum(strategy_returns > 0)\n",
        "    total_trades = np.sum(signals != 0)\n",
        "    hit_rate = profitable_trades / total_trades if total_trades > 0 else 0\n",
        "    \n",
        "    strategy_results[threshold] = {\n",
        "        'total_return': total_return,\n",
        "        'cumulative_returns': cumulative_returns,\n",
        "        'sharpe_ratio': sharpe_ratio,\n",
        "        'max_drawdown': max_drawdown,\n",
        "        'hit_rate': hit_rate,\n",
        "        'total_trades': total_trades,\n",
        "        'signals': signals\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nThreshold: {threshold:.3f}\")\n",
        "    print(f\"  Total return: {total_return:.4f}\")\n",
        "    print(f\"  Sharpe ratio: {sharpe_ratio:.4f}\")\n",
        "    print(f\"  Max drawdown: {max_drawdown:.4f}\")\n",
        "    print(f\"  Hit rate: {hit_rate:.3f}\")\n",
        "    print(f\"  Total trades: {total_trades}\")\n",
        "\n",
        "# Compare with buy-and-hold\n",
        "buy_hold_return = np.sum(y_test_btc)\n",
        "buy_hold_cumulative = np.cumsum(y_test_btc)\n",
        "buy_hold_sharpe = np.mean(y_test_btc) / np.std(y_test_btc)\n",
        "buy_hold_drawdown = np.max(np.maximum.accumulate(buy_hold_cumulative) - buy_hold_cumulative)\n",
        "\n",
        "print(f\"\\n=== BUY-AND-HOLD BENCHMARK ===\")\n",
        "print(f\"Total return: {buy_hold_return:.4f}\")\n",
        "print(f\"Sharpe ratio: {buy_hold_sharpe:.4f}\")\n",
        "print(f\"Max drawdown: {buy_hold_drawdown:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize trading strategies\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Cumulative returns comparison\n",
        "axes[0,0].plot(buy_hold_cumulative.values, label='Buy & Hold', linewidth=2)\n",
        "for threshold in thresholds[:3]:  # Show top 3 strategies\n",
        "    axes[0,0].plot(strategy_results[threshold]['cumulative_returns'], \n",
        "                   label=f'Strategy (t={threshold})', linewidth=1.5, alpha=0.8)\n",
        "axes[0,0].set_xlabel('Time')\n",
        "axes[0,0].set_ylabel('Cumulative Returns')\n",
        "axes[0,0].set_title('Cumulative Returns Comparison')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Sharpe ratios\n",
        "sharpe_ratios = [strategy_results[t]['sharpe_ratio'] for t in thresholds]\n",
        "threshold_labels = [f'{t:.3f}' for t in thresholds]\n",
        "bars = axes[0,1].bar(threshold_labels, sharpe_ratios, alpha=0.7, color='skyblue')\n",
        "axes[0,1].axhline(y=buy_hold_sharpe, color='red', linestyle='--', label='Buy & Hold')\n",
        "axes[0,1].set_xlabel('Threshold')\n",
        "axes[0,1].set_ylabel('Sharpe Ratio')\n",
        "axes[0,1].set_title('Sharpe Ratio by Threshold')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Hit rates and total trades\n",
        "hit_rates = [strategy_results[t]['hit_rate'] for t in thresholds]\n",
        "total_trades = [strategy_results[t]['total_trades'] for t in thresholds]\n",
        "\n",
        "ax2 = axes[1,0].twinx()\n",
        "bars1 = axes[1,0].bar([i-0.2 for i in range(len(thresholds))], hit_rates, \n",
        "                      width=0.4, alpha=0.7, color='green', label='Hit Rate')\n",
        "bars2 = ax2.bar([i+0.2 for i in range(len(thresholds))], total_trades, \n",
        "                width=0.4, alpha=0.7, color='orange', label='Total Trades')\n",
        "\n",
        "axes[1,0].set_xlabel('Threshold')\n",
        "axes[1,0].set_ylabel('Hit Rate', color='green')\n",
        "ax2.set_ylabel('Total Trades', color='orange')\n",
        "axes[1,0].set_title('Hit Rate vs Number of Trades')\n",
        "axes[1,0].set_xticks(range(len(thresholds)))\n",
        "axes[1,0].set_xticklabels(threshold_labels)\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Signal distribution for best strategy\n",
        "best_threshold = max(thresholds, key=lambda x: strategy_results[x]['sharpe_ratio'])\n",
        "best_signals = strategy_results[best_threshold]['signals']\n",
        "signal_counts = pd.Series(best_signals).value_counts().sort_index()\n",
        "\n",
        "signal_labels = ['Short (-1)', 'Hold (0)', 'Long (1)']\n",
        "signal_colors = ['red', 'gray', 'green']\n",
        "axes[1,1].pie(signal_counts.values, labels=signal_labels, colors=signal_colors, \n",
        "              autopct='%1.1f%%', startangle=90)\n",
        "axes[1,1].set_title(f'Signal Distribution (Best Strategy: t={best_threshold})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest strategy threshold: {best_threshold} (Sharpe ratio: {strategy_results[best_threshold]['sharpe_ratio']:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bitcoin Forecasting Insights\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "1. **Lag Length Impact**: Different lag lengths capture different market dynamics\n",
        "   - Short lags: Capture immediate momentum\n",
        "   - Long lags: Capture longer-term patterns\n",
        "\n",
        "2. **Directional Accuracy**: Often more important than R² for trading\n",
        "   - Even modest directional accuracy can be profitable\n",
        "   - R² can be low but strategy still viable\n",
        "\n",
        "3. **Trading Strategy Performance**: \n",
        "   - Threshold selection crucial for risk management\n",
        "   - Higher thresholds = fewer trades but potentially better quality\n",
        "   - Transaction costs would significantly impact real performance\n",
        "\n",
        "**Practical Trading Implications:**\n",
        "- Linear models provide baseline for more complex strategies\n",
        "- Risk management (thresholds, position sizing) critical\n",
        "- Out-of-sample testing essential before live trading\n",
        "- Consider transaction costs, slippage, and market impact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 7: Model Comparison\n",
        "\n",
        "**Task:** Compare linear regression with other simple models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 7\n",
        "\n",
        "print(\"=== MODEL COMPARISON: LINEAR, RIDGE, AND LASSO ===\")\n",
        "\n",
        "# Test different alpha values for regularization\n",
        "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "models_comparison = {}\n",
        "\n",
        "# Standard Linear Regression (no regularization)\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "\n",
        "models_comparison['Linear Regression'] = {\n",
        "    'model': lr_model,\n",
        "    'alpha': 0,\n",
        "    'r2_train': r2_score(y_train, lr_model.predict(X_train)),\n",
        "    'r2_test': r2_score(y_test, lr_pred),\n",
        "    'rmse_train': np.sqrt(mean_squared_error(y_train, lr_model.predict(X_train))),\n",
        "    'rmse_test': np.sqrt(mean_squared_error(y_test, lr_pred)),\n",
        "    'n_features': np.sum(lr_model.coef_[0] != 0),\n",
        "    'predictions': lr_pred\n",
        "}\n",
        "\n",
        "# Ridge Regression with different alphas\n",
        "best_ridge_alpha = None\n",
        "best_ridge_score = -np.inf\n",
        "\n",
        "for alpha in alphas:\n",
        "    ridge_model = Ridge(alpha=alpha)\n",
        "    ridge_model.fit(X_train, y_train)\n",
        "    ridge_pred = ridge_model.predict(X_test)\n",
        "    \n",
        "    r2_test = r2_score(y_test, ridge_pred)\n",
        "    \n",
        "    models_comparison[f'Ridge (α={alpha})'] = {\n",
        "        'model': ridge_model,\n",
        "        'alpha': alpha,\n",
        "        'r2_train': r2_score(y_train, ridge_model.predict(X_train)),\n",
        "        'r2_test': r2_test,\n",
        "        'rmse_train': np.sqrt(mean_squared_error(y_train, ridge_model.predict(X_train))),\n",
        "        'rmse_test': np.sqrt(mean_squared_error(y_test, ridge_pred)),\n",
        "        'n_features': np.sum(np.abs(ridge_model.coef_[0]) > 1e-6),\n",
        "        'predictions': ridge_pred\n",
        "    }\n",
        "    \n",
        "    if r2_test > best_ridge_score:\n",
        "        best_ridge_score = r2_test\n",
        "        best_ridge_alpha = alpha\n",
        "\n",
        "# Lasso Regression with different alphas\n",
        "best_lasso_alpha = None\n",
        "best_lasso_score = -np.inf\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso_model = Lasso(alpha=alpha, max_iter=2000)\n",
        "    lasso_model.fit(X_train, y_train.ravel())\n",
        "    lasso_pred = lasso_model.predict(X_test)\n",
        "    \n",
        "    r2_test = r2_score(y_test, lasso_pred)\n",
        "    \n",
        "    models_comparison[f'Lasso (α={alpha})'] = {\n",
        "        'model': lasso_model,\n",
        "        'alpha': alpha,\n",
        "        'r2_train': r2_score(y_train, lasso_model.predict(X_train)),\n",
        "        'r2_test': r2_test,\n",
        "        'rmse_train': np.sqrt(mean_squared_error(y_train, lasso_model.predict(X_train))),\n",
        "        'rmse_test': np.sqrt(mean_squared_error(y_test, lasso_pred)),\n",
        "        'n_features': np.sum(np.abs(lasso_model.coef_) > 1e-6),\n",
        "        'predictions': lasso_pred\n",
        "    }\n",
        "    \n",
        "    if r2_test > best_lasso_score:\n",
        "        best_lasso_score = r2_test\n",
        "        best_lasso_alpha = alpha\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== PERFORMANCE COMPARISON ===\")\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': list(models_comparison.keys()),\n",
        "    'Alpha': [models_comparison[m]['alpha'] for m in models_comparison.keys()],\n",
        "    'R²_Train': [f\"{models_comparison[m]['r2_train']:.4f}\" for m in models_comparison.keys()],\n",
        "    'R²_Test': [f\"{models_comparison[m]['r2_test']:.4f}\" for m in models_comparison.keys()],\n",
        "    'RMSE_Train': [f\"{models_comparison[m]['rmse_train']:.4f}\" for m in models_comparison.keys()],\n",
        "    'RMSE_Test': [f\"{models_comparison[m]['rmse_test']:.4f}\" for m in models_comparison.keys()],\n",
        "    'Features': [models_comparison[m]['n_features'] for m in models_comparison.keys()]\n",
        "})\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nBest Ridge alpha: {best_ridge_alpha} (R² = {best_ridge_score:.4f})\")\n",
        "print(f\"Best Lasso alpha: {best_lasso_alpha} (R² = {best_lasso_score:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Extract data for plotting\n",
        "model_names = list(models_comparison.keys())\n",
        "r2_train = [models_comparison[m]['r2_train'] for m in model_names]\n",
        "r2_test = [models_comparison[m]['r2_test'] for m in model_names]\n",
        "rmse_test = [models_comparison[m]['rmse_test'] for m in model_names]\n",
        "n_features = [models_comparison[m]['n_features'] for m in model_names]\n",
        "alphas_plot = [models_comparison[m]['alpha'] for m in model_names]\n",
        "\n",
        "# R² Train vs Test (overfitting check)\n",
        "axes[0,0].scatter(r2_train, r2_test, s=60, alpha=0.7)\n",
        "axes[0,0].plot([0, 1], [0, 1], 'r--', alpha=0.5, label='Perfect generalization')\n",
        "for i, name in enumerate(model_names):\n",
        "    if 'Linear' in name or f'α={best_ridge_alpha}' in name or f'α={best_lasso_alpha}' in name:\n",
        "        axes[0,0].annotate(name.split('(')[0], (r2_train[i], r2_test[i]), \n",
        "                          xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "axes[0,0].set_xlabel('R² Train')\n",
        "axes[0,0].set_ylabel('R² Test')\n",
        "axes[0,0].set_title('Train vs Test Performance')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Regularization path for Ridge\n",
        "ridge_alphas = [models_comparison[m]['alpha'] for m in model_names if 'Ridge' in m]\n",
        "ridge_r2_test = [models_comparison[m]['r2_test'] for m in model_names if 'Ridge' in m]\n",
        "ridge_features = [models_comparison[m]['n_features'] for m in model_names if 'Ridge' in m]\n",
        "\n",
        "axes[0,1].semilogx(ridge_alphas, ridge_r2_test, 'bo-', label='Ridge R²')\n",
        "axes[0,1].axhline(y=models_comparison['Linear Regression']['r2_test'], \n",
        "                  color='red', linestyle='--', label='Linear Regression')\n",
        "axes[0,1].set_xlabel('Alpha (log scale)')\n",
        "axes[0,1].set_ylabel('R² Test')\n",
        "axes[0,1].set_title('Ridge Regularization Path')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Regularization path for Lasso\n",
        "lasso_alphas = [models_comparison[m]['alpha'] for m in model_names if 'Lasso' in m]\n",
        "lasso_r2_test = [models_comparison[m]['r2_test'] for m in model_names if 'Lasso' in m]\n",
        "lasso_features = [models_comparison[m]['n_features'] for m in model_names if 'Lasso' in m]\n",
        "\n",
        "axes[0,2].semilogx(lasso_alphas, lasso_r2_test, 'go-', label='Lasso R²')\n",
        "axes[0,2].axhline(y=models_comparison['Linear Regression']['r2_test'], \n",
        "                  color='red', linestyle='--', label='Linear Regression')\n",
        "axes[0,2].set_xlabel('Alpha (log scale)')\n",
        "axes[0,2].set_ylabel('R² Test')\n",
        "axes[0,2].set_title('Lasso Regularization Path')\n",
        "axes[0,2].legend()\n",
        "axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "# Feature selection (Lasso)\n",
        "axes[1,0].semilogx(lasso_alphas, lasso_features, 'go-', linewidth=2, markersize=8)\n",
        "axes[1,0].axhline(y=models_comparison['Linear Regression']['n_features'], \n",
        "                  color='red', linestyle='--', label='Linear Regression')\n",
        "axes[1,0].set_xlabel('Alpha (log scale)')\n",
        "axes[1,0].set_ylabel('Number of Features')\n",
        "axes[1,0].set_title('Lasso Feature Selection')\n",
        "axes[1,0].legend()\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Best models comparison\n",
        "best_models = ['Linear Regression', f'Ridge (α={best_ridge_alpha})', f'Lasso (α={best_lasso_alpha})']\n",
        "best_r2 = [models_comparison[m]['r2_test'] for m in best_models]\n",
        "best_rmse = [models_comparison[m]['rmse_test'] for m in best_models]\n",
        "\n",
        "x_pos = np.arange(len(best_models))\n",
        "bars = axes[1,1].bar(x_pos, best_r2, alpha=0.7, color=['blue', 'orange', 'green'])\n",
        "axes[1,1].set_xlabel('Model')\n",
        "axes[1,1].set_ylabel('R² Test')\n",
        "axes[1,1].set_title('Best Models Comparison')\n",
        "axes[1,1].set_xticks(x_pos)\n",
        "axes[1,1].set_xticklabels([m.split('(')[0] for m in best_models], rotation=45)\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, r2 in zip(bars, best_r2):\n",
        "    height = bar.get_height()\n",
        "    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
        "                   f'{r2:.4f}', ha='center', va='bottom')\n",
        "\n",
        "# Coefficient comparison for best models\n",
        "lr_coef = models_comparison['Linear Regression']['model'].coef_[0]\n",
        "ridge_coef = models_comparison[f'Ridge (α={best_ridge_alpha})']['model'].coef_[0]\n",
        "lasso_coef = models_comparison[f'Lasso (α={best_lasso_alpha})']['model'].coef_\n",
        "\n",
        "# Show top 10 features by absolute coefficient value\n",
        "top_features_idx = np.argsort(np.abs(lr_coef))[-10:]\n",
        "feature_names_plot = [X_df.columns[i] for i in top_features_idx]\n",
        "\n",
        "x_pos_coef = np.arange(len(top_features_idx))\n",
        "width = 0.25\n",
        "\n",
        "axes[1,2].bar(x_pos_coef - width, lr_coef[top_features_idx], width, \n",
        "              label='Linear', alpha=0.7, color='blue')\n",
        "axes[1,2].bar(x_pos_coef, ridge_coef[top_features_idx], width, \n",
        "              label='Ridge', alpha=0.7, color='orange')\n",
        "axes[1,2].bar(x_pos_coef + width, lasso_coef[top_features_idx], width, \n",
        "              label='Lasso', alpha=0.7, color='green')\n",
        "\n",
        "axes[1,2].set_xlabel('Features')\n",
        "axes[1,2].set_ylabel('Coefficient Value')\n",
        "axes[1,2].set_title('Coefficient Comparison (Top 10 Features)')\n",
        "axes[1,2].set_xticks(x_pos_coef)\n",
        "axes[1,2].set_xticklabels([name[:10] + '...' if len(name) > 10 else name \n",
        "                          for name in feature_names_plot], rotation=45, ha='right')\n",
        "axes[1,2].legend()\n",
        "axes[1,2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison Insights\n",
        "\n",
        "**When to Use Each Model:**\n",
        "\n",
        "1. **Linear Regression**:\n",
        "   - When interpretability is crucial\n",
        "   - Small datasets with few features\n",
        "   - When you're confident about feature relevance\n",
        "\n",
        "2. **Ridge Regression**:\n",
        "   - When you have multicollinearity\n",
        "   - Want to keep all features but reduce their impact\n",
        "   - Stable performance across different datasets\n",
        "\n",
        "3. **Lasso Regression**:\n",
        "   - When you need automatic feature selection\n",
        "   - Many irrelevant features in the dataset\n",
        "   - Want a sparse, interpretable model\n",
        "\n",
        "**Business Decision Framework:**\n",
        "- **Interpretability vs Performance**: Simple models for explanation, complex for prediction\n",
        "- **Feature Importance**: Use Lasso to identify key drivers\n",
        "- **Stability**: Ridge for consistent performance across time\n",
        "- **Deployment**: Consider model complexity vs maintenance costs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 8: Business Impact Analysis\n",
        "\n",
        "**Task:** Quantify the business value of your duration prediction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 8\n",
        "\n",
        "print(\"=== BUSINESS IMPACT ANALYSIS ===\")\n",
        "\n",
        "# Define engagement categories based on call duration\n",
        "# log(2 minutes) ≈ 0.69, log(5 minutes) ≈ 1.61\n",
        "def categorize_engagement(log_duration):\n",
        "    \"\"\"Categorize engagement based on log duration\"\"\"\n",
        "    if log_duration < 0.69:\n",
        "        return 'Low'\n",
        "    elif log_duration < 1.61:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "# Apply categorization to actual and predicted values\n",
        "y_test_categories = [categorize_engagement(val) for val in y_test.ravel()]\n",
        "y_pred_categories = [categorize_engagement(val) for val in y_test_predicted.ravel()]\n",
        "\n",
        "# Create confusion matrix for engagement levels\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "engagement_labels = ['High', 'Low', 'Medium']  # Alphabetical order for sklearn\n",
        "conf_matrix = confusion_matrix(y_test_categories, y_pred_categories, labels=engagement_labels)\n",
        "\n",
        "print(\"\\n=== ENGAGEMENT LEVEL CONFUSION MATRIX ===\")\n",
        "conf_df = pd.DataFrame(conf_matrix, \n",
        "                      index=[f'Actual_{label}' for label in engagement_labels],\n",
        "                      columns=[f'Predicted_{label}' for label in engagement_labels])\n",
        "print(conf_df)\n",
        "\n",
        "# Calculate accuracy for each engagement level\n",
        "print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test_categories, y_pred_categories, labels=engagement_labels))\n",
        "\n",
        "# Business value calculation\n",
        "print(\"\\n=== BUSINESS VALUE CALCULATION ===\")\n",
        "\n",
        "# Define business values for each engagement level\n",
        "engagement_values = {\n",
        "    'High': 100,    # High engagement calls worth €100 in follow-up value\n",
        "    'Medium': 30,   # Medium engagement calls worth €30\n",
        "    'Low': 5        # Low engagement calls worth €5\n",
        "}\n",
        "\n",
        "follow_up_cost = 20  # Cost of follow-up call: €20\n",
        "\n",
        "# Calculate value for different strategies\n",
        "strategies = {\n",
        "    'No Model (Random)': {\n",
        "        'description': 'Follow up with random 50% of customers',\n",
        "        'selection': np.random.choice([True, False], size=len(y_test_categories), p=[0.5, 0.5])\n",
        "    },\n",
        "    'Perfect Model': {\n",
        "        'description': 'Perfect prediction - follow up only with High engagement',\n",
        "        'selection': [cat == 'High' for cat in y_test_categories]\n",
        "    },\n",
        "    'Our Model (Conservative)': {\n",
        "        'description': 'Follow up with predicted High engagement only',\n",
        "        'selection': [cat == 'High' for cat in y_pred_categories]\n",
        "    },\n",
        "    'Our Model (Aggressive)': {\n",
        "        'description': 'Follow up with predicted Medium and High engagement',\n",
        "        'selection': [cat in ['Medium', 'High'] for cat in y_pred_categories]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Calculate ROI for each strategy\n",
        "strategy_results = {}\n",
        "\n",
        "for strategy_name, strategy_info in strategies.items():\n",
        "    selection = strategy_info['selection']\n",
        "    \n",
        "    # Calculate costs and revenues\n",
        "    n_follow_ups = sum(selection)\n",
        "    total_cost = n_follow_ups * follow_up_cost\n",
        "    \n",
        "    # Calculate revenue from selected customers\n",
        "    total_revenue = 0\n",
        "    for i, selected in enumerate(selection):\n",
        "        if selected:\n",
        "            actual_engagement = y_test_categories[i]\n",
        "            total_revenue += engagement_values[actual_engagement]\n",
        "    \n",
        "    net_profit = total_revenue - total_cost\n",
        "    roi = (net_profit / total_cost * 100) if total_cost > 0 else 0\n",
        "    \n",
        "    strategy_results[strategy_name] = {\n",
        "        'n_follow_ups': n_follow_ups,\n",
        "        'total_cost': total_cost,\n",
        "        'total_revenue': total_revenue,\n",
        "        'net_profit': net_profit,\n",
        "        'roi': roi,\n",
        "        'profit_per_customer': net_profit / len(y_test_categories)\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{strategy_name}:\")\n",
        "    print(f\"  Description: {strategy_info['description']}\")\n",
        "    print(f\"  Follow-ups: {n_follow_ups}/{len(y_test_categories)} ({n_follow_ups/len(y_test_categories)*100:.1f}%)\")\n",
        "    print(f\"  Total cost: €{total_cost:,}\")\n",
        "    print(f\"  Total revenue: €{total_revenue:,}\")\n",
        "    print(f\"  Net profit: €{net_profit:,}\")\n",
        "    print(f\"  ROI: {roi:.1f}%\")\n",
        "    print(f\"  Profit per customer: €{net_profit/len(y_test_categories):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize business impact\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Confusion matrix heatmap\n",
        "sns.heatmap(conf_df, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
        "axes[0,0].set_title('Engagement Level Confusion Matrix')\n",
        "axes[0,0].set_ylabel('Actual Engagement')\n",
        "axes[0,0].set_xlabel('Predicted Engagement')\n",
        "\n",
        "# ROI comparison\n",
        "strategy_names = list(strategy_results.keys())\n",
        "rois = [strategy_results[s]['roi'] for s in strategy_names]\n",
        "colors = ['red', 'green', 'blue', 'orange']\n",
        "\n",
        "bars = axes[0,1].bar(range(len(strategy_names)), rois, color=colors, alpha=0.7)\n",
        "axes[0,1].set_xlabel('Strategy')\n",
        "axes[0,1].set_ylabel('ROI (%)')\n",
        "axes[0,1].set_title('Return on Investment by Strategy')\n",
        "axes[0,1].set_xticks(range(len(strategy_names)))\n",
        "axes[0,1].set_xticklabels([name.replace(' ', '\\n') for name in strategy_names], rotation=0)\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, roi in zip(bars, rois):\n",
        "    height = bar.get_height()\n",
        "    axes[0,1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                   f'{roi:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "# Net profit comparison\n",
        "net_profits = [strategy_results[s]['net_profit'] for s in strategy_names]\n",
        "bars2 = axes[1,0].bar(range(len(strategy_names)), net_profits, color=colors, alpha=0.7)\n",
        "axes[1,0].set_xlabel('Strategy')\n",
        "axes[1,0].set_ylabel('Net Profit (€)')\n",
        "axes[1,0].set_title('Net Profit by Strategy')\n",
        "axes[1,0].set_xticks(range(len(strategy_names)))\n",
        "axes[1,0].set_xticklabels([name.replace(' ', '\\n') for name in strategy_names], rotation=0)\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for bar, profit in zip(bars2, net_profits):\n",
        "    height = bar.get_height()\n",
        "    axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 50,\n",
        "                   f'€{profit:,.0f}', ha='center', va='bottom')\n",
        "\n",
        "# Cost vs Revenue breakdown\n",
        "costs = [strategy_results[s]['total_cost'] for s in strategy_names]\n",
        "revenues = [strategy_results[s]['total_revenue'] for s in strategy_names]\n",
        "\n",
        "x_pos = np.arange(len(strategy_names))\n",
        "width = 0.35\n",
        "\n",
        "bars3 = axes[1,1].bar(x_pos - width/2, costs, width, label='Costs', color='red', alpha=0.7)\n",
        "bars4 = axes[1,1].bar(x_pos + width/2, revenues, width, label='Revenues', color='green', alpha=0.7)\n",
        "\n",
        "axes[1,1].set_xlabel('Strategy')\n",
        "axes[1,1].set_ylabel('Amount (€)')\n",
        "axes[1,1].set_title('Cost vs Revenue Breakdown')\n",
        "axes[1,1].set_xticks(x_pos)\n",
        "axes[1,1].set_xticklabels([name.replace(' ', '\\n') for name in strategy_names], rotation=0)\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sensitivity analysis\n",
        "print(\"\\n=== SENSITIVITY ANALYSIS ===\")\n",
        "print(\"How does changing follow-up cost affect optimal strategy?\")\n",
        "\n",
        "follow_up_costs = [10, 15, 20, 25, 30, 40, 50]\n",
        "sensitivity_results = {}\n",
        "\n",
        "for cost in follow_up_costs:\n",
        "    best_strategy = None\n",
        "    best_profit = -float('inf')\n",
        "    \n",
        "    for strategy_name, strategy_info in strategies.items():\n",
        "        if strategy_name == 'No Model (Random)':\n",
        "            continue  # Skip random strategy\n",
        "            \n",
        "        selection = strategy_info['selection']\n",
        "        n_follow_ups = sum(selection)\n",
        "        total_cost = n_follow_ups * cost\n",
        "        \n",
        "        total_revenue = sum(engagement_values[y_test_categories[i]] \n",
        "                           for i, selected in enumerate(selection) if selected)\n",
        "        \n",
        "        net_profit = total_revenue - total_cost\n",
        "        \n",
        "        if net_profit > best_profit:\n",
        "            best_profit = net_profit\n",
        "            best_strategy = strategy_name\n",
        "    \n",
        "    sensitivity_results[cost] = {\n",
        "        'best_strategy': best_strategy,\n",
        "        'best_profit': best_profit\n",
        "    }\n",
        "    \n",
        "    print(f\"Follow-up cost €{cost}: Best strategy = {best_strategy} (Profit: €{best_profit:,.0f})\")\n",
        "\n",
        "# Calculate break-even point\n",
        "print(f\"\\n=== BREAK-EVEN ANALYSIS ===\")\n",
        "high_engagement_rate = sum(1 for cat in y_test_categories if cat == 'High') / len(y_test_categories)\n",
        "break_even_cost = engagement_values['High'] * high_engagement_rate\n",
        "print(f\"Break-even follow-up cost for random strategy: €{break_even_cost:.2f}\")\n",
        "print(f\"Current follow-up cost: €{follow_up_cost}\")\n",
        "print(f\"Margin for error: €{break_even_cost - follow_up_cost:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Business Impact Insights\n",
        "\n",
        "**Key Business Findings:**\n",
        "\n",
        "1. **Model Value**: Predictive models can significantly improve ROI vs random selection\n",
        "2. **Strategy Selection**: Conservative vs aggressive strategies have different risk/reward profiles\n",
        "3. **Cost Sensitivity**: Follow-up costs critically impact optimal strategy choice\n",
        "4. **Precision Matters**: Correctly identifying high-value customers drives profitability\n",
        "\n",
        "**Strategic Recommendations:**\n",
        "\n",
        "1. **Implement Predictive Targeting**: Even imperfect models beat random selection\n",
        "2. **Monitor Costs**: Track follow-up costs and adjust strategy accordingly\n",
        "3. **A/B Testing**: Test different engagement thresholds in practice\n",
        "4. **Continuous Improvement**: Regularly retrain models with new data\n",
        "\n",
        "**Risk Considerations:**\n",
        "- Model predictions may change over time\n",
        "- Customer behavior may shift\n",
        "- Competition may affect engagement values\n",
        "- Economic conditions may impact follow-up success rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 9: Advanced Diagnostics\n",
        "\n",
        "**Task:** Perform advanced model diagnostics to identify potential issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solution for Exercise 9\n",
        "\n",
        "print(\"=== ADVANCED MODEL DIAGNOSTICS ===\")\n",
        "\n",
        "# Calculate residuals and fitted values\n",
        "y_fitted = model.predict(X_train)\n",
        "residuals = y_train.ravel() - y_fitted.ravel()\n",
        "\n",
        "# 1. Cook's Distance - identifies influential observations\n",
        "print(\"\\n1. COOK'S DISTANCE ANALYSIS\")\n",
        "print(\"(Identifying influential observations)\")\n",
        "\n",
        "# Calculate leverage (hat values)\n",
        "X_train_with_intercept = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
        "H = X_train_with_intercept @ np.linalg.inv(X_train_with_intercept.T @ X_train_with_intercept) @ X_train_with_intercept.T\n",
        "leverage = np.diag(H)\n",
        "\n",
        "# Calculate Cook's distance\n",
        "n, p = X_train.shape\n",
        "mse = np.mean(residuals**2)\n",
        "cooks_d = (residuals**2 / (p * mse)) * (leverage / (1 - leverage)**2)\n",
        "\n",
        "# Identify influential points (Cook's D > 4/n)\n",
        "threshold_cooks = 4 / n\n",
        "influential_points = np.where(cooks_d > threshold_cooks)[0]\n",
        "\n",
        "print(f\"Cook's Distance threshold (4/n): {threshold_cooks:.6f}\")\n",
        "print(f\"Number of influential points: {len(influential_points)}\")\n",
        "print(f\"Percentage of influential points: {len(influential_points)/n*100:.2f}%\")\n",
        "\n",
        "if len(influential_points) > 0:\n",
        "    print(f\"Top 5 most influential points (indices): {influential_points[np.argsort(cooks_d[influential_points])[-5:]]}\")\n",
        "    print(f\"Their Cook's distances: {cooks_d[influential_points[np.argsort(cooks_d[influential_points])[-5:]]]:.6f}\")\n",
        "\n",
        "# 2. Variance Inflation Factor (VIF) - checks for multicollinearity\n",
        "print(\"\\n2. MULTICOLLINEARITY ANALYSIS (VIF)\")\n",
        "\n",
        "def calculate_vif(X, feature_names):\n",
        "    \"\"\"Calculate VIF for each feature\"\"\"\n",
        "    vif_data = []\n",
        "    \n",
        "    for i in range(X.shape[1]):\n",
        "        # Regress feature i on all other features\n",
        "        X_others = np.delete(X, i, axis=1)\n",
        "        \n",
        "        if X_others.shape[1] > 0:  # Ensure we have other features\n",
        "            try:\n",
        "                reg = LinearRegression().fit(X_others, X[:, i])\n",
        "                r_squared = reg.score(X_others, X[:, i])\n",
        "                vif = 1 / (1 - r_squared) if r_squared < 0.999 else float('inf')\n",
        "            except:\n",
        "                vif = float('inf')\n",
        "        else:\n",
        "            vif = 1.0\n",
        "        \n",
        "        vif_data.append({\n",
        "            'Feature': feature_names[i],\n",
        "            'VIF': vif\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(vif_data)\n",
        "\n",
        "# Calculate VIF for a subset of features (to avoid computational issues)\n",
        "# Use numerical features only\n",
        "numerical_feature_indices = [i for i, col in enumerate(X_df.columns) \n",
        "                           if any(num_col in col for num_col in ['age', 'previous', 'emp_var_rate', \n",
        "                                                                'cons_price_idx', 'cons_conf_idx', \n",
        "                                                                'euribor3m', 'nr_employed'])]\n",
        "\n",
        "if len(numerical_feature_indices) > 1:\n",
        "    X_numerical_subset = X_train[:, numerical_feature_indices]\n",
        "    numerical_feature_names = [X_df.columns[i] for i in numerical_feature_indices]\n",
        "    \n",
        "    vif_df = calculate_vif(X_numerical_subset, numerical_feature_names)\n",
        "    vif_df = vif_df.sort_values('VIF', ascending=False)\n",
        "    \n",
        "    print(\"VIF Analysis (Numerical features only):\")\n",
        "    print(vif_df.to_string(index=False))\n",
        "    \n",
        "    high_vif = vif_df[vif_df['VIF'] > 10]\n",
        "    if len(high_vif) > 0:\n",
        "        print(f\"\\nFeatures with high multicollinearity (VIF > 10):\")\n",
        "        print(high_vif[['Feature', 'VIF']].to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\nNo severe multicollinearity detected (all VIF < 10)\")\n",
        "else:\n",
        "    print(\"Insufficient numerical features for VIF analysis\")\n",
        "\n",
        "# 3. Durbin-Watson test for autocorrelation\n",
        "print(\"\\n3. AUTOCORRELATION ANALYSIS (DURBIN-WATSON TEST)\")\n",
        "\n",
        "def durbin_watson(residuals):\n",
        "    \"\"\"Calculate Durbin-Watson statistic\"\"\"\n",
        "    diff = np.diff(residuals)\n",
        "    return np.sum(diff**2) / np.sum(residuals**2)\n",
        "\n",
        "dw_stat = durbin_watson(residuals)\n",
        "print(f\"Durbin-Watson statistic: {dw_stat:.4f}\")\n",
        "print(f\"Interpretation:\")\n",
        "print(f\"  - Close to 2.0: No autocorrelation\")\n",
        "print(f\"  - Close to 0.0: Positive autocorrelation\")\n",
        "print(f\"  - Close to 4.0: Negative autocorrelation\")\n",
        "\n",
        "if 1.5 <= dw_stat <= 2.5:\n",
        "    print(f\"  - Result: No significant autocorrelation detected\")\n",
        "elif dw_stat < 1.5:\n",
        "    print(f\"  - Result: Positive autocorrelation detected\")\n",
        "else:\n",
        "    print(f\"  - Result: Negative autocorrelation detected\")\n",
        "\n",
        "# 4. Heteroscedasticity tests\n",
        "print(\"\\n4. HETEROSCEDASTICITY ANALYSIS\")\n",
        "\n",
        "# Breusch-Pagan test (simplified version)\n",
        "fitted_values = y_fitted.ravel()\n",
        "squared_residuals = residuals**2\n",
        "\n",
        "# Regress squared residuals on fitted values\n",
        "bp_reg = LinearRegression().fit(fitted_values.reshape(-1, 1), squared_residuals)\n",
        "bp_r_squared = bp_reg.score(fitted_values.reshape(-1, 1), squared_residuals)\n",
        "bp_statistic = n * bp_r_squared\n",
        "\n",
        "print(f\"Breusch-Pagan test (simplified):\")\n",
        "print(f\"  - Test statistic: {bp_statistic:.4f}\")\n",
        "print(f\"  - R² of auxiliary regression: {bp_r_squared:.6f}\")\n",
        "\n",
        "# Critical value for chi-square with 1 df at 5% significance\n",
        "critical_value = 3.841\n",
        "if bp_statistic > critical_value:\n",
        "    print(f\"  - Result: Heteroscedasticity detected (statistic > {critical_value})\")\n",
        "else:\n",
        "    print(f\"  - Result: No heteroscedasticity detected (statistic < {critical_value})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize advanced diagnostics\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Cook's Distance plot\n",
        "axes[0,0].stem(range(len(cooks_d)), cooks_d, basefmt=\" \")\n",
        "axes[0,0].axhline(y=threshold_cooks, color='red', linestyle='--', \n",
        "                  label=f'Threshold ({threshold_cooks:.6f})')\n",
        "axes[0,0].set_xlabel('Observation Index')\n",
        "axes[0,0].set_ylabel(\"Cook's Distance\")\n",
        "axes[0,0].set_title(\"Cook's Distance - Influential Points\")\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight influential points\n",
        "if len(influential_points) > 0:\n",
        "    axes[0,0].scatter(influential_points, cooks_d[influential_points], \n",
        "                      color='red', s=50, zorder=5, label='Influential')\n",
        "\n",
        "# 2. Leverage vs Residuals\n",
        "axes[0,1].scatter(leverage, residuals, alpha=0.6)\n",
        "axes[0,1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0,1].axvline(x=2*p/n, color='orange', linestyle='--', \n",
        "                  label=f'High leverage threshold ({2*p/n:.4f})')\n",
        "axes[0,1].set_xlabel('Leverage')\n",
        "axes[0,1].set_ylabel('Residuals')\n",
        "axes[0,1].set_title('Leverage vs Residuals')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. VIF plot (if available)\n",
        "if 'vif_df' in locals() and len(vif_df) > 0:\n",
        "    vif_plot_data = vif_df.head(10)  # Top 10 features\n",
        "    colors = ['red' if vif > 10 else 'orange' if vif > 5 else 'green' \n",
        "              for vif in vif_plot_data['VIF']]\n",
        "    \n",
        "    bars = axes[0,2].barh(range(len(vif_plot_data)), vif_plot_data['VIF'], color=colors, alpha=0.7)\n",
        "    axes[0,2].set_yticks(range(len(vif_plot_data)))\n",
        "    axes[0,2].set_yticklabels([name[:15] + '...' if len(name) > 15 else name \n",
        "                               for name in vif_plot_data['Feature']])\n",
        "    axes[0,2].axvline(x=5, color='orange', linestyle='--', alpha=0.7, label='Moderate (5)')\n",
        "    axes[0,2].axvline(x=10, color='red', linestyle='--', alpha=0.7, label='High (10)')\n",
        "    axes[0,2].set_xlabel('VIF Value')\n",
        "    axes[0,2].set_title('Variance Inflation Factors')\n",
        "    axes[0,2].legend()\n",
        "    axes[0,2].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[0,2].text(0.5, 0.5, 'VIF analysis\\nnot available', \n",
        "                   ha='center', va='center', transform=axes[0,2].transAxes)\n",
        "    axes[0,2].set_title('VIF Analysis')\n",
        "\n",
        "# 4. Residuals autocorrelation plot\n",
        "lag_residuals = residuals[:-1]\n",
        "lead_residuals = residuals[1:]\n",
        "axes[1,0].scatter(lag_residuals, lead_residuals, alpha=0.6)\n",
        "axes[1,0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1,0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1,0].set_xlabel('Residual(t)')\n",
        "axes[1,0].set_ylabel('Residual(t+1)')\n",
        "axes[1,0].set_title(f'Residual Autocorrelation\\n(DW = {dw_stat:.3f})')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Heteroscedasticity plot\n",
        "axes[1,1].scatter(fitted_values, squared_residuals, alpha=0.6)\n",
        "# Add trend line\n",
        "z = np.polyfit(fitted_values, squared_residuals, 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1,1].plot(sorted(fitted_values), p(sorted(fitted_values)), \"r--\", alpha=0.8)\n",
        "axes[1,1].set_xlabel('Fitted Values')\n",
        "axes[1,1].set_ylabel('Squared Residuals')\n",
        "axes[1,1].set_title(f'Heteroscedasticity Test\\n(BP = {bp_statistic:.3f})')\n",
        "axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Summary diagnostic plot\n",
        "diagnostic_summary = {\n",
        "    'Influential Points': f\"{len(influential_points)} ({len(influential_points)/n*100:.1f}%)\",\n",
        "    'High VIF Features': f\"{len(high_vif) if 'high_vif' in locals() else 'N/A'}\",\n",
        "    'Autocorrelation': 'Yes' if not (1.5 <= dw_stat <= 2.5) else 'No',\n",
        "    'Heteroscedasticity': 'Yes' if bp_statistic > critical_value else 'No'\n",
        "}\n",
        "\n",
        "y_pos = np.arange(len(diagnostic_summary))\n",
        "axes[1,2].barh(y_pos, [1]*len(diagnostic_summary), color='lightblue', alpha=0.7)\n",
        "axes[1,2].set_yticks(y_pos)\n",
        "axes[1,2].set_yticklabels(list(diagnostic_summary.keys()))\n",
        "axes[1,2].set_xlim(0, 1)\n",
        "axes[1,2].set_title('Diagnostic Summary')\n",
        "\n",
        "# Add text annotations\n",
        "for i, (key, value) in enumerate(diagnostic_summary.items()):\n",
        "    axes[1,2].text(0.5, i, value, ha='center', va='center', fontweight='bold')\n",
        "\n",
        "axes[1,2].set_xticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recommendations based on diagnostics\n",
        "print(\"\\n=== DIAGNOSTIC RECOMMENDATIONS ===\")\n",
        "\n",
        "recommendations = []\n",
        "\n",
        "# Cook's Distance recommendations\n",
        "if len(influential_points) > n * 0.05:  # More than 5% influential points\n",
        "    recommendations.append(\n",
        "        f\"⚠️  HIGH INFLUENCE: {len(influential_points)} influential points detected. \"\n",
        "        \"Consider investigating these observations for data quality issues or outliers.\"\n",
        "    )\n",
        "elif len(influential_points) > 0:\n",
        "    recommendations.append(\n",
        "        f\"✓ MODERATE INFLUENCE: {len(influential_points)} influential points detected. \"\n",
        "        \"Monitor these observations but no immediate action needed.\"\n",
        "    )\n",
        "else:\n",
        "    recommendations.append(\n",
        "        \"✓ LOW INFLUENCE: No highly influential points detected. Model is robust to individual observations.\"\n",
        "    )\n",
        "\n",
        "# VIF recommendations\n",
        "if 'high_vif' in locals() and len(high_vif) > 0:\n",
        "    recommendations.append(\n",
        "        f\"⚠️  MULTICOLLINEARITY: {len(high_vif)} features with high VIF detected. \"\n",
        "        \"Consider removing redundant features or using regularization (Ridge/Lasso).\"\n",
        "    )\n",
        "else:\n",
        "    recommendations.append(\n",
        "        \"✓ MULTICOLLINEARITY: No severe multicollinearity detected. Feature set is appropriate.\"\n",
        "    )\n",
        "\n",
        "# Autocorrelation recommendations\n",
        "if not (1.5 <= dw_stat <= 2.5):\n",
        "    if dw_stat < 1.5:\n",
        "        recommendations.append(\n",
        "            f\"⚠️  AUTOCORRELATION: Positive autocorrelation detected (DW = {dw_stat:.3f}). \"\n",
        "            \"Consider adding lagged variables or using time series models.\"\n",
        "        )\n",
        "    else:\n",
        "        recommendations.append(\n",
        "            f\"⚠️  AUTOCORRELATION: Negative autocorrelation detected (DW = {dw_stat:.3f}). \"\n",
        "            \"Check for over-differencing or model specification issues.\"\n",
        "        )\n",
        "else:\n",
        "    recommendations.append(\n",
        "        f\"✓ AUTOCORRELATION: No significant autocorrelation detected (DW = {dw_stat:.3f}). \"\n",
        "        \"Residuals appear independent.\"\n",
        "    )\n",
        "\n",
        "# Heteroscedasticity recommendations\n",
        "if bp_statistic > critical_value:\n",
        "    recommendations.append(\n",
        "        f\"⚠️  HETEROSCEDASTICITY: Non-constant variance detected (BP = {bp_statistic:.3f}). \"\n",
        "        \"Consider using robust standard errors or transforming the target variable.\"\n",
        "    )\n",
        "else:\n",
        "    recommendations.append(\n",
        "        f\"✓ HOMOSCEDASTICITY: Constant variance assumption appears satisfied (BP = {bp_statistic:.3f}).\"\n",
        "    )\n",
        "\n",
        "# Print recommendations\n",
        "for i, rec in enumerate(recommendations, 1):\n",
        "    print(f\"\\n{i}. {rec}\")\n",
        "\n",
        "# Overall model health score\n",
        "issues = sum(1 for rec in recommendations if '⚠️' in rec)\n",
        "total_checks = len(recommendations)\n",
        "health_score = (total_checks - issues) / total_checks * 100\n",
        "\n",
        "print(f\"\\n=== OVERALL MODEL HEALTH SCORE ===\")\n",
        "print(f\"Score: {health_score:.1f}% ({total_checks - issues}/{total_checks} checks passed)\")\n",
        "\n",
        "if health_score >= 75:\n",
        "    print(\"🟢 GOOD: Model assumptions are largely satisfied. Safe to use for predictions.\")\n",
        "elif health_score >= 50:\n",
        "    print(\"🟡 MODERATE: Some assumption violations detected. Use with caution and consider improvements.\")\n",
        "else:\n",
        "    print(\"🔴 POOR: Multiple assumption violations detected. Model may be unreliable.\")\n",
        "\n",
        "print(f\"\\n=== SUGGESTED IMPROVEMENTS ===\")\n",
        "if issues > 0:\n",
        "    print(\"Based on the diagnostic results, consider:\")\n",
        "    print(\"• Data preprocessing: Remove outliers, handle missing values\")\n",
        "    print(\"• Feature engineering: Transform variables, create interactions\")\n",
        "    print(\"• Regularization: Use Ridge/Lasso to handle multicollinearity\")\n",
        "    print(\"• Robust methods: Use robust standard errors for inference\")\n",
        "    print(\"• Alternative models: Consider non-linear or ensemble methods\")\n",
        "else:\n",
        "    print(\"• Model appears healthy! Consider:\")\n",
        "    print(\"• Cross-validation for performance validation\")\n",
        "    print(\"• Feature importance analysis for business insights\")\n",
        "    print(\"• Regular monitoring for model drift in production\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Diagnostics Insights\n",
        "\n",
        "**Why Advanced Diagnostics Matter:**\n",
        "\n",
        "1. **Model Reliability**: Assumption violations can lead to unreliable predictions\n",
        "2. **Statistical Inference**: Invalid assumptions affect confidence intervals and p-values\n",
        "3. **Business Decisions**: Poor model quality can lead to costly business mistakes\n",
        "4. **Regulatory Compliance**: Some industries require model validation\n",
        "\n",
        "**Diagnostic Checklist for Production Models:**\n",
        "\n",
        "✅ **Influential Points**: Check for observations that heavily influence results\n",
        "✅ **Multicollinearity**: Ensure features provide independent information\n",
        "✅ **Autocorrelation**: Verify residuals are independent (especially for time series)\n",
        "✅ **Heteroscedasticity**: Confirm constant variance assumption\n",
        "✅ **Normality**: Check if residuals follow normal distribution\n",
        "✅ **Linearity**: Verify linear relationship between features and target\n",
        "\n",
        "**Business Implementation:**\n",
        "- Automate diagnostic checks in model pipelines\n",
        "- Set up alerts for assumption violations\n",
        "- Document model limitations for stakeholders\n",
        "- Plan regular model health assessments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary and Key Takeaways\n",
        "\n",
        "Congratulations! You've completed all the linear regression exercises. Here are the key insights:\n",
        "\n",
        "### 🎯 **Technical Skills Developed**\n",
        "1. **Model Interpretation**: Understanding coefficients and their business meaning\n",
        "2. **Assumption Checking**: Validating model assumptions through residual analysis\n",
        "3. **Feature Engineering**: Creating new features to improve model performance\n",
        "4. **Model Validation**: Using cross-validation for robust performance estimates\n",
        "5. **Advanced Diagnostics**: Identifying influential points and assumption violations\n",
        "\n",
        "### 💼 **Business Applications**\n",
        "1. **Customer Segmentation**: Using engagement levels for targeted marketing\n",
        "2. **ROI Analysis**: Quantifying the business value of predictive models\n",
        "3. **Risk Management**: Understanding model limitations and uncertainties\n",
        "4. **Strategic Planning**: Using model insights for business decisions\n",
        "\n",
        "### 🔧 **Best Practices Learned**\n",
        "1. **Always validate assumptions** before trusting model results\n",
        "2. **Use cross-validation** for reliable performance estimates\n",
        "3. **Consider business context** when interpreting model outputs\n",
        "4. **Balance complexity with interpretability** based on use case\n",
        "5. **Monitor model health** regularly in production\n",
        "\n",
        "### 🚀 **Next Steps**\n",
        "- Apply these techniques to your own datasets\n",
        "- Explore more advanced regression techniques (polynomial, spline)\n",
        "- Learn about ensemble methods (Random Forest, Gradient Boosting)\n",
        "- Study time series analysis for temporal data\n",
        "- Practice with different business domains and use cases\n",
        "\n",
        "### 📚 **Additional Resources**\n",
        "- \"An Introduction to Statistical Learning\" by James, Witten, Hastie, and Tibshirani\n",
        "- \"The Elements of Statistical Learning\" by Hastie, Tibshirani, and Friedman\n",
        "- Scikit-learn documentation and tutorials\n",
        "- Kaggle competitions for practical experience\n",
        "\n",
        "Remember: **The best model is not always the most complex one, but the one that best serves your business objectives while being reliable and interpretable!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
