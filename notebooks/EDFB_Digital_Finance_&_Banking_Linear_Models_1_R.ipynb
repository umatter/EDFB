{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-cell",
      "metadata": {},
      "source": [
        "# Linear Regression: Univariate\n",
        "\n",
        "---\n",
        "This notebook demonstrates how to train and test a linear regression model in R, using tidyverse and modern R best practices. The examples and explanations are designed to mirror the Python version, so you can compare the two approaches side by side.\n",
        "\n",
        "## What you'll learn\n",
        "\n",
        "- How to generate and visualize linear data in R\n",
        "- How to fit a linear regression model using `lm()`\n",
        "- How to make predictions and interpret model coefficients\n",
        "- How to use real-world data (e.g., `mtcars`)\n",
        "- How to split data into train/test sets and evaluate model performance\n",
        "- How to check model assumptions (linearity, homoscedasticity, normality, independence)\n",
        "- How to use time series data and create lagged features for forecasting\n",
        "\n",
        "## Libraries\n",
        "\n",
        "- **tidyverse**: For data manipulation and visualization (dplyr, ggplot2, readr, tibble, etc.)\n",
        "- **broom**: For tidying model outputs\n",
        "- **caret**: For train/test splitting and metrics\n",
        "- **lubridate**: For date handling (if needed)\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "> **Note:** This notebook is heavily commented and includes explanations for each step, just like the Python version. If you are new to R, pay attention to the code comments and markdown cells for guidance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "libraries-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install packages if not already installed\n",
        "packages <- c(\"tidyverse\", \"broom\", \"caret\", \"lubridate\", \"reshape2\")\n",
        "new_packages <- packages[!(packages %in% installed.packages()[, \"Package\"])]\n",
        "if (length(new_packages) > 0) {\n",
        "  cat(\"Installing packages:\", paste(new_packages, collapse = \", \"), \"\\n\")\n",
        "  install.packages(new_packages, repos = \"https://cran.rstudio.com/\", dependencies = TRUE)\n",
        "}\n",
        "\n",
        "# Load packages with error handling\n",
        "for (pkg in packages) {\n",
        "  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
        "    stop(paste(\"Failed to load package:\", pkg))\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generate-data-intro",
      "metadata": {},
      "source": [
        "## Generate Linear Data Example\n",
        "\n",
        "Let's generate some linear-looking data, similar to the Python example. We'll use `runif` for uniform random numbers and `rnorm` for normal noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "generate-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a random seed for reproducibility (so results are the same each run)\n",
        "set.seed(42)\n",
        "n <- 100\n",
        "# Generate 100 random x values between 0 and 2\n",
        "X <- tibble(x = runif(n, 0, 2))\n",
        "# Generate y values with a linear relationship plus some random noise\n",
        "y <- 4 + 3 * X$x + rnorm(n)\n",
        "# Combine x and y into a single data frame\n",
        "df <- X %>% mutate(y = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "visualize-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the data\n",
        "ggplot(df, aes(x = x, y = y)) +\n",
        "  geom_point(color = 'blue') +\n",
        "  labs(x = 'x', y = 'y', title = 'Simulated Linear Data') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fit-model-intro",
      "metadata": {},
      "source": [
        "## Fit a Linear Model\n",
        "\n",
        "We'll use `lm()` to fit a linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fit-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a linear regression model: y = intercept + slope * x\n",
        "model <- lm(y ~ x, data = df)\n",
        "# Show a summary of the model (coefficients, R-squared, etc.)\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot-fit",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add predictions to the data frame\n",
        "df <- df %>% mutate(y_pred = predict(model, newdata = df))\n",
        "\n",
        "# Plot data and fitted line\n",
        "ggplot(df, aes(x = x, y = y)) +\n",
        "  geom_point(color = 'blue') +\n",
        "  geom_line(aes(y = y_pred), color = 'red') +\n",
        "  labs(x = 'x', y = 'y', title = 'Linear Fit') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "predict-intro",
      "metadata": {},
      "source": [
        "## Predict New Values\n",
        "\n",
        "Let's predict for new x values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "predict-new",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict y for new x values using the fitted model\n",
        "X_new <- tibble(x = c(0.5, 1.75))\n",
        "y_new_pred <- predict(model, newdata = X_new)\n",
        "# Show the predicted values\n",
        "tibble(x = X_new$x, y_pred = y_new_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "real-data-intro",
      "metadata": {},
      "source": [
        "## Real Data Example: Import and Explore\n",
        "\n",
        "Let's read a real dataset. We'll use a sample CSV (replace with your own path or use a built-in dataset for demonstration)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Use built-in mtcars dataset for demonstration\n",
        "# (In practice, you would load your own CSV file here)\n",
        "data <- as_tibble(mtcars)\n",
        "# Show the first few rows of the data\n",
        "data %>% head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explore-intro",
      "metadata": {},
      "source": [
        "## Data Exploration\n",
        "\n",
        "Let's check the structure, missing values, and summary statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "explore-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the structure of the data (column types, etc.)\n",
        "glimpse(data)\n",
        "# Check for missing values in each column\n",
        "colSums(is.na(data))\n",
        "# Show summary statistics for each column\n",
        "summary(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "simple-regression-intro",
      "metadata": {},
      "source": [
        "## Simple Linear Regression Example\n",
        "\n",
        "Let's predict `mpg` (miles per gallon) from `hp` (horsepower) as a univariate regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot-mpg-hp",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the relationship between horsepower (hp) and miles per gallon (mpg)\n",
        "ggplot(data, aes(x = hp, y = mpg)) +\n",
        "  geom_point() +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fit-mpg-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a simple linear regression: mpg ~ hp\n",
        "model2 <- lm(mpg ~ hp, data = data)\n",
        "# Show model summary\n",
        "summary(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot-mpg-fit",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add predictions to the data frame and plot the fit\n",
        "data <- data %>% mutate(mpg_pred = predict(model2, newdata = data))\n",
        "ggplot(data, aes(x = hp, y = mpg)) +\n",
        "  geom_point(color = 'blue') +\n",
        "  geom_line(aes(y = mpg_pred), color = 'red') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "train-test-intro",
      "metadata": {},
      "source": [
        "## Train/Test Split and Model Evaluation\n",
        "\n",
        "We'll use `caret::createDataPartition` to split the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-test-split",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "set.seed(123)\n",
        "train_idx <- createDataPartition(data$mpg, p = 0.8, list = FALSE)\n",
        "train <- data[train_idx, ]\n",
        "test <- data[-train_idx, ]\n",
        "\n",
        "# Fit the model on the training set\n",
        "model3 <- lm(mpg ~ hp, data = train)\n",
        "# Predict on the test set\n",
        "test <- test %>% mutate(mpg_pred = predict(model3, newdata = test))\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error) and R-squared\n",
        "rmse <- sqrt(mean((test$mpg - test$mpg_pred)^2))\n",
        "r2 <- cor(test$mpg, test$mpg_pred)^2\n",
        "cat('Root Mean Squared Error:', round(rmse, 2), '\\n')\n",
        "cat('R-squared:', round(r2, 2), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "residual-intro",
      "metadata": {},
      "source": [
        "## Residual Analysis\n",
        "\n",
        "Let's check the residuals for homoscedasticity and normality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "residual-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate residuals (difference between actual and predicted values)\n",
        "residuals <- test$mpg - test$mpg_pred\n",
        "residual_df <- tibble(index = 1:length(residuals), residuals = residuals)\n",
        "\n",
        "# Plot residuals to check for patterns (should look random if model is good)\n",
        "p1 <- ggplot(residual_df, aes(x = index, y = residuals)) +\n",
        "  geom_point() +\n",
        "  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +\n",
        "  labs(title = 'Residuals', x = 'Index', y = 'Residual') +\n",
        "  theme_minimal()\n",
        "\n",
        "# Q-Q plot to check if residuals are normally distributed\n",
        "p2 <- ggplot(residual_df, aes(sample = residuals)) +\n",
        "  stat_qq() +\n",
        "  stat_qq_line() +\n",
        "  labs(title = 'Q-Q Plot', x = 'Theoretical Quantiles', y = 'Sample Quantiles') +\n",
        "  theme_minimal()\n",
        "\n",
        "# Display plots side by side\n",
        "library(gridExtra)\n",
        "grid.arrange(p1, p2, ncol = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "correlation-intro",
      "metadata": {},
      "source": [
        "## Correlation Matrix and Heatmap\n",
        "\n",
        "Let's check the correlation between numeric variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correlation-heatmap",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate correlation matrix for numeric variables\n",
        "cor_mat <- cor(data %>% select(where(is.numeric)))\n",
        "# Reshape for plotting\n",
        "melted_cor <- melt(cor_mat)\n",
        "# Plot a heatmap of correlations\n",
        "ggplot(melted_cor, aes(Var1, Var2, fill = value)) +\n",
        "  geom_tile() +\n",
        "  scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0) +\n",
        "  theme_minimal() +\n",
        "  labs(title = 'Correlation Heatmap')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "timeseries-intro",
      "metadata": {},
      "source": [
        "# Time Series Example: Bitcoin Price Forecasting\n",
        "\n",
        "Let's show how to use lagged features for time series forecasting in R. We'll use a simulated time series for demonstration (replace with your own data as needed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "simulate-timeseries",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate a time series (replace with your own data for real use)\n",
        "# Here we create a fake Bitcoin price series for demonstration\n",
        "set.seed(123)\n",
        "n <- 200\n",
        "btc <- tibble(\n",
        "  date = seq.Date(from = as.Date('2022-01-01'), by = 'day', length.out = n),\n",
        "  price = cumsum(rnorm(n, 0.1, 2)) + 30000\n",
        ")\n",
        "# Plot the simulated price series\n",
        "ggplot(btc, aes(x = date, y = price)) +\n",
        "  geom_line(color = 'blue') +\n",
        "  labs(title = 'Simulated Bitcoin Price', x = 'Date', y = 'Price (USD)') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create-lags",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create lagged features for time series forecasting\n",
        "# This function adds columns for previous values (lags) of the target variable\n",
        "create_lags <- function(df, var, lags = 5) {\n",
        "  for (i in 1:lags) {\n",
        "    df[[paste0(var, '_lag', i)]] <- dplyr::lag(df[[var]], i)\n",
        "  }\n",
        "  df\n",
        "}\n",
        "# Add 5 lagged features and drop rows with NA (due to lag)\n",
        "btc_lagged <- create_lags(btc, 'price', lags = 5) %>% drop_na()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the time series into train and test sets (use last 20% as test)\n",
        "n_train <- floor(0.8 * nrow(btc_lagged))\n",
        "train <- btc_lagged[1:n_train, ]\n",
        "test <- btc_lagged[(n_train + 1):nrow(btc_lagged), ]\n",
        "\n",
        "# Fit a linear model using lagged features to predict price\n",
        "model_ts <- lm(price ~ price_lag1 + price_lag2 + price_lag3 + price_lag4 + price_lag5, data = train)\n",
        "# Show model summary\n",
        "summary(model_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-evaluate",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on the test set and evaluate performance\n",
        "test <- test %>% mutate(pred = predict(model_ts, newdata = test))\n",
        "rmse_ts <- sqrt(mean((test$price - test$pred)^2))\n",
        "r2_ts <- cor(test$price, test$pred)^2\n",
        "cat('Time Series RMSE:', round(rmse_ts, 2), '\\n')\n",
        "cat('Time Series R-squared:', round(r2_ts, 2), '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-plot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot true vs predicted prices for the test set\n",
        "ggplot(test, aes(x = price, y = pred)) +\n",
        "  geom_point(color = 'red') +\n",
        "  geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +\n",
        "  labs(title = 'True vs Predicted Bitcoin Price', x = 'True', y = 'Predicted') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "assumptions-intro",
      "metadata": {},
      "source": [
        "# Linear Regression Assumptions\n",
        "\n",
        "1. **Linearity**: Relationship between predictors and target is linear.\n",
        "2. **No (or little) multicollinearity**: Predictors are not highly correlated.\n",
        "3. **Homoscedasticity**: Residuals have constant variance.\n",
        "4. **Normality of residuals**: Residuals are normally distributed.\n",
        "5. **Independence of residuals**: No autocorrelation in residuals (important for time series).\n",
        "\n",
        "Let's check these for our simple regression example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-linearity",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Linearity: Check if the relationship between lagged price and current price is linear\n",
        "ggplot(train, aes(x = price_lag1, y = price)) +\n",
        "  geom_point() +\n",
        "  geom_smooth(method = 'lm', se = FALSE, color = 'red') +\n",
        "  labs(title = 'Linearity Check', x = 'Lag 1 Price', y = 'Price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-multicollinearity",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Multicollinearity: Check if lagged features are highly correlated\n",
        "cor(train %>% select(starts_with('price_lag')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-homoscedasticity",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Homoscedasticity: Plot residuals to check for constant variance\n",
        "resid_ts <- test$price - test$pred\n",
        "resid_ts_df <- tibble(index = 1:length(resid_ts), residuals = resid_ts)\n",
        "ggplot(resid_ts_df, aes(x = index, y = residuals)) +\n",
        "  geom_point() +\n",
        "  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +\n",
        "  labs(title = 'Residuals (Time Series)', x = 'Index', y = 'Residual') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-normality",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Normality of residuals: Q-Q plot to check if residuals are normally distributed\n",
        "ggplot(resid_ts_df, aes(sample = residuals)) +\n",
        "  stat_qq() +\n",
        "  stat_qq_line() +\n",
        "  labs(title = 'Q-Q Plot of Residuals', x = 'Theoretical Quantiles', y = 'Sample Quantiles') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "check-independence",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Independence (autocorrelation): Plot autocorrelation of residuals\n",
        "acf_result <- acf(resid_ts, plot = FALSE)\n",
        "acf_df <- tibble(\n",
        "  lag = as.numeric(acf_result$lag),\n",
        "  acf = as.numeric(acf_result$acf)\n",
        ")\n",
        "ggplot(acf_df, aes(x = lag, y = acf)) +\n",
        "  geom_hline(yintercept = 0, color = 'black') +\n",
        "  geom_segment(aes(xend = lag, yend = 0)) +\n",
        "  geom_hline(yintercept = c(-0.2, 0.2), linetype = 'dashed', color = 'blue') +\n",
        "  labs(title = 'ACF of Residuals', x = 'Lag', y = 'ACF') +\n",
        "  theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook covered univariate and time series linear regression in R, using tidyverse and modern R idioms. The structure and explanations mirror the Python notebook, so you can compare the two approaches directly.\n",
        "\n",
        "### Key takeaways\n",
        "- You learned how to generate, visualize, and model linear data in R\n",
        "- You saw how to use train/test splits and evaluate model performance\n",
        "- You checked model assumptions visually\n",
        "- You saw how to use lagged features for time series forecasting\n",
        "\n",
        "For more advanced modeling, check out the `tidymodels` ecosystem in R!\n",
        "\n",
        "> **Tip:** If you want to see more detailed explanations or have questions about any step, compare this notebook with the Python version or check the code comments above."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
