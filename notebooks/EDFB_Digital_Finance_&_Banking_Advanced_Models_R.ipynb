{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Predictive Models in R: Lasso, Trees, Random Forests, and Boosting\n",
        "\n",
        "---\n",
        "This notebook demonstrates how to use more advanced machine learning models in R for predicting customer behavior in banking. We'll cover:\n",
        "\n",
        "- **Lasso regression**: A linear model that automatically selects important features\n",
        "- **Decision Trees**: Easy-to-interpret models that make decisions like a flowchart\n",
        "- **Random Forests**: Combines many decision trees for better predictions\n",
        "- **Boosting**: Builds models sequentially, learning from previous mistakes\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will:\n",
        "1. Understand when to use each type of model\n",
        "2. Know how to prepare data for machine learning\n",
        "3. Be able to train, evaluate, and compare different models\n",
        "4. Interpret model results and feature importance\n",
        "\n",
        "## Required Packages\n",
        "Please ensure you have the required packages installed:\n",
        "\n",
        "```r\n",
        "install.packages(c(\"gamlr\", \"rpart\", \"randomForest\", \"xgboost\", \"caret\", \"pROC\"))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load libraries with error handling\n",
        "required_packages <- c(\"gamlr\", \"rpart\", \"randomForest\", \"xgboost\", \"caret\", \"pROC\", \"data.table\", \"ggplot2\")\n",
        "\n",
        "for (pkg in required_packages) {\n",
        "  if (!require(pkg, character.only = TRUE)) {\n",
        "    cat(\"Installing package:\", pkg, \"\\n\")\n",
        "    install.packages(pkg)\n",
        "    library(pkg, character.only = TRUE)\n",
        "  }\n",
        "}\n",
        "\n",
        "cat(\"All packages loaded successfully!\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and explore the banking dataset\n",
        "data <- fread(\"banking.csv\")\n",
        "\n",
        "cat(\"Dataset dimensions:\", nrow(data), \"rows and\", ncol(data), \"columns\\n\\n\")\n",
        "\n",
        "# Display structure\n",
        "str(data)\n",
        "\n",
        "# Summary statistics\n",
        "summary(data)\n",
        "\n",
        "# Check for missing values\n",
        "cat(\"\\nMissing values per column:\\n\")\n",
        "sapply(data, function(x) sum(is.na(x)))\n",
        "\n",
        "# Look at the target variable distribution\n",
        "cat(\"\\nTarget variable (y) distribution:\\n\")\n",
        "table(data$y)\n",
        "prop.table(table(data$y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation\n",
        "\n",
        "Before building models, we need to prepare our data properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert categorical variables to factors\n",
        "categorical_vars <- c(\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\", \"y\")\n",
        "data[, (categorical_vars) := lapply(.SD, as.factor), .SDcols = categorical_vars]\n",
        "\n",
        "# Create train/test split (80/20)\n",
        "set.seed(123)  # For reproducibility\n",
        "train_idx <- sample(seq_len(nrow(data)), size = 0.8 * nrow(data))\n",
        "train_data <- data[train_idx, ]\n",
        "test_data <- data[-train_idx, ]\n",
        "\n",
        "cat(\"Training set:\", nrow(train_data), \"observations\\n\")\n",
        "cat(\"Test set:\", nrow(test_data), \"observations\\n\")\n",
        "\n",
        "# Check that target variable is balanced in both sets\n",
        "cat(\"\\nTarget distribution in training set:\\n\")\n",
        "prop.table(table(train_data$y))\n",
        "cat(\"\\nTarget distribution in test set:\\n\")\n",
        "prop.table(table(test_data$y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Lasso Regression\n",
        "\n",
        "**What is Lasso?** Lasso (Least Absolute Shrinkage and Selection Operator) is a linear model that automatically selects the most important features by setting less important coefficients to zero. This helps prevent overfitting and makes the model easier to interpret.\n",
        "\n",
        "**When to use Lasso:**\n",
        "- When you have many features and want automatic feature selection\n",
        "- When you need an interpretable model\n",
        "- When you suspect many features are irrelevant\n",
        "\n",
        "### Logistic Lasso: Predicting customer subscription (y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare data for logistic lasso (training set)\n",
        "X_train <- model.matrix(y ~ ., train_data)[, -1]  # Remove intercept\n",
        "y_train <- train_data$y\n",
        "\n",
        "# Prepare test set\n",
        "X_test <- model.matrix(y ~ ., test_data)[, -1]\n",
        "y_test <- test_data$y\n",
        "\n",
        "# Fit logistic lasso with cross-validation to find optimal lambda\n",
        "cv_lasso <- cv.gamlr(X_train, y_train, family = \"binomial\")\n",
        "\n",
        "# Plot the cross-validation curve\n",
        "plot(cv_lasso, main = \"Lasso Cross-Validation\")\n",
        "cat(\"Optimal lambda:\", cv_lasso$lambda.min, \"\\n\")\n",
        "\n",
        "# Get coefficients for the optimal model\n",
        "lasso_coef <- coef(cv_lasso, select = \"min\")\n",
        "cat(\"\\nNumber of selected features:\", sum(lasso_coef != 0) - 1, \"\\n\")  # -1 for intercept\n",
        "\n",
        "# Show non-zero coefficients (selected features)\n",
        "selected_features <- lasso_coef[lasso_coef != 0, , drop = FALSE]\n",
        "print(selected_features)\n",
        "\n",
        "# Make predictions on test set\n",
        "lasso_pred_prob <- predict(cv_lasso, X_test, type = \"response\")\n",
        "lasso_pred_class <- ifelse(lasso_pred_prob > 0.5, \"yes\", \"no\")\n",
        "\n",
        "# Evaluate performance\n",
        "lasso_accuracy <- mean(lasso_pred_class == y_test)\n",
        "cat(\"\\nLasso Test Accuracy:\", round(lasso_accuracy, 3), \"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "lasso_cm <- table(Predicted = lasso_pred_class, Actual = y_test)\n",
        "print(lasso_cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Decision Trees\n",
        "\n",
        "**What are Decision Trees?** Decision trees make predictions by asking a series of yes/no questions about the features. They're like a flowchart that leads to a prediction.\n",
        "\n",
        "**When to use Decision Trees:**\n",
        "- When you need a highly interpretable model\n",
        "- When relationships between features are non-linear\n",
        "- When you want to understand the decision-making process\n",
        "\n",
        "**Pros:** Easy to interpret, handles non-linear relationships\n",
        "**Cons:** Can overfit, unstable (small data changes can create very different trees)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit a decision tree for classification\n",
        "tree_mod <- rpart(y ~ ., data = train_data, method = \"class\", \n",
        "                  control = rpart.control(cp = 0.01, minsplit = 20))\n",
        "\n",
        "# Plot the tree\n",
        "plot(tree_mod, uniform=TRUE, margin=0.1)\n",
        "text(tree_mod, use.n=TRUE, all=TRUE, cex=.8)\n",
        "title(\"Decision Tree for Customer Subscription Prediction\")\n",
        "\n",
        "# Print complexity parameter table\n",
        "printcp(tree_mod)\n",
        "\n",
        "# Make predictions\n",
        "tree_pred_class <- predict(tree_mod, test_data, type = \"class\")\n",
        "tree_pred_prob <- predict(tree_mod, test_data, type = \"prob\")[, \"yes\"]\n",
        "\n",
        "# Evaluate performance\n",
        "tree_accuracy <- mean(tree_pred_class == test_data$y)\n",
        "cat(\"\\nDecision Tree Test Accuracy:\", round(tree_accuracy, 3), \"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "tree_cm <- table(Predicted = tree_pred_class, Actual = test_data$y)\n",
        "print(tree_cm)\n",
        "\n",
        "# Feature importance\n",
        "cat(\"\\nFeature Importance (Decision Tree):\\n\")\n",
        "importance_tree <- tree_mod$variable.importance\n",
        "print(sort(importance_tree, decreasing = TRUE)[1:10])  # Top 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Random Forests\n",
        "\n",
        "**What are Random Forests?** Random Forests combine many decision trees, where each tree is trained on a random subset of the data and features. The final prediction is the average (or majority vote) of all trees.\n",
        "\n",
        "**When to use Random Forests:**\n",
        "- When you want better accuracy than a single decision tree\n",
        "- When you have enough data (works well with large datasets)\n",
        "- When you want feature importance rankings\n",
        "\n",
        "**Pros:** Usually more accurate than single trees, provides feature importance, handles missing values\n",
        "**Cons:** Less interpretable than single trees, can overfit with very noisy data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit a random forest for classification\n",
        "set.seed(123)\n",
        "rf_mod <- randomForest(y ~ ., data = train_data, ntree = 500, importance = TRUE, \n",
        "                       mtry = sqrt(ncol(train_data) - 1))  # Standard mtry for classification\n",
        "\n",
        "print(rf_mod)\n",
        "\n",
        "# Plot variable importance\n",
        "varImpPlot(rf_mod, main = \"Random Forest Feature Importance\")\n",
        "\n",
        "# Make predictions\n",
        "rf_pred_class <- predict(rf_mod, test_data)\n",
        "rf_pred_prob <- predict(rf_mod, test_data, type = \"prob\")[, \"yes\"]\n",
        "\n",
        "# Evaluate performance\n",
        "rf_accuracy <- mean(rf_pred_class == test_data$y)\n",
        "cat(\"\\nRandom Forest Test Accuracy:\", round(rf_accuracy, 3), \"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "rf_cm <- table(Predicted = rf_pred_class, Actual = test_data$y)\n",
        "print(rf_cm)\n",
        "\n",
        "# Feature importance (top 10)\n",
        "importance_rf <- importance(rf_mod)[, \"MeanDecreaseGini\"]\n",
        "cat(\"\\nTop 10 Most Important Features (Random Forest):\\n\")\n",
        "print(sort(importance_rf, decreasing = TRUE)[1:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Boosting (using XGBoost)\n",
        "\n",
        "**What is Boosting?** Boosting builds models sequentially, where each new model tries to correct the mistakes of the previous models. XGBoost is a popular and powerful implementation of gradient boosting.\n",
        "\n",
        "**When to use Boosting:**\n",
        "- When you want state-of-the-art predictive performance\n",
        "- When you have sufficient data and computational resources\n",
        "- When accuracy is more important than interpretability\n",
        "\n",
        "**Pros:** Often achieves the best predictive performance, handles missing values, provides feature importance\n",
        "**Cons:** More complex to tune, less interpretable, can overfit easily\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare data for xgboost (needs numeric labels: 0/1)\n",
        "Xmat_train <- model.matrix(y ~ ., train_data)[, -1]\n",
        "Xmat_test <- model.matrix(y ~ ., test_data)[, -1]\n",
        "y_train_numeric <- as.numeric(train_data$y) - 1  # Convert to 0/1\n",
        "y_test_numeric <- as.numeric(test_data$y) - 1\n",
        "\n",
        "# Create DMatrix objects\n",
        "dtrain <- xgb.DMatrix(data = Xmat_train, label = y_train_numeric)\n",
        "dtest <- xgb.DMatrix(data = Xmat_test, label = y_test_numeric)\n",
        "\n",
        "# Set parameters\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  eval_metric = \"auc\",\n",
        "  max_depth = 4,\n",
        "  eta = 0.1,\n",
        "  subsample = 0.8,\n",
        "  colsample_bytree = 0.8\n",
        ")\n",
        "\n",
        "# Train with cross-validation to find optimal number of rounds\n",
        "cv_result <- xgb.cv(\n",
        "  params = params,\n",
        "  data = dtrain,\n",
        "  nrounds = 200,\n",
        "  nfold = 5,\n",
        "  early_stopping_rounds = 10,\n",
        "  verbose = 0\n",
        ")\n",
        "\n",
        "best_nrounds <- cv_result$best_iteration\n",
        "cat(\"Optimal number of rounds:\", best_nrounds, \"\\n\")\n",
        "\n",
        "# Fit final model\n",
        "xgb_mod <- xgboost(\n",
        "  params = params,\n",
        "  data = dtrain,\n",
        "  nrounds = best_nrounds,\n",
        "  verbose = 0\n",
        ")\n",
        "\n",
        "# Feature importance\n",
        "importance <- xgb.importance(model = xgb_mod)\n",
        "xgb.plot.importance(importance[1:15, ], main = \"XGBoost Feature Importance (Top 15)\")\n",
        "\n",
        "# Make predictions\n",
        "xgb_pred_prob <- predict(xgb_mod, dtest)\n",
        "xgb_pred_class <- ifelse(xgb_pred_prob > 0.5, \"yes\", \"no\")\n",
        "\n",
        "# Evaluate performance\n",
        "xgb_accuracy <- mean(xgb_pred_class == test_data$y)\n",
        "cat(\"\\nXGBoost Test Accuracy:\", round(xgb_accuracy, 3), \"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "xgb_cm <- table(Predicted = xgb_pred_class, Actual = test_data$y)\n",
        "print(xgb_cm)\n",
        "\n",
        "# ROC curve and AUC\n",
        "roc_obj <- roc(y_test_numeric, xgb_pred_prob)\n",
        "plot(roc_obj, main = \"ROC Curve (XGBoost)\")\n",
        "cat(\"\\nAUC:\", round(auc(roc_obj), 3), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison and Summary\n",
        "\n",
        "Let's compare all our models to see which performs best.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a comparison table\n",
        "model_comparison <- data.frame(\n",
        "  Model = c(\"Lasso\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"),\n",
        "  Accuracy = c(lasso_accuracy, tree_accuracy, rf_accuracy, xgb_accuracy),\n",
        "  stringsAsFactors = FALSE\n",
        ")\n",
        "\n",
        "model_comparison$Accuracy <- round(model_comparison$Accuracy, 3)\n",
        "model_comparison <- model_comparison[order(model_comparison$Accuracy, decreasing = TRUE), ]\n",
        "\n",
        "cat(\"Model Performance Comparison (Test Set Accuracy):\\n\")\n",
        "print(model_comparison)\n",
        "\n",
        "# Plot comparison\n",
        "ggplot(model_comparison, aes(x = reorder(Model, Accuracy), y = Accuracy)) +\n",
        "  geom_col(fill = \"steelblue\", alpha = 0.7) +\n",
        "  geom_text(aes(label = Accuracy), hjust = -0.1) +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Model Performance Comparison\", \n",
        "       x = \"Model\", y = \"Test Accuracy\") +\n",
        "  theme_minimal() +\n",
        "  ylim(0, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "### Model Characteristics Summary:\n",
        "\n",
        "1. **Lasso Regression**\n",
        "   - ✅ Automatic feature selection\n",
        "   - ✅ Highly interpretable\n",
        "   - ✅ Fast to train and predict\n",
        "   - ❌ Assumes linear relationships\n",
        "\n",
        "2. **Decision Trees**\n",
        "   - ✅ Most interpretable (visual flowchart)\n",
        "   - ✅ Handles non-linear relationships\n",
        "   - ✅ No assumptions about data distribution\n",
        "   - ❌ Prone to overfitting\n",
        "   - ❌ Unstable (small changes → different tree)\n",
        "\n",
        "3. **Random Forest**\n",
        "   - ✅ Usually more accurate than single trees\n",
        "   - ✅ Robust to overfitting\n",
        "   - ✅ Provides feature importance\n",
        "   - ✅ Handles missing values well\n",
        "   - ❌ Less interpretable than single trees\n",
        "\n",
        "4. **XGBoost**\n",
        "   - ✅ Often achieves best predictive performance\n",
        "   - ✅ Handles missing values\n",
        "   - ✅ Built-in regularization\n",
        "   - ❌ More complex to tune\n",
        "   - ❌ Least interpretable\n",
        "   - ❌ Can overfit if not tuned properly\n",
        "\n",
        "### Choosing the Right Model:\n",
        "\n",
        "- **Need interpretability?** → Decision Tree or Lasso\n",
        "- **Want good performance with minimal tuning?** → Random Forest\n",
        "- **Need maximum accuracy?** → XGBoost (with proper tuning)\n",
        "- **Have limited data?** → Lasso or Decision Tree\n",
        "- **Have lots of irrelevant features?** → Lasso or XGBoost\n",
        "\n",
        "### Next Steps:\n",
        "1. Try different hyperparameters for each model\n",
        "2. Use cross-validation for more robust evaluation\n",
        "3. Consider ensemble methods (combining multiple models)\n",
        "4. Analyze feature importance to gain business insights\n",
        "5. Test models on new, unseen data before deployment"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
