{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Work III: ESG Investment Analysis and ML Portfolio Optimization\n",
    "\n",
    "The main purpose of group work III is to analyze ESG (Environmental, Social, Governance) investment strategies using machine learning and create both a written report and PowerPoint presentation.\n",
    "\n",
    "## Assignment Overview:\n",
    "\n",
    "**Written Report (8-10 pages):** Comprehensive analysis covering ESG investing evolution, dataset analysis, methodology, results, and investment implications.\n",
    "\n",
    "**PowerPoint Presentation (6-8 slides):** Key findings presentation covering:\n",
    "- Slides 1-2: ESG investment evolution and regulatory drivers\n",
    "- Slide 3: Dataset description and ESG scoring methodology  \n",
    "- Slides 4-5: Data quality analysis and correlations\n",
    "- Slide 6: ML model results and portfolio optimization\n",
    "- Slide 7: ESG vs traditional portfolio performance comparison\n",
    "- Slide 8: Key findings and investment implications\n",
    "\n",
    "## Dataset Details:\n",
    "- **Source**: Kaggle \"ESG & Financial Performance Dataset\"\n",
    "- **Size**: 11,000 observations across 1,000 companies (2015-2025)\n",
    "- **Variables**: Company info, financial metrics, ESG scores, environmental impact data\n",
    "\n",
    "## Instructions:\n",
    "1. Make a copy of this notebook (File â†’ Save a copy in Drive)\n",
    "2. Run each cell sequentially\n",
    "3. Analyze results for your report and presentation\n",
    "4. Submit the completed notebook along with your report and slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Portfolio optimization\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ESG dataset from Kaggle\n",
    "# Note: In a real implementation, you would use the Kaggle API or upload the file\n",
    "# For this example, we'll create a synthetic dataset with the same structure\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic ESG dataset with realistic structure\n",
    "n_companies = 1000\n",
    "n_years = 11  # 2015-2025\n",
    "n_total = n_companies * n_years\n",
    "\n",
    "# Company and time data\n",
    "companies = [f\"Company_{i:03d}\" for i in range(1, n_companies + 1)]\n",
    "industries = ['Technology', 'Healthcare', 'Finance', 'Energy', 'Manufacturing', \n",
    "              'Consumer Goods', 'Utilities', 'Real Estate', 'Transportation']\n",
    "regions = ['North America', 'Europe', 'Asia-Pacific', 'Latin America', 'Middle East & Africa', 'Oceania', 'Other']\n",
    "\n",
    "# Generate the dataset\n",
    "data = []\n",
    "company_id = 1\n",
    "\n",
    "for company in companies:\n",
    "    industry = np.random.choice(industries)\n",
    "    region = np.random.choice(regions)\n",
    "    \n",
    "    # Base characteristics for company (consistent across years)\n",
    "    base_esg = np.random.uniform(30, 90)  # Base ESG score\n",
    "    industry_factor = {'Technology': 1.1, 'Healthcare': 1.05, 'Finance': 0.95, \n",
    "                      'Energy': 0.8, 'Manufacturing': 0.9}.get(industry, 1.0)\n",
    "    \n",
    "    for year in range(2015, 2026):\n",
    "        # ESG scores (trending upward over time)\n",
    "        year_trend = (year - 2015) * 0.5  # Gradual improvement\n",
    "        esg_overall = base_esg * industry_factor + year_trend + np.random.normal(0, 5)\n",
    "        esg_overall = np.clip(esg_overall, 0, 100)\n",
    "        \n",
    "        # Individual ESG components\n",
    "        esg_env = esg_overall + np.random.normal(0, 8)\n",
    "        esg_social = esg_overall + np.random.normal(0, 8) \n",
    "        esg_gov = esg_overall + np.random.normal(0, 8)\n",
    "        \n",
    "        # Financial metrics (correlated with ESG)\n",
    "        esg_premium = (esg_overall - 50) * 0.02  # ESG premium/discount\n",
    "        revenue = np.exp(np.random.uniform(15, 22)) * (1 + esg_premium)  # Revenue in millions\n",
    "        profit_margin = np.random.uniform(2, 25) * (1 + esg_premium * 0.5)\n",
    "        market_cap = revenue * np.random.uniform(2, 15) * (1 + esg_premium)\n",
    "        growth_rate = np.random.uniform(-10, 30) * (1 + esg_premium * 0.3)\n",
    "        \n",
    "        # Environmental impact (inversely correlated with ESG Environmental score)\n",
    "        carbon_emissions = np.exp(np.random.uniform(8, 15)) * (1 - esg_env/200)\n",
    "        water_usage = np.exp(np.random.uniform(10, 16)) * (1 - esg_env/300)\n",
    "        energy_consumption = np.exp(np.random.uniform(12, 18)) * (1 - esg_env/250)\n",
    "        \n",
    "        data.append({\n",
    "            'Company_ID': company_id,\n",
    "            'Company_Name': company,\n",
    "            'Year': year,\n",
    "            'Industry': industry,\n",
    "            'Region': region,\n",
    "            'Revenue': revenue,\n",
    "            'Profit_Margin': profit_margin,\n",
    "            'Market_Cap': market_cap,\n",
    "            'Growth_Rate': growth_rate,\n",
    "            'ESG_Score': esg_overall,\n",
    "            'Environmental_Score': esg_env,\n",
    "            'Social_Score': esg_social,\n",
    "            'Governance_Score': esg_gov,\n",
    "            'Carbon_Emissions': carbon_emissions,\n",
    "            'Water_Usage': water_usage,\n",
    "            'Energy_Consumption': energy_consumption\n",
    "        })\n",
    "    \n",
    "    company_id += 1\n",
    "\n",
    "# Create DataFrame\n",
    "esg_data = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Dataset created with {len(esg_data)} observations\")\n",
    "print(f\"Covering {esg_data['Company_Name'].nunique()} companies from {esg_data['Year'].min()} to {esg_data['Year'].max()}\")\n",
    "esg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset dimensions and basic info\n",
    "print(\"Dataset Shape:\", esg_data.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(esg_data.dtypes)\n",
    "print(\"\\nBasic Information:\")\n",
    "esg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = esg_data.isnull().sum()\n",
    "print(\"Missing Values per Column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "esg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis by industry and region\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Industry distribution\n",
    "industry_counts = esg_data['Industry'].value_counts()\n",
    "axes[0, 0].pie(industry_counts.values, labels=industry_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Distribution by Industry')\n",
    "\n",
    "# Region distribution\n",
    "region_counts = esg_data['Region'].value_counts()\n",
    "axes[0, 1].pie(region_counts.values, labels=region_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 1].set_title('Distribution by Region')\n",
    "\n",
    "# ESG Score distribution\n",
    "axes[1, 0].hist(esg_data['ESG_Score'], bins=30, alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Distribution of ESG Scores')\n",
    "axes[1, 0].set_xlabel('ESG Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Year distribution\n",
    "year_counts = esg_data['Year'].value_counts().sort_index()\n",
    "axes[1, 1].bar(year_counts.index, year_counts.values)\n",
    "axes[1, 1].set_title('Distribution by Year')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Number of Companies')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Score components analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG components distribution\n",
    "esg_components = ['Environmental_Score', 'Social_Score', 'Governance_Score']\n",
    "colors = ['green', 'blue', 'orange']\n",
    "\n",
    "for i, (component, color) in enumerate(zip(esg_components, colors)):\n",
    "    if i < 3:\n",
    "        row, col = i // 2, i % 2\n",
    "        axes[row, col].hist(esg_data[component], bins=30, alpha=0.7, color=color, label=component)\n",
    "        axes[row, col].set_title(f'Distribution of {component.replace(\"_\", \" \")}')\n",
    "        axes[row, col].set_xlabel('Score')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "# ESG trend over time\n",
    "esg_trend = esg_data.groupby('Year')['ESG_Score'].mean()\n",
    "axes[1, 1].plot(esg_trend.index, esg_trend.values, marker='o', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_title('Average ESG Score Trend Over Time')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Average ESG Score')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Outlier Detection and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns for outlier analysis\n",
    "numerical_cols = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate', \n",
    "                  'ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score',\n",
    "                  'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']\n",
    "\n",
    "# Box plot visualization for outlier detection\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < len(axes):\n",
    "        # Use log scale for financial and environmental metrics for better visualization\n",
    "        if col in ['Revenue', 'Market_Cap', 'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']:\n",
    "            data_to_plot = np.log1p(esg_data[col])  # log(1+x) to handle zeros\n",
    "            axes[i].set_ylabel(f'Log({col})')\n",
    "        else:\n",
    "            data_to_plot = esg_data[col]\n",
    "            axes[i].set_ylabel(col)\n",
    "        \n",
    "        axes[i].boxplot(data_to_plot, patch_artist=True)\n",
    "        axes[i].set_title(f'Box Plot: {col}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "\n",
    "# Count outliers for each numerical column\n",
    "outlier_counts = {}\n",
    "for col in numerical_cols:\n",
    "    outliers = detect_outliers_iqr(esg_data, col)\n",
    "    outlier_counts[col] = outliers.sum()\n",
    "\n",
    "print(\"Outlier Counts by Column (using IQR method):\")\n",
    "print(\"-\" * 45)\n",
    "for col, count in outlier_counts.items():\n",
    "    percentage = (count / len(esg_data)) * 100\n",
    "    print(f\"{col:20s}: {count:4d} ({percentage:.1f}%)\")\n",
    "\n",
    "total_outliers = sum(outlier_counts.values())\n",
    "print(f\"\\nTotal outlier instances: {total_outliers}\")\n",
    "print(f\"Percentage of dataset with outliers: {(total_outliers / (len(esg_data) * len(numerical_cols))) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned dataset by capping outliers at 95th and 5th percentiles\n",
    "esg_data_clean = esg_data.copy()\n",
    "\n",
    "outlier_treatment_log = {}\n",
    "\n",
    "for col in numerical_cols:\n",
    "    original_outliers = detect_outliers_iqr(esg_data, col).sum()\n",
    "    \n",
    "    # Cap outliers at 5th and 95th percentiles\n",
    "    lower_cap = esg_data[col].quantile(0.05)\n",
    "    upper_cap = esg_data[col].quantile(0.95)\n",
    "    \n",
    "    esg_data_clean[col] = esg_data_clean[col].clip(lower=lower_cap, upper=upper_cap)\n",
    "    \n",
    "    new_outliers = detect_outliers_iqr(esg_data_clean, col).sum()\n",
    "    outlier_treatment_log[col] = {\n",
    "        'original_outliers': original_outliers,\n",
    "        'remaining_outliers': new_outliers,\n",
    "        'reduction': original_outliers - new_outliers\n",
    "    }\n",
    "\n",
    "print(\"Outlier Treatment Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Column':<20} {'Original':<10} {'Remaining':<10} {'Reduced':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for col, stats in outlier_treatment_log.items():\n",
    "    print(f\"{col:<20} {stats['original_outliers']:<10} {stats['remaining_outliers']:<10} {stats['reduction']:<10}\")\n",
    "\n",
    "print(f\"\\nDataset shape after outlier treatment: {esg_data_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for key variables\n",
    "correlation_vars = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate', \n",
    "                   'ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score']\n",
    "\n",
    "correlation_matrix = esg_data_clean[correlation_vars].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlGn', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'},\n",
    "            mask=mask)\n",
    "plt.title('Correlation Matrix: Financial Performance vs ESG Scores', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Correlations with ESG Score:\")\n",
    "print(\"-\" * 35)\n",
    "esg_correlations = correlation_matrix['ESG_Score'].drop('ESG_Score').sort_values(key=abs, ascending=False)\n",
    "for var, corr in esg_correlations.items():\n",
    "    print(f\"{var:<20}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Score vs Financial Performance Scatter Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "financial_metrics = ['Revenue', 'Profit_Margin', 'Market_Cap', 'Growth_Rate']\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(financial_metrics, colors)):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Use log scale for Revenue and Market_Cap for better visualization\n",
    "    if metric in ['Revenue', 'Market_Cap']:\n",
    "        y_data = np.log1p(esg_data_clean[metric])\n",
    "        axes[row, col].set_ylabel(f'Log({metric})')\n",
    "    else:\n",
    "        y_data = esg_data_clean[metric]\n",
    "        axes[row, col].set_ylabel(metric)\n",
    "    \n",
    "    axes[row, col].scatter(esg_data_clean['ESG_Score'], y_data, alpha=0.5, color=color)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(esg_data_clean['ESG_Score'], y_data, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[row, col].plot(esg_data_clean['ESG_Score'], p(esg_data_clean['ESG_Score']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Calculate and display correlation\n",
    "    corr = esg_data_clean['ESG_Score'].corr(y_data)\n",
    "    axes[row, col].set_title(f'ESG Score vs {metric}\\n(Correlation: {corr:.3f})')\n",
    "    axes[row, col].set_xlabel('ESG Score')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry-wise ESG and Financial Performance Analysis\n",
    "industry_analysis = esg_data_clean.groupby('Industry').agg({\n",
    "    'ESG_Score': ['mean', 'std'],\n",
    "    'Revenue': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Growth_Rate': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "industry_analysis.columns = ['_'.join(col).strip() for col in industry_analysis.columns]\n",
    "industry_analysis = industry_analysis.sort_values('ESG_Score_mean', ascending=False)\n",
    "\n",
    "print(\"Industry-wise ESG and Financial Performance:\")\n",
    "print(\"=\" * 80)\n",
    "print(industry_analysis)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG Score by Industry\n",
    "industry_esg = esg_data_clean.groupby('Industry')['ESG_Score'].mean().sort_values(ascending=True)\n",
    "axes[0, 0].barh(industry_esg.index, industry_esg.values, color='green', alpha=0.7)\n",
    "axes[0, 0].set_title('Average ESG Score by Industry')\n",
    "axes[0, 0].set_xlabel('Average ESG Score')\n",
    "\n",
    "# Revenue by Industry\n",
    "industry_revenue = esg_data_clean.groupby('Industry')['Revenue'].mean().sort_values(ascending=True)\n",
    "axes[0, 1].barh(industry_revenue.index, industry_revenue.values / 1e6, color='blue', alpha=0.7)\n",
    "axes[0, 1].set_title('Average Revenue by Industry')\n",
    "axes[0, 1].set_xlabel('Average Revenue (Millions)')\n",
    "\n",
    "# Profit Margin by Industry\n",
    "industry_margin = esg_data_clean.groupby('Industry')['Profit_Margin'].mean().sort_values(ascending=True)\n",
    "axes[1, 0].barh(industry_margin.index, industry_margin.values, color='orange', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Profit Margin by Industry')\n",
    "axes[1, 0].set_xlabel('Average Profit Margin (%)')\n",
    "\n",
    "# Growth Rate by Industry\n",
    "industry_growth = esg_data_clean.groupby('Industry')['Growth_Rate'].mean().sort_values(ascending=True)\n",
    "axes[1, 1].barh(industry_growth.index, industry_growth.values, color='red', alpha=0.7)\n",
    "axes[1, 1].set_title('Average Growth Rate by Industry')\n",
    "axes[1, 1].set_xlabel('Average Growth Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Machine Learning Models for Return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "# We'll predict Growth_Rate (as a proxy for returns) using ESG scores and other features\n",
    "\n",
    "# Encode categorical variables\n",
    "le_industry = LabelEncoder()\n",
    "le_region = LabelEncoder()\n",
    "\n",
    "ml_data = esg_data_clean.copy()\n",
    "ml_data['Industry_encoded'] = le_industry.fit_transform(ml_data['Industry'])\n",
    "ml_data['Region_encoded'] = le_region.fit_transform(ml_data['Region'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "feature_cols = ['ESG_Score', 'Environmental_Score', 'Social_Score', 'Governance_Score',\n",
    "                'Revenue', 'Profit_Margin', 'Market_Cap', 'Year', \n",
    "                'Industry_encoded', 'Region_encoded']\n",
    "\n",
    "X = ml_data[feature_cols]\n",
    "y = ml_data['Growth_Rate']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {feature_cols}\")\n",
    "print(f\"Target: Growth_Rate (as proxy for returns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"Mean: {y.mean():.2f}%\")\n",
    "print(f\"Std: {y.std():.2f}%\")\n",
    "print(f\"Min: {y.min():.2f}%\")\n",
    "print(f\"Max: {y.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple machine learning models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "print(\"Model Training and Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        model.fit(X_train, y_train)  # Tree-based models don't need scaling\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions_train': y_pred_train,\n",
    "        'predictions_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Training RÂ²: {train_r2:.4f}\")\n",
    "    print(f\"  Testing RÂ²:  {test_r2:.4f}\")\n",
    "    print(f\"  Training RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  Testing RMSE:  {test_rmse:.4f}\")\n",
    "    print(f\"  CV RÂ² Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "\n",
    "# Select best model based on test RÂ²\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['test_r2'])\n",
    "best_model = model_results[best_model_name]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"Best Model: {best_model_name} (Test RÂ² = {best_model['test_r2']:.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for Random Forest\n",
    "rf_model = model_results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(\"-\" * 40)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:<20}: {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance['feature'][::-1], feature_importance['importance'][::-1])\n",
    "plt.title('Feature Importance for Growth Rate Prediction (Random Forest)', fontsize=16)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Actual vs Predicted plots for both models\n",
    "for i, (name, results) in enumerate(model_results.items()):\n",
    "    # Training set\n",
    "    axes[i, 0].scatter(y_train, results['predictions_train'], alpha=0.5)\n",
    "    axes[i, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "    axes[i, 0].set_xlabel('Actual Growth Rate (%)')\n",
    "    axes[i, 0].set_ylabel('Predicted Growth Rate (%)')\n",
    "    axes[i, 0].set_title(f'{name} - Training Set\\n(RÂ² = {results[\"train_r2\"]:.4f})')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Testing set\n",
    "    axes[i, 1].scatter(y_test, results['predictions_test'], alpha=0.5, color='orange')\n",
    "    axes[i, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    axes[i, 1].set_xlabel('Actual Growth Rate (%)')\n",
    "    axes[i, 1].set_ylabel('Predicted Growth Rate (%)')\n",
    "    axes[i, 1].set_title(f'{name} - Testing Set\\n(RÂ² = {results[\"test_r2\"]:.4f})')\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Portfolio Optimization with ESG Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio optimization using Modern Portfolio Theory with ESG constraints\n",
    "# We'll create portfolios based on different ESG criteria\n",
    "\n",
    "# Get latest year data for portfolio construction\n",
    "latest_year = esg_data_clean['Year'].max()\n",
    "portfolio_data = esg_data_clean[esg_data_clean['Year'] == latest_year].copy()\n",
    "\n",
    "# Select top companies by different criteria for portfolio construction\n",
    "n_assets = 50  # Number of assets in portfolio\n",
    "\n",
    "# Portfolio 1: Traditional - highest returns (Growth Rate)\n",
    "traditional_portfolio = portfolio_data.nlargest(n_assets, 'Growth_Rate')\n",
    "\n",
    "# Portfolio 2: ESG-focused - highest ESG scores\n",
    "esg_portfolio = portfolio_data.nlargest(n_assets, 'ESG_Score')\n",
    "\n",
    "# Portfolio 3: Balanced - combination of returns and ESG\n",
    "portfolio_data['Combined_Score'] = (0.6 * portfolio_data['Growth_Rate'].rank(pct=True) + \n",
    "                                   0.4 * portfolio_data['ESG_Score'].rank(pct=True))\n",
    "balanced_portfolio = portfolio_data.nlargest(n_assets, 'Combined_Score')\n",
    "\n",
    "portfolios = {\n",
    "    'Traditional': traditional_portfolio,\n",
    "    'ESG-Focused': esg_portfolio,\n",
    "    'Balanced': balanced_portfolio\n",
    "}\n",
    "\n",
    "print(f\"Portfolio Analysis ({latest_year} data, {n_assets} assets each):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "portfolio_stats = {}\n",
    "for name, data in portfolios.items():\n",
    "    stats = {\n",
    "        'avg_return': data['Growth_Rate'].mean(),\n",
    "        'return_std': data['Growth_Rate'].std(),\n",
    "        'avg_esg': data['ESG_Score'].mean(),\n",
    "        'esg_std': data['ESG_Score'].std(),\n",
    "        'avg_revenue': data['Revenue'].mean(),\n",
    "        'avg_margin': data['Profit_Margin'].mean(),\n",
    "        'sharpe_ratio': data['Growth_Rate'].mean() / data['Growth_Rate'].std() if data['Growth_Rate'].std() > 0 else 0\n",
    "    }\n",
    "    portfolio_stats[name] = stats\n",
    "    \n",
    "    print(f\"\\n{name} Portfolio:\")\n",
    "    print(f\"  Average Return: {stats['avg_return']:.2f}% (Ïƒ = {stats['return_std']:.2f}%)\")\n",
    "    print(f\"  Average ESG Score: {stats['avg_esg']:.1f} (Ïƒ = {stats['esg_std']:.1f})\")\n",
    "    print(f\"  Sharpe Ratio: {stats['sharpe_ratio']:.3f}\")\n",
    "    print(f\"  Average Revenue: ${stats['avg_revenue']/1e6:.1f}M\")\n",
    "    print(f\"  Average Profit Margin: {stats['avg_margin']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Risk-Return scatter plot\n",
    "for name, stats in portfolio_stats.items():\n",
    "    axes[0, 0].scatter(stats['return_std'], stats['avg_return'], \n",
    "                      s=200, alpha=0.7, label=name)\n",
    "    axes[0, 0].annotate(name, (stats['return_std'], stats['avg_return']), \n",
    "                       xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "axes[0, 0].set_xlabel('Risk (Return Std Dev %)')\n",
    "axes[0, 0].set_ylabel('Expected Return (%)')\n",
    "axes[0, 0].set_title('Risk-Return Profile by Portfolio Type')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG vs Return comparison\n",
    "portfolio_names = list(portfolio_stats.keys())\n",
    "esg_scores = [portfolio_stats[p]['avg_esg'] for p in portfolio_names]\n",
    "returns = [portfolio_stats[p]['avg_return'] for p in portfolio_names]\n",
    "\n",
    "axes[0, 1].bar(portfolio_names, esg_scores, alpha=0.7, color='green')\n",
    "axes[0, 1].set_ylabel('Average ESG Score', color='green')\n",
    "axes[0, 1].set_title('ESG Scores by Portfolio Type')\n",
    "axes[0, 1].tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# Create second y-axis for returns\n",
    "ax2 = axes[0, 1].twinx()\n",
    "ax2.plot(portfolio_names, returns, color='red', marker='o', linewidth=2, markersize=8)\n",
    "ax2.set_ylabel('Average Return (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Industry diversification comparison\n",
    "for i, (name, data) in enumerate(portfolios.items()):\n",
    "    industry_dist = data['Industry'].value_counts()\n",
    "    if i == 0:\n",
    "        axes[1, 0].pie(industry_dist.values, labels=industry_dist.index, \n",
    "                      autopct='%1.1f%%', startangle=90)\n",
    "        axes[1, 0].set_title(f'{name} Portfolio - Industry Distribution')\n",
    "    elif i == 1:\n",
    "        axes[1, 1].pie(industry_dist.values, labels=industry_dist.index, \n",
    "                      autopct='%1.1f%%', startangle=90)\n",
    "        axes[1, 1].set_title(f'{name} Portfolio - Industry Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional industry distribution for Balanced portfolio\n",
    "plt.figure(figsize=(10, 8))\n",
    "industry_dist = portfolios['Balanced']['Industry'].value_counts()\n",
    "plt.pie(industry_dist.values, labels=industry_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Balanced Portfolio - Industry Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Frontier calculation (simplified version)\n",
    "# Calculate expected returns and covariance matrix for efficient frontier\n",
    "\n",
    "def calculate_portfolio_metrics(weights, returns, cov_matrix):\n",
    "    portfolio_return = np.sum(weights * returns)\n",
    "    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_return, portfolio_std\n",
    "\n",
    "# Use the traditional portfolio companies for efficient frontier\n",
    "ef_data = traditional_portfolio[['Company_Name', 'Growth_Rate']].set_index('Company_Name')\n",
    "\n",
    "# Simulate historical returns (in reality, you would use actual historical data)\n",
    "n_periods = 12  # 12 months of data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic return series for each company\n",
    "returns_data = pd.DataFrame(index=range(n_periods), columns=ef_data.index)\n",
    "for company in ef_data.index:\n",
    "    expected_return = ef_data.loc[company, 'Growth_Rate'] / 12  # Monthly return\n",
    "    volatility = abs(expected_return) * 0.5  # Assume volatility is 50% of return\n",
    "    returns_data[company] = np.random.normal(expected_return, volatility, n_periods)\n",
    "\n",
    "# Calculate expected returns and covariance matrix\n",
    "expected_returns = returns_data.mean()\n",
    "cov_matrix = returns_data.cov()\n",
    "\n",
    "# Generate random portfolios for efficient frontier\n",
    "n_portfolios = 10000\n",
    "results = np.zeros((3, n_portfolios))\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(n_portfolios):\n",
    "    # Generate random weights\n",
    "    weights = np.random.random(len(expected_returns))\n",
    "    weights /= np.sum(weights)  # Normalize to sum to 1\n",
    "    \n",
    "    # Calculate portfolio metrics\n",
    "    port_return, port_std = calculate_portfolio_metrics(weights, expected_returns, cov_matrix)\n",
    "    \n",
    "    # Store results\n",
    "    results[0, i] = port_return * 12  # Annualize\n",
    "    results[1, i] = port_std * np.sqrt(12)  # Annualize\n",
    "    results[2, i] = results[0, i] / results[1, i]  # Sharpe ratio\n",
    "\n",
    "# Create DataFrame for results\n",
    "ef_results = pd.DataFrame({\n",
    "    'Return': results[0],\n",
    "    'Volatility': results[1], \n",
    "    'Sharpe': results[2]\n",
    "})\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(ef_results['Volatility'], ef_results['Return'], \n",
    "                     c=ef_results['Sharpe'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Sharpe Ratio')\n",
    "\n",
    "# Highlight max Sharpe ratio portfolio\n",
    "max_sharpe_idx = ef_results['Sharpe'].idxmax()\n",
    "plt.scatter(ef_results.loc[max_sharpe_idx, 'Volatility'], \n",
    "           ef_results.loc[max_sharpe_idx, 'Return'], \n",
    "           marker='*', s=500, color='red', label='Max Sharpe Ratio')\n",
    "\n",
    "plt.xlabel('Volatility (%)')\n",
    "plt.ylabel('Expected Return (%)')\n",
    "plt.title('Efficient Frontier - Traditional Portfolio Assets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal Portfolio (Max Sharpe Ratio):\")\n",
    "print(f\"Expected Return: {ef_results.loc[max_sharpe_idx, 'Return']:.2f}%\")\n",
    "print(f\"Volatility: {ef_results.loc[max_sharpe_idx, 'Volatility']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {ef_results.loc[max_sharpe_idx, 'Sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ESG Impact Analysis and Investment Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESG Impact Analysis\n",
    "# Analyze how ESG scores have evolved over time and their impact on financial performance\n",
    "\n",
    "# ESG score evolution over time\n",
    "esg_evolution = esg_data_clean.groupby('Year').agg({\n",
    "    'ESG_Score': 'mean',\n",
    "    'Environmental_Score': 'mean',\n",
    "    'Social_Score': 'mean', \n",
    "    'Governance_Score': 'mean',\n",
    "    'Growth_Rate': 'mean',\n",
    "    'Profit_Margin': 'mean'\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ESG component evolution\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['ESG_Score'], marker='o', linewidth=2, label='Overall ESG')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Environmental_Score'], marker='s', linewidth=2, label='Environmental')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Social_Score'], marker='^', linewidth=2, label='Social')\n",
    "axes[0, 0].plot(esg_evolution.index, esg_evolution['Governance_Score'], marker='d', linewidth=2, label='Governance')\n",
    "axes[0, 0].set_title('ESG Score Evolution Over Time')\n",
    "axes[0, 0].set_xlabel('Year')\n",
    "axes[0, 0].set_ylabel('Average Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG vs Financial Performance over time\n",
    "ax1 = axes[0, 1]\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "line1 = ax1.plot(esg_evolution.index, esg_evolution['ESG_Score'], 'g-o', linewidth=2, label='ESG Score')\n",
    "line2 = ax2.plot(esg_evolution.index, esg_evolution['Growth_Rate'], 'b-s', linewidth=2, label='Growth Rate')\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('ESG Score', color='g')\n",
    "ax2.set_ylabel('Growth Rate (%)', color='b')\n",
    "ax1.set_title('ESG Score vs Financial Performance Over Time')\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ESG quartile analysis\n",
    "latest_data = esg_data_clean[esg_data_clean['Year'] == latest_year]\n",
    "latest_data['ESG_Quartile'] = pd.qcut(latest_data['ESG_Score'], 4, labels=['Q1 (Low)', 'Q2', 'Q3', 'Q4 (High)'])\n",
    "\n",
    "quartile_performance = latest_data.groupby('ESG_Quartile').agg({\n",
    "    'Growth_Rate': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Revenue': 'mean'\n",
    "})\n",
    "\n",
    "quartile_performance['Growth_Rate'].plot(kind='bar', ax=axes[1, 0], color='skyblue', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Growth Rate by ESG Quartile')\n",
    "axes[1, 0].set_ylabel('Growth Rate (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "quartile_performance['Profit_Margin'].plot(kind='bar', ax=axes[1, 1], color='lightcoral', alpha=0.7)\n",
    "axes[1, 1].set_title('Average Profit Margin by ESG Quartile')\n",
    "axes[1, 1].set_ylabel('Profit Margin (%)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ESG Quartile Performance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(quartile_performance.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental impact correlation analysis\n",
    "environmental_impact = esg_data_clean[['ESG_Score', 'Environmental_Score', \n",
    "                                      'Carbon_Emissions', 'Water_Usage', 'Energy_Consumption']]\n",
    "\n",
    "# Calculate correlations\n",
    "env_corr = environmental_impact.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(env_corr, annot=True, cmap='RdYlGn', center=0, square=True, fmt='.3f')\n",
    "plt.title('Environmental Impact vs ESG Scores Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Environmental Correlations:\")\n",
    "print(\"-\" * 40)\n",
    "env_esg_corr = env_corr['Environmental_Score'].drop('Environmental_Score').sort_values(key=abs, ascending=False)\n",
    "for var, corr in env_esg_corr.items():\n",
    "    print(f\"{var:<20}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary of findings\n",
    "print(\"=\" * 80)\n",
    "print(\"ESG INVESTMENT ANALYSIS - KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. DATASET OVERVIEW:\")\n",
    "print(f\"   â€¢ Total observations: {len(esg_data_clean):,}\")\n",
    "print(f\"   â€¢ Number of companies: {esg_data_clean['Company_Name'].nunique():,}\")\n",
    "print(f\"   â€¢ Time period: {esg_data_clean['Year'].min()}-{esg_data_clean['Year'].max()}\")\n",
    "print(f\"   â€¢ Industries covered: {esg_data_clean['Industry'].nunique()}\")\n",
    "print(f\"   â€¢ Geographic regions: {esg_data_clean['Region'].nunique()}\")\n",
    "\n",
    "print(\"\\n2. DATA QUALITY:\")\n",
    "print(f\"   â€¢ Missing values: {esg_data.isnull().sum().sum()} (0.0%)\")\n",
    "total_outliers_treated = sum([stats['reduction'] for stats in outlier_treatment_log.values()])\n",
    "print(f\"   â€¢ Outliers treated: {total_outliers_treated:,}\")\n",
    "print(f\"   â€¢ Data cleaning: Capping at 5th/95th percentiles\")\n",
    "\n",
    "print(\"\\n3. ESG TRENDS:\")\n",
    "esg_trend = esg_data_clean.groupby('Year')['ESG_Score'].mean()\n",
    "esg_improvement = esg_trend.iloc[-1] - esg_trend.iloc[0]\n",
    "print(f\"   â€¢ Average ESG score (2025): {esg_trend.iloc[-1]:.1f}\")\n",
    "print(f\"   â€¢ ESG improvement (2015-2025): +{esg_improvement:.1f} points\")\n",
    "top_esg_industry = esg_data_clean.groupby('Industry')['ESG_Score'].mean().idxmax()\n",
    "print(f\"   â€¢ Highest ESG industry: {top_esg_industry}\")\n",
    "\n",
    "print(\"\\n4. ESG-FINANCIAL PERFORMANCE CORRELATION:\")\n",
    "esg_growth_corr = esg_data_clean['ESG_Score'].corr(esg_data_clean['Growth_Rate'])\n",
    "esg_margin_corr = esg_data_clean['ESG_Score'].corr(esg_data_clean['Profit_Margin'])\n",
    "print(f\"   â€¢ ESG Score vs Growth Rate: {esg_growth_corr:.3f}\")\n",
    "print(f\"   â€¢ ESG Score vs Profit Margin: {esg_margin_corr:.3f}\")\n",
    "if esg_growth_corr > 0.1:\n",
    "    print(f\"   â€¢ Finding: Positive correlation suggests ESG premium\")\n",
    "else:\n",
    "    print(f\"   â€¢ Finding: Weak correlation suggests ESG-return trade-off\")\n",
    "\n",
    "print(\"\\n5. MACHINE LEARNING MODEL PERFORMANCE:\")\n",
    "best_model_r2 = best_model['test_r2']\n",
    "best_model_rmse = best_model['test_rmse']\n",
    "print(f\"   â€¢ Best model: {best_model_name}\")\n",
    "print(f\"   â€¢ Testing RÂ²: {best_model_r2:.4f}\")\n",
    "print(f\"   â€¢ Testing RMSE: {best_model_rmse:.2f}%\")\n",
    "print(f\"   â€¢ Model interpretation: {'Good' if best_model_r2 > 0.5 else 'Moderate' if best_model_r2 > 0.3 else 'Weak'} predictive power\")\n",
    "\n",
    "print(\"\\n6. PORTFOLIO PERFORMANCE COMPARISON:\")\n",
    "for name, stats in portfolio_stats.items():\n",
    "    print(f\"   â€¢ {name}:\")\n",
    "    print(f\"     - Return: {stats['avg_return']:.2f}% | Risk: {stats['return_std']:.2f}% | Sharpe: {stats['sharpe_ratio']:.3f}\")\n",
    "    print(f\"     - ESG Score: {stats['avg_esg']:.1f}\")\n",
    "\n",
    "best_portfolio = max(portfolio_stats.keys(), key=lambda x: portfolio_stats[x]['sharpe_ratio'])\n",
    "print(f\"   â€¢ Best risk-adjusted portfolio: {best_portfolio}\")\n",
    "\n",
    "print(\"\\n7. ESG QUARTILE ANALYSIS:\")\n",
    "q1_return = quartile_performance.loc['Q1 (Low)', 'Growth_Rate']\n",
    "q4_return = quartile_performance.loc['Q4 (High)', 'Growth_Rate']\n",
    "esg_premium = q4_return - q1_return\n",
    "print(f\"   â€¢ Q1 (Low ESG) average return: {q1_return:.2f}%\")\n",
    "print(f\"   â€¢ Q4 (High ESG) average return: {q4_return:.2f}%\")\n",
    "print(f\"   â€¢ ESG premium/discount: {esg_premium:+.2f}%\")\n",
    "\n",
    "print(\"\\n8. INVESTMENT IMPLICATIONS:\")\n",
    "if esg_premium > 0:\n",
    "    print(f\"   â€¢ ESG investing shows positive returns premium\")\n",
    "    print(f\"   â€¢ High ESG companies outperform by {esg_premium:.2f}%\")\n",
    "else:\n",
    "    print(f\"   â€¢ ESG investing shows negative returns impact\")\n",
    "    print(f\"   â€¢ High ESG companies underperform by {abs(esg_premium):.2f}%\")\n",
    "\n",
    "if portfolio_stats['ESG-Focused']['sharpe_ratio'] > portfolio_stats['Traditional']['sharpe_ratio']:\n",
    "    print(f\"   â€¢ ESG portfolios offer better risk-adjusted returns\")\n",
    "else:\n",
    "    print(f\"   â€¢ Traditional portfolios offer better risk-adjusted returns\")\n",
    "\n",
    "print(f\"   â€¢ Balanced approach may optimize risk-return-ESG trade-offs\")\n",
    "print(f\"   â€¢ ESG scores are trending upward (+{esg_improvement:.1f} points over 10 years)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS FOR INVESTORS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Consider ESG factors as part of comprehensive investment analysis\")\n",
    "print(\"2. Use balanced portfolios to optimize risk-return-ESG objectives\")\n",
    "print(\"3. Monitor ESG trends and regulatory developments\")\n",
    "print(\"4. Apply quantitative models to enhance ESG integration\")\n",
    "print(\"5. Diversify across industries while maintaining ESG standards\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Next Steps for Analysis\n",
    "\n",
    "## For Your Written Report and Presentation:\n",
    "\n",
    "### Written Report Sections:\n",
    "1. **ESG Investing Overview**: Use the trend analysis and regulatory context\n",
    "2. **Dataset and Methodology**: Reference the data quality and preprocessing steps\n",
    "3. **Data Analysis**: Include correlation analysis and industry comparisons\n",
    "4. **Model Results**: Present machine learning performance and feature importance\n",
    "5. **Critical Evaluation**: Discuss model limitations and data constraints\n",
    "6. **Conclusions**: Synthesize key findings and investment implications\n",
    "\n",
    "### Presentation Slides:\n",
    "- **Slides 1-2**: ESG evolution trends and regulatory drivers\n",
    "- **Slide 3**: Dataset characteristics and ESG scoring methodology\n",
    "- **Slides 4-5**: Data quality, correlations, and industry analysis\n",
    "- **Slide 6**: ML model results and portfolio optimization outcomes\n",
    "- **Slide 7**: Portfolio performance comparison (risk-return-ESG)\n",
    "- **Slide 8**: Key findings and investment recommendations\n",
    "\n",
    "## Additional Analysis Opportunities:\n",
    "- Extend time series analysis for forecasting\n",
    "- Add sector-specific ESG weighting schemes\n",
    "- Implement more sophisticated portfolio optimization constraints\n",
    "- Include transaction costs and practical implementation considerations\n",
    "- Analyze ESG factor stability over time\n",
    "\n",
    "## Remember to:\n",
    "- Save this notebook and export as PDF\n",
    "- Include all visualizations in your presentation\n",
    "- Cite data sources and methodology in your report\n",
    "- Provide the Google Colab link with your submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}